{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tesis_Maestria_Ing_Julio_Hallo_201020022065_v3.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "a_xP0CFgCHOm",
        "4m96dqYpog4L",
        "MABbG_Kgxsy9",
        "5V-ELxPHGfN9",
        "iV6a17HnHjrf",
        "7l4eFt_xJXfc",
        "jg95lAUTMFK2",
        "zQnimQ1wPhT1",
        "6rdGCc7kQ2WM",
        "qOQREvkBRzMs",
        "Dx4DEMTGTYYB"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOTJA/Rp8uML3ckSLMmpPRq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JulioXa69/Thesis_Public_Repository/blob/Thesis/Tesis_Maestria_Ing_Julio_Hallo_201020022065_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeDYJdaWLERL"
      },
      "source": [
        "### ***Raw Data Set Construction***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_xP0CFgCHOm"
      },
      "source": [
        "# **Data Corpus Analysis and Data Set Construction**\n",
        "2020-07-12\n",
        "JXHALLO: Construction and Review of data sets in order to know if they are independent. Processing Raw Data from:\n",
        "\n",
        "Complete Data Catalog available at: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "\n",
        "Data Corpus Explanation available at: http://webdatacommons.org/largescaleproductcorpus/v2/index.html\n",
        "\n",
        " ***Raw Data Set Outputs:***\n",
        "* TestDataSet\n",
        "* TrainDataSet\n",
        "* NonDupTest\n",
        "* DupTest\n",
        "* NonDupTrain\n",
        "* DupTrain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nx8eMXFBCXSN"
      },
      "source": [
        "# 1- Import Python Libraries\n",
        "import numpy as np\n",
        "import gensim as gs\n",
        "import re as re\n",
        "import string as st\n",
        "import codecs as co\n",
        "import glob as gl\n",
        "import logging as logger\n",
        "import multiprocessing as mult\n",
        "import os as os\n",
        "import pprint as pp\n",
        "import nltk\n",
        "import gensim.models.word2vec as w2v\n",
        "import sklearn.manifold\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import whoosh as ws\n",
        "import random as ra\n",
        "import csv as csv\n",
        "import scipy as sc\n",
        "import json as js\n",
        "# 2- Import Python Functions\n",
        "from whoosh.fields import Schema, TEXT, KEYWORD, ID, STORED\n",
        "from whoosh.support.levenshtein import levenshtein\n",
        "from whoosh.support.levenshtein import damerau_levenshtein\n",
        "# 3- Import Python tensorflow library\n",
        "import tensorflow as tf\n",
        "print(tf.version)  # make sure the version is 2.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myTE1ZDTCdw5"
      },
      "source": [
        "# 4- JXHALLO Download Data Corpus\n",
        "\n",
        "# all_train_xlarge_sample.json\n",
        "# Complete Data Catalog available at: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# Data Corpus Explanation available at: http://webdatacommons.org/largescaleproductcorpus/v2/index.html\n",
        "# Version 1.0: 2020-04-24\n",
        "\n",
        "url = \"/Users/juliohallo/Documents/Personal/Maestria 2018/Python/Corpus/all_gs.json\"\n",
        "\n",
        "df1 = pd.read_json(url, #compression='gzip'\n",
        "                  lines=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jdo9B_dvCz7_"
      },
      "source": [
        "df1.shape\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULICFom1DBJK"
      },
      "source": [
        "# 5- JXHALLO Download Data Corpus\n",
        "\n",
        "# all_train_xlarge_sample.json\n",
        "# Complete Data Catalog available at: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# Data Corpus Explanation available at: http://webdatacommons.org/largescaleproductcorpus/v2/index.html\n",
        "# Version 1.0: 2020-04-24\n",
        "\n",
        "url = \"/Users/juliohallo/Documents/Personal/Maestria 2018/Python/Corpus/all_train/all_train_small.json.gz\"\n",
        "\n",
        "df2 = pd.read_json(url, compression='gzip',lines=True)\n",
        "\n",
        "df2.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9Y3lNmMDD1y"
      },
      "source": [
        "Left_join = pd.merge(df2,  \n",
        "                     df1,  \n",
        "                     on ='pair_id',  \n",
        "                     how ='left') \n",
        "Left_join "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ze1PZwpSDGIY"
      },
      "source": [
        "Left_join.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-v2RCrZDGlQ"
      },
      "source": [
        "Left_join.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzR0eYzEDIiM"
      },
      "source": [
        "# 6- JXHALLO Download Data Corpus\n",
        "\n",
        "# all_train_xlarge_sample.json\n",
        "# Complete Data Catalog available at: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# Data Corpus Explanation available at: http://webdatacommons.org/largescaleproductcorpus/v2/index.html\n",
        "# Version 1.0: 2020-04-24\n",
        "\n",
        "url = \"/Users/juliohallo/Documents/Personal/Maestria 2018/Python/Corpus/all_train/all_train_medium.json.gz\"\n",
        "\n",
        "df3 = pd.read_json(url, compression='gzip',lines=True)\n",
        "\n",
        "df3.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIvMZ3x9DLHx"
      },
      "source": [
        "# 7- JXHALLO Download Data Corpus\n",
        "\n",
        "# all_train_xlarge_sample.json\n",
        "# Complete Data Catalog available at: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# Data Corpus Explanation available at: http://webdatacommons.org/largescaleproductcorpus/v2/index.html\n",
        "# Version 1.0: 2020-04-24\n",
        "\n",
        "url = \"/Users/juliohallo/Documents/Personal/Maestria 2018/Python/Corpus/all_train/all_train_large.json.gz\"\n",
        "\n",
        "df4 = pd.read_json(url, compression='gzip',lines=True)\n",
        "\n",
        "df4.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iihwu76dDNm4"
      },
      "source": [
        "# 8- JXHALLO Download Data Corpus\n",
        "\n",
        "# all_train_xlarge_sample.json\n",
        "# Complete Data Catalog available at: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# Data Corpus Explanation available at: http://webdatacommons.org/largescaleproductcorpus/v2/index.html\n",
        "# Version 1.0: 2020-04-24\n",
        "\n",
        "url = \"/Users/juliohallo/Documents/Personal/Maestria 2018/Python/Corpus/all_train/all_train_xlarge.json.gz\"\n",
        "\n",
        "df5 = pd.read_json(url, compression='gzip',lines=True)\n",
        "\n",
        "df5.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sotx-CCuDQBE"
      },
      "source": [
        "Left_join_xl_l = pd.merge(df5,  \n",
        "                     df4,  \n",
        "                     on ='pair_id',  \n",
        "                     how ='left') \n",
        "Left_join_xl_l\n",
        "Left_join_xl_l.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-v0en436DTzQ"
      },
      "source": [
        "Left_join_l_m = pd.merge(df4,  \n",
        "                     df3,  \n",
        "                     on ='pair_id',  \n",
        "                     how ='left') \n",
        "Left_join_l_m.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hq00K57nDaax"
      },
      "source": [
        "Left_join_l_m = pd.merge(df4,  \n",
        "                     df3,  \n",
        "                     on ='pair_id',  \n",
        "                     how ='left') \n",
        "Left_join_l_m.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbcYNwW9DduY"
      },
      "source": [
        "Left_join_m_gs = pd.merge(df3,  \n",
        "                     df1,  \n",
        "                     on ='pair_id',  \n",
        "                     how ='left') \n",
        "Left_join_m_gs.shape \n",
        "Left_join_m_gs.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rm-oefBuDfXJ"
      },
      "source": [
        "Left_join_l_gs = pd.merge(df4,  \n",
        "                     df1,  \n",
        "                     on ='pair_id',  \n",
        "                     how ='left') \n",
        "Left_join_l_gs.shape\n",
        "Left_join_l_gs.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goJ785KZDmji"
      },
      "source": [
        "Left_join_xl_gs = pd.merge(df5,  \n",
        "                     df1,  \n",
        "                     on ='pair_id',  \n",
        "                     how ='left') \n",
        "Left_join_xl_gs.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjlbGg5yDonA"
      },
      "source": [
        "Left_join_xl_gs.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lApIriSUDqtA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kksMpBVP5uZ"
      },
      "source": [
        "Left_join_xl_s = pd.merge(df5,  \n",
        "                     df2,  \n",
        "                     on ='pair_id',  \n",
        "                     how ='left') \n",
        "Left_join_xl_s.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUqeCbeCP5ud"
      },
      "source": [
        "Left_join_xl_s.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WX6VK1vDP5uf"
      },
      "source": [
        "Left_join_xl_m = pd.merge(df5,  \n",
        "                     df3,  \n",
        "                     on ='pair_id',  \n",
        "                     how ='left') \n",
        "Left_join_xl_m.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Azq--8jzP5uh"
      },
      "source": [
        "Left_join_xl_m.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lY1v7dGhP5uj"
      },
      "source": [
        "Left_join_xl_l = pd.merge(df5,  \n",
        "                     df4,  \n",
        "                     on ='pair_id',  \n",
        "                     how ='left') \n",
        "Left_join_xl_l.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5K_qcOKdP5um"
      },
      "source": [
        "Left_join_xl_l.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ida9KGY8P5uo"
      },
      "source": [
        "Left_join_xl_xl = pd.merge(df5,  \n",
        "                     df5,  \n",
        "                     on ='pair_id',  \n",
        "                     how ='left') \n",
        "Left_join_xl_xl.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxc7tC2tP5uq"
      },
      "source": [
        "Left_join_xl_xl.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHkuAP4CP5ur"
      },
      "source": [
        "Left_join_l_s = pd.merge(df4,  \n",
        "                     df2,  \n",
        "                     on ='pair_id',  \n",
        "                     how ='left') \n",
        "Left_join_l_s.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9eUlGRBP5uu"
      },
      "source": [
        "Left_join_l_s.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIo7eL9EP5uv"
      },
      "source": [
        "Left_join_l_m = pd.merge(df4,  \n",
        "                     df3,  \n",
        "                     on ='pair_id',  \n",
        "                     how ='left') \n",
        "Left_join_l_m.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3l1b-vtP5ux"
      },
      "source": [
        "Left_join_l_m.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkxe8qwNP5uz"
      },
      "source": [
        "Left_join_l_l = pd.merge(df4,  \n",
        "                     df4,  \n",
        "                     on ='pair_id',  \n",
        "                     how ='left') \n",
        "Left_join_l_l.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zx6KkJiRP5u1"
      },
      "source": [
        "Left_join_l_l.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VN5tQo6hP5u3"
      },
      "source": [
        "Left_join_l_xl = pd.merge(df4,  \n",
        "                     df5,  \n",
        "                     on ='pair_id',  \n",
        "                     how ='left') \n",
        "Left_join_l_xl.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3Wb_BJ3P5u-"
      },
      "source": [
        "Left_join_l_xl.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoMUQDmeP5vB"
      },
      "source": [
        "Left_join_m_s = pd.merge(df3,  \n",
        "                     df2,  \n",
        "                     on ='pair_id',  \n",
        "                     how ='left') \n",
        "Left_join_m_s.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaeZuAtnP5vE"
      },
      "source": [
        "Left_join_m_s.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQZ17nloP5vI"
      },
      "source": [
        "Left_join_m_l = pd.merge(df3,  \n",
        "                     df4,  \n",
        "                     on ='pair_id',  \n",
        "                     how ='left') \n",
        "Left_join_m_l.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bIDT4ZkP5vL"
      },
      "source": [
        "Left_join_m_l.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5s-l3HsmP5vO"
      },
      "source": [
        "Left_join_m_xl = pd.merge(df3,  \n",
        "                     df5,  \n",
        "                     on ='pair_id',  \n",
        "                     how ='left') \n",
        "Left_join_m_xl.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5prJz-czP5vS"
      },
      "source": [
        "Left_join_m_xl.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRMgcJ8iP5vT"
      },
      "source": [
        "Left_join_s_m = pd.merge(df2,  \n",
        "                     df3,  \n",
        "                     on ='pair_id',  \n",
        "                     how ='left') \n",
        "Left_join_s_m.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIEjIHRcP5vV"
      },
      "source": [
        "Left_join_s_m.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCB0P8qXP5vX"
      },
      "source": [
        "Left_join_s_l = pd.merge(df2,  \n",
        "                     df4,  \n",
        "                     on ='pair_id',  \n",
        "                     how ='left') \n",
        "Left_join_s_l.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xc2OFA4sP5vZ"
      },
      "source": [
        "Left_join_s_l.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X16YHYLDP5vh"
      },
      "source": [
        "Left_join_s_xl = pd.merge(df2,  \n",
        "                     df5,  \n",
        "                     on ='pair_id',  \n",
        "                     how ='left') \n",
        "Left_join_s_xl.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtXBV6_xP5vj"
      },
      "source": [
        "Left_join_s_xl.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0L48d19-DzPe"
      },
      "source": [
        "# 9- JXHALLO Append All Dataframes\n",
        "\n",
        "# all_train_xlarge_sample.json.gz, all_train_large.json.gz, all_train_medium.json.gz, all_train_small.json.gz\n",
        "# Complete Data Catalog available at: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# Data Corpus Explanation available at: http://webdatacommons.org/largescaleproductcorpus/v2/index.html\n",
        "# Version 1.0: 2020-07-12\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECjsPg3tP5vn"
      },
      "source": [
        "AppendedDataFile = df5.append(df4)\n",
        "AppendedDataFile.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNJrW8WeP5vp"
      },
      "source": [
        "AppendedDataFile = AppendedDataFile.append(df3)\n",
        "AppendedDataFile.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1-qohCRP5vr"
      },
      "source": [
        "AppendedDataFile = AppendedDataFile.append(df2)\n",
        "AppendedDataFile.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlqJTWZkP5vt"
      },
      "source": [
        "TotalRecords = 214736+103411+25567+9038\n",
        "print (TotalRecords)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9-YPPVEP5vv"
      },
      "source": [
        "AppendedDataFile.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oydx3LXIP5vw"
      },
      "source": [
        "AppendedDataFile.sort_values(\"pair_id\", inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kI-cL0qlP5vz"
      },
      "source": [
        "AppendedDataFile.drop_duplicates(subset =\"pair_id\", keep='first', inplace=True)\n",
        "AppendedDataFile.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNj9IOWAP5v1"
      },
      "source": [
        "AppendedDataFile.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51g0OeYDP5v2"
      },
      "source": [
        "print (AppendedDataFile.query('label == \"1\"').label.count())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdfJvvsfP5v4"
      },
      "source": [
        "print (AppendedDataFile.query('label == \"0\"').label.count())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4zgtqE7P5v5"
      },
      "source": [
        "#2020-07-20 Saviing AppendedDataFile using pickle\n",
        "AppendedDataFile.to_pickle('/Users/juliohallo/Documents/Personal/Maestria 2018/Python/20200720_DataAnalysis/AppendedDataFile.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpXnoQ-sP5v7"
      },
      "source": [
        "#2020-07-20 Reading AppendedDataFile using pickle\n",
        "AppendedDataFile=pd.read_pickle('/Users/juliohallo/Documents/Personal/Maestria 2018/Python/20200720_DataAnalysis/AppendedDataFile.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tih4ZjAmP5v8"
      },
      "source": [
        "print(AppendedDataFile.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-uAyJ3zP5v-"
      },
      "source": [
        "AppendedDataFile.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4rnXiqdP5wC"
      },
      "source": [
        "AppendedDataFile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRCNNBwvP5wG"
      },
      "source": [
        "print (AppendedDataFile.query('category_left == \"Jewelry\"').label.count())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkakOKdFP5wH"
      },
      "source": [
        "AppendedDataFile['category_left'].value_counts().plot(kind='bar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxe82i_QP5wJ"
      },
      "source": [
        "AppendedDataFile['category_right'].value_counts().plot(kind='bar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MshJHO99P5wK"
      },
      "source": [
        "AppendedDataFile['label'].value_counts('')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0egLmdMP5wN"
      },
      "source": [
        "AppendedDataFile['category_left'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iw1sqLdUP5wO"
      },
      "source": [
        "subset_df = AppendedDataFile[(AppendedDataFile[\"category_right\"] == 'Computers_and_Accessories')&(AppendedDataFile[\"label\"] == 0)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWwk6Ku7P5wQ"
      },
      "source": [
        "subset_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5KKIqpaP5wR"
      },
      "source": [
        "subset_df = subset_df[(subset_df[\"label\"] == 1)]\n",
        "subset_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDjz1JviP5wV"
      },
      "source": [
        "# 2020-07-20: Create Dataframe with lable = 1 of all four categories\n",
        "# Computers_and_Accessories_Dup\n",
        "# Shoes\n",
        "# Camera_and_Photo\n",
        "# Jewelry\n",
        "# Save into pickle\n",
        "Computers_and_Accessories_Dup  = AppendedDataFile[(AppendedDataFile[\"category_left\"] == 'Computers_and_Accessories')&(AppendedDataFile[\"label\"] == 1)]\n",
        "Shoes_Dup  = AppendedDataFile[(AppendedDataFile[\"category_left\"] == 'Shoes')&(AppendedDataFile[\"label\"] == 1)]\n",
        "Camera_and_Photo_Dup  = AppendedDataFile[(AppendedDataFile[\"category_left\"] == 'Camera_and_Photo')&(AppendedDataFile[\"label\"] == 1)]\n",
        "Jewelry_Dup  = AppendedDataFile[(AppendedDataFile[\"category_left\"] == 'Jewelry')&(AppendedDataFile[\"label\"] == 1)]\n",
        "print(\"Computers_and_Accessories_Dup.shape\")\n",
        "print(Computers_and_Accessories_Dup.shape)\n",
        "print(\"Shoes_Dup.shape\")\n",
        "print(Shoes_Dup.shape)\n",
        "print(\"Camera_and_Photo_Dup.shape\")\n",
        "print(Camera_and_Photo_Dup.shape)\n",
        "print(\"Jewelry_Dup.shape\")\n",
        "print(Jewelry_Dup.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hr4ygDA2P5wW"
      },
      "source": [
        "Computers_and_Accessories_Dup.to_pickle('/Users/juliohallo/Documents/Personal/Maestria 2018/Python/20200720_DataAnalysis/Computers_and_Accessories_Dup.pkl')\n",
        "Shoes_Dup.to_pickle('/Users/juliohallo/Documents/Personal/Maestria 2018/Python/20200720_DataAnalysis/Shoes_Dup.pkl')\n",
        "Camera_and_Photo_Dup.to_pickle('/Users/juliohallo/Documents/Personal/Maestria 2018/Python/20200720_DataAnalysis/Camera_and_Photo_Dup.pkl')\n",
        "Jewelry_Dup.to_pickle('/Users/juliohallo/Documents/Personal/Maestria 2018/Python/20200720_DataAnalysis/Jewelry_Dup.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvmVaMd5P5wX"
      },
      "source": [
        "# 2020-07-20: Create Dataframe with lable = 0 of all four categories\n",
        "# Computers_and_Accessories_Dup\n",
        "# Shoes\n",
        "# Camera_and_Photo\n",
        "# Jewelry\n",
        "# Save into pickle\n",
        "Computers_and_Accessories_NonDup  = AppendedDataFile[(AppendedDataFile[\"category_left\"] == 'Computers_and_Accessories')&(AppendedDataFile[\"label\"] == 0)]\n",
        "Shoes_NonDup  = AppendedDataFile[(AppendedDataFile[\"category_left\"] == 'Shoes')&(AppendedDataFile[\"label\"] == 0)]\n",
        "Camera_and_Photo_NonDup  = AppendedDataFile[(AppendedDataFile[\"category_left\"] == 'Camera_and_Photo')&(AppendedDataFile[\"label\"] == 0)]\n",
        "Jewelry_NonDup  = AppendedDataFile[(AppendedDataFile[\"category_left\"] == 'Jewelry')&(AppendedDataFile[\"label\"] == 0)]\n",
        "print(\"Computers_and_Accessories_NonDup.shape\")\n",
        "print(Computers_and_Accessories_NonDup.shape)\n",
        "print(\"Shoes_NonDup.shape\")\n",
        "print(Shoes_NonDup.shape)\n",
        "print(\"Camera_and_Photo_NonDup.shape\")\n",
        "print(Camera_and_Photo_NonDup.shape)\n",
        "print(\"Jewelry_NonDup.shape\")\n",
        "print(Jewelry_NonDup.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaLt1c4LP5wZ"
      },
      "source": [
        "Computers_and_Accessories_NonDup.to_pickle('/Users/juliohallo/Documents/Personal/Maestria 2018/Python/20200720_DataAnalysis/Computers_and_Accessories_NonDup.pkl')\n",
        "Shoes_NonDup.to_pickle('/Users/juliohallo/Documents/Personal/Maestria 2018/Python/20200720_DataAnalysis/Shoes_NonDup.pkl')\n",
        "Camera_and_Photo_NonDup.to_pickle('/Users/juliohallo/Documents/Personal/Maestria 2018/Python/20200720_DataAnalysis/Camera_and_Photo_NonDup.pkl')\n",
        "Jewelry_NonDup.to_pickle('/Users/juliohallo/Documents/Personal/Maestria 2018/Python/20200720_DataAnalysis/Jewelry_NonDup.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "295Rj9luP5wc"
      },
      "source": [
        "# 2020-07-20: Create Dataframe for Train and Test with lable = 1 of all four categories\n",
        "# Computers_and_Accessories_Dup\n",
        "# Save into pickle\n",
        "\n",
        "print(\"Computers_and_Accessories_Dup.shape\")\n",
        "print(Computers_and_Accessories_Dup.shape)\n",
        "\n",
        "Computers_and_Accessories_Dup_Train = Computers_and_Accessories_Dup.sample(frac=0.7)\n",
        "print(\"Computers_and_Accessories_Dup_Train.shape\")\n",
        "print(Computers_and_Accessories_Dup_Train.shape)\n",
        "\n",
        "Computers_and_Accessories_Dup_Test = Computers_and_Accessories_Dup.append(Computers_and_Accessories_Dup_Train)\n",
        "print(\"Computers_and_Accessories_Dup_Test.shape\")\n",
        "print(Computers_and_Accessories_Dup_Test.shape)\n",
        "Computers_and_Accessories_Dup_Test.drop_duplicates(subset =\"pair_id\", keep=False, inplace=True)\n",
        "print(\"Computers_and_Accessories_Dup_Test.shape\")\n",
        "print(Computers_and_Accessories_Dup_Test.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRdBOX8wP5wd"
      },
      "source": [
        "Computers_and_Accessories_Dup_Train.to_pickle('/Users/juliohallo/Documents/Personal/Maestria 2018/Python/20200720_DataAnalysis/Computers_and_Accessories_Dup_Train.pkl')\n",
        "Computers_and_Accessories_Dup_Test.to_pickle('/Users/juliohallo/Documents/Personal/Maestria 2018/Python/20200720_DataAnalysis/Computers_and_Accessories_Dup_Test.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsa7lsgOP5we"
      },
      "source": [
        "# 2020-07-20: Create Dataframe for Train and Test with lable = 1 of all four categories\n",
        "# Shoes_Dup\n",
        "# Save into pickle\n",
        "print(\"Shoes_Dup.shape\")\n",
        "print(Shoes_Dup.shape)\n",
        "\n",
        "Shoes_Dup_Train = Shoes_Dup.sample(frac=0.7)\n",
        "print(\"Shoes_Dup_Train.shape\")\n",
        "print(Shoes_Dup_Train.shape)\n",
        "\n",
        "Shoes_Dup_Test = Shoes_Dup.append(Shoes_Dup_Train)\n",
        "print(\"Shoes_Dup_Test.shape\")\n",
        "print(Shoes_Dup_Test.shape)\n",
        "Shoes_Dup_Test.drop_duplicates(subset =\"pair_id\", keep=False, inplace=True)\n",
        "print(\"Shoes_Dup_Test.shape\")\n",
        "print(Shoes_Dup_Test.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94ka6W3wP5wg"
      },
      "source": [
        "Shoes_Dup_Train.to_pickle('/Users/juliohallo/Documents/Personal/Maestria 2018/Python/20200720_DataAnalysis/Shoes_Dup_Train.pkl')\n",
        "Shoes_Dup_Test.to_pickle('/Users/juliohallo/Documents/Personal/Maestria 2018/Python/20200720_DataAnalysis/Shoes_Dup_Test.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHMGxl4EP5wh"
      },
      "source": [
        "# 2020-07-20: Create Dataframe for Train and Test with lable = 1 of all four categories\n",
        "# Camera_and_Photo\n",
        "# Save into pickle\n",
        "print(\"Camera_and_Photo_Dup.shape\")\n",
        "print(Camera_and_Photo_Dup.shape)\n",
        "\n",
        "Camera_and_Photo_Dup_Train = Camera_and_Photo_Dup.sample(frac=0.7)\n",
        "print(\"Camera_and_Photo_Dup_Train.shape\")\n",
        "print(Camera_and_Photo_Dup_Train.shape)\n",
        "\n",
        "Camera_and_Photo_Dup_Test = Camera_and_Photo_Dup.append(Camera_and_Photo_Dup_Train)\n",
        "print(\"Camera_and_Photo_Dup_Test.shape\")\n",
        "print(Camera_and_Photo_Dup_Test.shape)\n",
        "Camera_and_Photo_Dup_Test.drop_duplicates(subset =\"pair_id\", keep=False, inplace=True)\n",
        "print(\"Camera_and_Photo_Dup_Test.shape\")\n",
        "print(Camera_and_Photo_Dup_Test.shape)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lzR9UptP5wk"
      },
      "source": [
        "Camera_and_Photo_Dup_Train.to_pickle('/Users/juliohallo/Documents/Personal/Maestria 2018/Python/20200720_DataAnalysis/Camera_and_Photo_Dup_Train.pkl')\n",
        "Camera_and_Photo_Dup_Test.to_pickle('/Users/juliohallo/Documents/Personal/Maestria 2018/Python/20200720_DataAnalysis/Camera_and_Photo_Dup_Test.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFu0u6OcP5wl"
      },
      "source": [
        "# 2020-07-20: Create Dataframe for Train and Test with lable = 1 of all four categories\n",
        "# Jewelry\n",
        "# Save into pickle\n",
        "print(\"Jewelry_Dup.shape\")\n",
        "print(Jewelry_Dup.shape)\n",
        "\n",
        "Jewelry_Dup_Train = Jewelry_Dup.sample(frac=0.7)\n",
        "print(\"Jewelry_Dup_Train.shape\")\n",
        "print(Jewelry_Dup_Train.shape)\n",
        "\n",
        "Jewelry_Dup_Test = Jewelry_Dup.append(Jewelry_Dup_Train)\n",
        "print(\"Jewelry_Dup_Test.shape\")\n",
        "print(Jewelry_Dup_Test.shape)\n",
        "Jewelry_Dup_Test.drop_duplicates(subset =\"pair_id\", keep=False, inplace=True)\n",
        "print(\"Jewelry_Dup_Test.shape\")\n",
        "print(Jewelry_Dup_Test.shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60IRvUNvP5wn"
      },
      "source": [
        "Jewelry_Dup_Train.to_pickle('/Users/juliohallo/Documents/Personal/Maestria 2018/Python/20200720_DataAnalysis/Jewelry_Dup_Train.pkl')\n",
        "Jewelry_Dup_Test.to_pickle('/Users/juliohallo/Documents/Personal/Maestria 2018/Python/20200720_DataAnalysis/Jewelry_Dup_Test.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoMrNRq0P5wp"
      },
      "source": [
        "# 2020-07-20: Create Dataframe for Train and Test with lable = 0, but ensure 27.27% Dups in all DataSet like in All_GS\n",
        "# Jewelry Dups = 10,027\n",
        "# Jewlry New NonDups = (10,027/0.2717)*(1-0.2727) = 26,742\n",
        "# NEW TOTAL DATASET = 36,769\n",
        "# Save into pickle\n",
        "print(\"Jewelry_NonDup.shape\")\n",
        "print(Jewelry_NonDup.shape)\n",
        "\n",
        "Jewelry_NonDup_New = Jewelry_NonDup.sample(n=26742)\n",
        "print(\"Jewelry_NonDup_New.shape\")\n",
        "print(Jewelry_NonDup_New.shape)\n",
        "\n",
        "Jewelry_NonDup_Train = Jewelry_NonDup_New.sample(frac=0.7)\n",
        "print(\"Jewelry_NonDup_Train.shape\")\n",
        "print(Jewelry_NonDup_Train.shape)\n",
        "\n",
        "Jewelry_NonDup_Test = Jewelry_NonDup_New.append(Jewelry_NonDup_Train)\n",
        "print(\"Jewelry_NonDup_Test.shape\")\n",
        "print(Jewelry_NonDup_Test.shape)\n",
        "Jewelry_NonDup_Test.drop_duplicates(subset =\"pair_id\", keep=False, inplace=True)\n",
        "print(\"Jewelry_NonDup_Test.shape\")\n",
        "print(Jewelry_NonDup_Test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fqee9ITPP5wq"
      },
      "source": [
        "Jewelry_NonDup_Train.to_pickle('/Users/juliohallo/Documents/Personal/Maestria 2018/Python/20200720_DataAnalysis/Jewelry_NonDup_Train.pkl')\n",
        "Jewelry_NonDup_Test.to_pickle('/Users/juliohallo/Documents/Personal/Maestria 2018/Python/20200720_DataAnalysis/Jewelry_NonDup_Test.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCRlfdt2P5ws"
      },
      "source": [
        "# 2020-07-20: Create Dataframe for Train and Test with lable = 0, but ensure 27.27% Dups in all DataSet like in All_GS\n",
        "# Camera_and_Photo Dups = 7,530\n",
        "# Camera_and_Photo New NonDups = (7,530/0.2727)*(1-0.2727) = 20,083\n",
        "# NEW TOTAL DATASET = 27,613\n",
        "# Save into pickle\n",
        "print(\"Camera_and_Photo_NonDup.shape\")\n",
        "print(Camera_and_Photo_NonDup.shape)\n",
        "\n",
        "Camera_and_Photo_NonDup_New = Camera_and_Photo_NonDup.sample(n=20083)\n",
        "print(\"Camera_and_Photo_NonDup_New.shape\")\n",
        "print(Camera_and_Photo_NonDup_New.shape)\n",
        "\n",
        "Camera_and_Photo_NonDup_Train = Camera_and_Photo_NonDup_New.sample(frac=0.7)\n",
        "print(\"Camera_and_Photo_NonDup_Train.shape\")\n",
        "print(Camera_and_Photo_NonDup_Train.shape)\n",
        "\n",
        "Camera_and_Photo_NonDup_Test = Camera_and_Photo_NonDup_New.append(Camera_and_Photo_NonDup_Train)\n",
        "print(\"Camera_and_Photo_NonDup_Test.shape\")\n",
        "print(Camera_and_Photo_NonDup_Test.shape)\n",
        "Camera_and_Photo_NonDup_Test.drop_duplicates(subset =\"pair_id\", keep=False, inplace=True)\n",
        "print(\"Camera_and_Photo_NonDup_Test.shape\")\n",
        "print(Camera_and_Photo_NonDup_Test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2XYzTjDP5wt"
      },
      "source": [
        "Camera_and_Photo_NonDup_Train.to_pickle('/Users/juliohallo/Documents/Personal/Maestria 2018/Python/20200720_DataAnalysis/Camera_and_Photo_NonDup_Train.pkl')\n",
        "Camera_and_Photo_NonDup_Test.to_pickle('/Users/juliohallo/Documents/Personal/Maestria 2018/Python/20200720_DataAnalysis/Camera_and_Photo_NonDup_Test.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9pVvh7yP5wu"
      },
      "source": [
        "# 2020-07-20: Create Dataframe for Train and Test with lable = 0, but ensure 27.27% Dups in all DataSet like in All_GS\n",
        "# Shoes Dups = 4,527\n",
        "# Shoes New NonDups = (4,527/0.2727)*(1-0.2727) = 12,074\n",
        "# NEW TOTAL DATASET = 16601\n",
        "# Save into pickle\n",
        "print(\"Shoes_NonDup.shape\")\n",
        "print(Shoes_NonDup.shape)\n",
        "\n",
        "Shoes_NonDup_New = Camera_and_Photo_NonDup.sample(n=12074)\n",
        "print(\"Shoes_NonDup_New.shape\")\n",
        "print(Shoes_NonDup_New.shape)\n",
        "\n",
        "Shoes_NonDup_Train = Shoes_NonDup_New.sample(frac=0.7)\n",
        "print(\"Shoes_NonDup_Train.shape\")\n",
        "print(Shoes_NonDup_Train.shape)\n",
        "\n",
        "Shoes_NonDup_Test = Shoes_NonDup_New.append(Shoes_NonDup_Train)\n",
        "print(\"Shoes_NonDup_Test.shape\")\n",
        "print(Shoes_NonDup_Test.shape)\n",
        "Shoes_NonDup_Test.drop_duplicates(subset =\"pair_id\", keep=False, inplace=True)\n",
        "print(\"Shoes_NonDup_Test.shape\")\n",
        "print(Shoes_NonDup_Test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKnNlYIvP5wv"
      },
      "source": [
        "Shoes_NonDup_Train.to_pickle('/Users/juliohallo/Documents/Personal/Maestria 2018/Python/20200720_DataAnalysis/Shoes_NonDup_Train.pkl')\n",
        "Shoes_NonDup_Test.to_pickle('/Users/juliohallo/Documents/Personal/Maestria 2018/Python/20200720_DataAnalysis/Shoes_NonDup_Test.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpK3QMftP5wy"
      },
      "source": [
        "# 2020-07-20: Create Dataframe for Train and Test with lable = 0, but ensure 27.27% Dups in all DataSet like in All_GS\n",
        "# Computers_and_Accessories Dups = 10,244\n",
        "# Computers_and_Accessories New NonDups = (10,244/0.2727)*(1-0.2727) = 27,321\n",
        "# NEW TOTAL DATASET = 37,565\n",
        "# Save into pickle\n",
        "print(\"Computers_and_Accessories_NonDup.shape\")\n",
        "print(Computers_and_Accessories_NonDup.shape)\n",
        "\n",
        "Computers_and_Accessories_NonDup_New = Computers_and_Accessories_NonDup.sample(n=27321)\n",
        "print(\"Computers_and_Accessories_NonDup_New.shape\")\n",
        "print(Computers_and_Accessories_NonDup_New.shape)\n",
        "\n",
        "Computers_and_Accessories_NonDup_Train = Computers_and_Accessories_NonDup_New.sample(frac=0.7)\n",
        "print(\"Computers_and_Accessories_NonDup_Train.shape\")\n",
        "print(Computers_and_Accessories_NonDup_Train.shape)\n",
        "\n",
        "Computers_and_Accessories_NonDup_Test = Computers_and_Accessories_NonDup_New.append(Computers_and_Accessories_NonDup_Train)\n",
        "print(\"Computers_and_Accessories_NonDup_Test.shape\")\n",
        "print(Computers_and_Accessories_NonDup_Test.shape)\n",
        "Computers_and_Accessories_NonDup_Test.drop_duplicates(subset =\"pair_id\", keep=False, inplace=True)\n",
        "print(\"Computers_and_Accessories_NonDup_Test.shape\")\n",
        "print(Computers_and_Accessories_NonDup_Test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4SkeL1vP5w2"
      },
      "source": [
        "Computers_and_Accessories_NonDup_Train.to_pickle('/Users/juliohallo/Documents/Personal/Maestria 2018/Python/20200720_DataAnalysis/Computers_and_Accessories_NonDup_Train.pkl')\n",
        "Computers_and_Accessories_NonDup_Test.to_pickle('/Users/juliohallo/Documents/Personal/Maestria 2018/Python/20200720_DataAnalysis/Computers_and_Accessories_NonDup_Test.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIQJIZ8MP5w3"
      },
      "source": [
        "# NonDupTrain = Computers_and_Accessories_NonDup_Train.append(Shoes_NonDup_Train,Camera_and_Photo_NonDup_Train,Jewelry_NonDup_Train)\n",
        "NonDupTrain = Computers_and_Accessories_NonDup_Train.append(Shoes_NonDup_Train)\n",
        "NonDupTrain = NonDupTrain.append(Camera_and_Photo_NonDup_Train)\n",
        "NonDupTrain = NonDupTrain.append(Jewelry_NonDup_Train)\n",
        "print(\"Computers_and_Accessories_NonDup_Train.shape\")\n",
        "print(Computers_and_Accessories_NonDup_Train.shape)\n",
        "print(\"Shoes_NonDup_Train.shape\")\n",
        "print(Shoes_NonDup_Train.shape)\n",
        "print(\"Camera_and_Photo_NonDup_Train.shape\")\n",
        "print(Camera_and_Photo_NonDup_Train.shape)\n",
        "print(\"Jewelry_NonDup_Train.shape\")\n",
        "print(Jewelry_NonDup_Train.shape)\n",
        "print(\"NonDupTrain.shape\")\n",
        "print(NonDupTrain.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BRkFeU2P5w7"
      },
      "source": [
        "# NonDupTest = Computers_and_Accessories_NonDup_Test.append(Shoes_NonDup_Test,Camera_and_Photo_NonDup_Test,Jewelry_NonDup_Test)\n",
        "NonDupTest = Computers_and_Accessories_NonDup_Test.append(Shoes_NonDup_Test)\n",
        "NonDupTest = NonDupTest.append(Camera_and_Photo_NonDup_Test)\n",
        "NonDupTest = NonDupTest.append(Jewelry_NonDup_Test)\n",
        "print(\"Computers_and_Accessories_NonDup_Test.shape\")\n",
        "print(Computers_and_Accessories_NonDup_Test.shape)\n",
        "print(\"Shoes_NonDup_Test.shape\")\n",
        "print(Shoes_NonDup_Test.shape)\n",
        "print(\"Camera_and_Photo_NonDup_Test.shape\")\n",
        "print(Camera_and_Photo_NonDup_Test.shape)\n",
        "print(\"Jewelry_NonDup_Test.shape\")\n",
        "print(Jewelry_NonDup_Test.shape)\n",
        "print(\"NonDupTest.shape\")\n",
        "print(NonDupTest.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHb3VIpTP5w9"
      },
      "source": [
        "# DupTrain = Computers_and_Accessories_Dup_Train.append(Shoes_Dup_Train,Camera_and_Photo_Dup_Train,Jewelry_Dup_Train)\n",
        "DupTrain = Computers_and_Accessories_Dup_Train.append(Shoes_Dup_Train)\n",
        "DupTrain = DupTrain.append(Camera_and_Photo_Dup_Train)\n",
        "DupTrain = DupTrain.append(Jewelry_Dup_Train)\n",
        "print(\"Computers_and_Accessories_Dup_Train.shape\")\n",
        "print(Computers_and_Accessories_Dup_Train.shape)\n",
        "print(\"Shoes_Dup_Train.shape\")\n",
        "print(Shoes_Dup_Train.shape)\n",
        "print(\"Camera_and_Photo_Dup_Train.shape\")\n",
        "print(Camera_and_Photo_Dup_Train.shape)\n",
        "print(\"Jewelry_Dup_Train.shape\")\n",
        "print(Jewelry_Dup_Train.shape)\n",
        "print(\"DupTrain.shape\")\n",
        "print(DupTrain.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGmpCN7_P5w-"
      },
      "source": [
        "# DupTest = Computers_and_Accessories_Dup_Test.append(Shoes_Dup_Test,Camera_and_Photo_Dup_Test,Jewelry_Dup_Test)\n",
        "DupTest = Computers_and_Accessories_Dup_Test.append(Shoes_Dup_Test)\n",
        "DupTest = DupTest.append(Camera_and_Photo_Dup_Test)\n",
        "DupTest = DupTest.append(Jewelry_Dup_Test)\n",
        "print(\"Computers_and_Accessories_Dup_Test.shape\")\n",
        "print(Computers_and_Accessories_Dup_Test.shape)\n",
        "print(\"Shoes_Dup_Test.shape\")\n",
        "print(Shoes_Dup_Test.shape)\n",
        "print(\"Camera_and_Photo_Dup_Test.shape\")\n",
        "print(Camera_and_Photo_Dup_Test.shape)\n",
        "print(\"Jewelry_Dup_Test.shape\")\n",
        "print(Jewelry_Dup_Test.shape)\n",
        "print(\"DupTest.shape\")\n",
        "print(DupTest.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lf4cecbWP5xA"
      },
      "source": [
        "print (DupTest.query('label == \"1\"').label.count())\n",
        "print (DupTrain.query('label == \"1\"').label.count())\n",
        "print (NonDupTest.query('label == \"0\"').label.count())\n",
        "print (NonDupTrain.query('label == \"0\"').label.count())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c86gRBIIP5xB"
      },
      "source": [
        "TestDataSet = NonDupTest.append(DupTest)\n",
        "TrainDataSet = NonDupTrain.append(DupTrain)\n",
        "print (TestDataSet.query('label == \"1\"').label.count())\n",
        "print (TestDataSet.query('label == \"0\"').label.count())\n",
        "print (TrainDataSet.query('label == \"1\"').label.count())\n",
        "print (TrainDataSet.query('label == \"0\"').label.count())\n",
        "print (TrainDataSet.shape)\n",
        "print (TestDataSet.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LopDmFcP5xC"
      },
      "source": [
        "TestDataSet.to_pickle('/Users/juliohallo/Documents/Personal/Maestria 2018/Python/20200720_DataAnalysis/TestDataSet.pkl')\n",
        "TrainDataSet.to_pickle('/Users/juliohallo/Documents/Personal/Maestria 2018/Python/20200720_DataAnalysis/TrainDataSet.pkl')\n",
        "NonDupTest.to_pickle('/Users/juliohallo/Documents/Personal/Maestria 2018/Python/20200720_DataAnalysis/NonDupTest.pkl')\n",
        "DupTest.to_pickle('/Users/juliohallo/Documents/Personal/Maestria 2018/Python/20200720_DataAnalysis/DupTest.pkl')\n",
        "NonDupTrain.to_pickle('/Users/juliohallo/Documents/Personal/Maestria 2018/Python/20200720_DataAnalysis/NonDupTrain.pkl')\n",
        "DupTrain.to_pickle('/Users/juliohallo/Documents/Personal/Maestria 2018/Python/20200720_DataAnalysis/DupTrain.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0beDSnLtwit3"
      },
      "source": [
        "# ***Preprocessing Data Corpus***\n",
        "\n",
        "Word 2 Vec Data Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4m96dqYpog4L"
      },
      "source": [
        "# Preprocessing Data Corpus: Preprocessing of TrainDataSet.pkl with Word2Vec v2\n",
        "2020-08-17\n",
        "JXHALLO: Preprocessing of TrainDataSet.pkl with Word2Vec v2: Applied transformation to create matrix (n,501) for word2vec transformation\n",
        "\n",
        " ***Preprocessed Data Set Outputs:***\n",
        "* TrainDataSetW2V_501\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bppdkSQlo7HC"
      },
      "source": [
        "2020-08-17\n",
        "\n",
        "JXHALLO: Preprocessing of TrainDataSet.pkl with Word2Vec\n",
        "v2: Applied transformation to create matrix (n,501) for word2vec transformation where:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ctl740CborAL"
      },
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dd6gZx73pBi6"
      },
      "source": [
        "# 0.1 - Install whoosh\n",
        "!pip install whoosh\n",
        "# 1- Import Python Libraries\n",
        "import numpy as np\n",
        "import gensim as gs\n",
        "import re as re\n",
        "import string as st\n",
        "import codecs as co\n",
        "import glob as gl\n",
        "import logging as logger\n",
        "import multiprocessing as mult\n",
        "import os as os\n",
        "import pprint as pp\n",
        "import nltk\n",
        "import gensim.models.word2vec as w2v\n",
        "import sklearn.manifold\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import whoosh as ws\n",
        "import random as ra\n",
        "import csv as csv\n",
        "import scipy as sc\n",
        "import json as js\n",
        "import itertools "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3ivCRC0pFd8"
      },
      "source": [
        "# 2- Import Python Functions\n",
        "from whoosh.fields import Schema, TEXT, KEYWORD, ID, STORED\n",
        "from whoosh.support.levenshtein import levenshtein\n",
        "from whoosh.support.levenshtein import damerau_levenshtein\n",
        "from IPython.display import clear_output\n",
        "from six.moves import urllib\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import ConfusionMatrixDisplay"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2v4sqQcpJjz"
      },
      "source": [
        "# 3- Import Python tensorflow library\n",
        "import tensorflow as tf\n",
        "print(tf.version)  # make sure the version is 2.x\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_probability as tfp  # We are using a different module from tensorflow this time\n",
        "import tensorflow.compat.v2.feature_column as fc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWNrPjzupMwa"
      },
      "source": [
        "#2020-08-09 Reading TrainDataSet using pickle from My drive Google Drive\n",
        "TrainDataSet=pd.read_pickle('/content/drive/My Drive/Python/20200720_DataAnalysis/TrainDataSet.pkl')\n",
        "print (\"TrainDataSet.shape\")\n",
        "print (TrainDataSet.shape)\n",
        "print (\"TrainDataSet.dtypes\")\n",
        "print (TrainDataSet.dtypes)\n",
        "print (\"TrainDataSet.isnull().sum()\")\n",
        "print (TrainDataSet.isnull().sum())\n",
        "TrainDataSet = TrainDataSet.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_npc-pEpWD-"
      },
      "source": [
        "# 3- JXHALLO Personal Functions for Code\n",
        "\n",
        "# String Normalizer\n",
        "# Version 1.0: 2020-04-10\n",
        "# Returns normalized string without spaces and special characters using RegEx. Then sets lower case\n",
        "\n",
        "def norm (x):\n",
        "    return re.sub(r\"\\s|[^a-z0-9]\",\"\",x.lower(), flags=re.IGNORECASE)\n",
        "\n",
        "# String Exact Comparison\n",
        "# Version 1.0: 2020-04-10\n",
        "# Returns boolean if string comparison is exact.\n",
        "\n",
        "def exact(a,b):\n",
        "    if a is b:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "# Function to access a specific value within an object list\n",
        "# Returns the value of the record with the corresponding key.\n",
        "# Arguments: object that contain the list of keys and values, the key that you want to match to return the value\n",
        "# Special Note: This function will only return the first value of the list.\n",
        "# Special Note2: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Version 1.2: 2020-04-17\n",
        "\n",
        "def multiObjects(values,key):\n",
        "    val = None\n",
        "    for i in range(len(values)):\n",
        "        data = values[i]\n",
        "        for (k, v) in data.items():\n",
        "            if k == key:\n",
        "                val = list(v.split(\", \"))[0].replace(\"[\",\"\").replace(\"]\",\"\").strip()\n",
        "    return val\n",
        "    \n",
        "# Function to access a specific value within an object list\n",
        "# Returns the value of the record of the corresponding key.\n",
        "# Arguments: object that contain the list of keys and values, the key that you want to match to return the value\n",
        "# Special Note: This function will only return the first value of the list.\n",
        "# Special Note2: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Version 1.0: 2020-04-24\n",
        "\n",
        "def identifiersList (column,key):\n",
        "    lineLst = []\n",
        "    for i in range (len(column)):\n",
        "        mpn = multiObjects(column[i],key)\n",
        "        lineLst.append(mpn)\n",
        "    return lineLst\n",
        "    \n",
        "# Damerau–Levenshtein distance similarity function for normalized strings. Caluculates the Damerau–Levenshtein distance between two strings\n",
        "# Then caluclates the similarity dividing the Damerau–Levenshtein distance over the length of the first argument (string)\n",
        "# Returns 0 if any of the strings in the function arguments is None\n",
        "# Version 1.1: 2020-04-10\n",
        "# Returns Damerau–Levenshtein distance similarity [0-1]\n",
        "\n",
        "def DL (x,y):\n",
        "    if x is None or y is None:\n",
        "        return 0\n",
        "    else:\n",
        "        x = norm (x)\n",
        "        y = norm (y)\n",
        "        #return (1-(damerau_levenshtein (x,y)/len(x)))\n",
        "        return abs((1-(damerau_levenshtein (x,y)/len(x))))\n",
        "    \n",
        "# Calculates the DL for ten (10) pair attributes of a data set, and adds the label and stores them in a matrix [n,11] where n,11 is the label to identify if the reord is duplicated\n",
        "# Returns the matrix with the calucalted DL result for each pair of attributes.\n",
        "# Special Note: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Version 1.3: 2020-04-25\n",
        "\n",
        "    \n",
        "\n",
        "def DLM1 (dset,\n",
        "          left1,right1,\n",
        "          left2,right2,\n",
        "          left3,right3,\n",
        "          left4,right4,\n",
        "          left5,right5,\n",
        "          left6,right6,\n",
        "          left7,right7,\n",
        "          left8,right8,\n",
        "          left9,right9,\n",
        "          left10,right10,\n",
        "          label):\n",
        "    rows=len(dset)\n",
        "    #matrix1 = np.array(np.zeros(rows*11).reshape(rows,11),dtype=object)\n",
        "    matrix1 = np.zeros(rows*11).reshape(rows,11)\n",
        "    for i in range(rows):\n",
        "      if i % 10000 == 0:\n",
        "        print ('row number= ')\n",
        "        print (i)\n",
        "      for j in range(11):\n",
        "            if i % 10000 == 0:\n",
        "                print ('column number= ')\n",
        "                print (j)\n",
        "            if j == 0:\n",
        "                matrix1[i,j] = DL(left1[i],right1[i])\n",
        "            elif j == 1:\n",
        "                matrix1[i,j] = DL(left2[i],right2[i])\n",
        "            elif j == 2:\n",
        "                matrix1[i,j] = DL(left3[i],right3[i])\n",
        "            elif j == 3:\n",
        "                matrix1[i,j] = DL(left4[i],right4[i])\n",
        "            elif j == 4:\n",
        "                matrix1[i,j] = DL(left5[i],right5[i])\n",
        "            elif j == 5:\n",
        "                matrix1[i,j] = DL(left6[i],right6[i])\n",
        "            elif j == 6:\n",
        "                matrix1[i,j] = DL(left7[i],right7[i])\n",
        "            elif j == 7:\n",
        "                matrix1[i,j] = DL(left8[i],right8[i])\n",
        "            elif j == 8:\n",
        "                matrix1[i,j] = DL(left9[i],right9[i])\n",
        "            elif j == 9:\n",
        "                matrix1[i,j] = DL(left10[i],right10[i])\n",
        "            elif j == 10:\n",
        "                matrix1[i,j] = label[i]\n",
        "                \n",
        "    return matrix1\n",
        "    \n",
        "    \n",
        "# Calculates the DL for ten (10) pair attributes of a data set, and adds the pair_id and label and stores them in a matrix [n,12] where n,12 is the BIAS is the number of records\n",
        "# Returns the matrix with the calucalted DL result for each pair of attributes.\n",
        "# Special Note: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Version 1.3: 2020-04-25\n",
        "\n",
        "    \n",
        "\n",
        "def DLM2 (dset,\n",
        "          left1,right1,\n",
        "          left2,right2,\n",
        "          left3,right3,\n",
        "          left4,right4,\n",
        "          left5,right5,\n",
        "          left6,right6,\n",
        "          left7,right7,\n",
        "          left8,right8,\n",
        "          left9,right9,\n",
        "          left10,right10,\n",
        "          pair_id,\n",
        "          label):\n",
        "    rows=len(dset)\n",
        "    matrix1 = np.zeros(rows*12).reshape(rows,12)\n",
        "    for i in range(rows):\n",
        "        for j in range(12):\n",
        "            if j == 0:\n",
        "                matrix1[i,j] = DL(left1[i],right1[i])\n",
        "            elif j == 1:\n",
        "                matrix1[i,j] = DL(left2[i],right2[i])\n",
        "            elif j == 2:\n",
        "                matrix1[i,j] = DL(left3[i],right3[i])\n",
        "            elif j == 3:\n",
        "                matrix1[i,j] = DL(left4[i],right4[i])\n",
        "            elif j == 4:\n",
        "                matrix1[i,j] = DL(left5[i],right5[i])\n",
        "            elif j == 5:\n",
        "                matrix1[i,j] = DL(left6[i],right6[i])\n",
        "            elif j == 6:\n",
        "                matrix1[i,j] = DL(left7[i],right7[i])\n",
        "            elif j == 7:\n",
        "                matrix1[i,j] = DL(left8[i],right8[i])\n",
        "            elif j == 8:\n",
        "                matrix1[i,j] = DL(left9[i],right9[i])\n",
        "            elif j == 9:\n",
        "                matrix1[i,j] = DL(left10[i],right10[i])\n",
        "            elif j == 10:\n",
        "                matrix1[i,j] = pair_id[i]\n",
        "            elif j == 11:\n",
        "                matrix1[i,j] = label[i]\n",
        "                \n",
        "    return matrix1\n",
        "    \n",
        "    \n",
        "# Calculates the DL for ten (10) pair attributes of a data set, and adds the pair_id and label and stores them in a matrix [n,12] where n,12 is the BIAS is the number of records\n",
        "# Returns the matrix with the calucalted DL result for each pair of attributes.\n",
        "# Special Note: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Version 1.3: 2020-04-25\n",
        "\n",
        "    \n",
        "\n",
        "def DLM3 (dset,\n",
        "          left1,right1,\n",
        "          left2,right2,\n",
        "          left3,right3,\n",
        "          left4,right4,\n",
        "          left5,right5,\n",
        "          key1,\n",
        "          key2,\n",
        "          key3,\n",
        "          key4,\n",
        "          key5,\n",
        "          key6,\n",
        "          pair_id,\n",
        "          label):\n",
        "    rows=len(dset)\n",
        "    matrix1 = np.zeros(rows*12).reshape(rows,12)\n",
        "    for i in range(rows):\n",
        "        for j in range(12):\n",
        "            if j == 0:\n",
        "                matrix1[i,j] = DL(left1[i],right1[i])\n",
        "            elif j == 1:\n",
        "                matrix1[i,j] = DL(left2[i],right2[i])\n",
        "            elif j == 2:\n",
        "                matrix1[i,j] = DL(left3[i],right3[i])\n",
        "            elif j == 3:\n",
        "                matrix1[i,j] = DL(left4[i],right4[i])\n",
        "            elif j == 4:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key1)),(multiObjects(right5[i],key1)))\n",
        "            elif j == 5:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key2)),(multiObjects(right5[i],key2)))\n",
        "            elif j == 6:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key3)),(multiObjects(right5[i],key3)))\n",
        "            elif j == 7:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key4)),(multiObjects(right5[i],key4)))\n",
        "            elif j == 8:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key5)),(multiObjects(right5[i],key5)))\n",
        "            elif j == 9:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key6)),(multiObjects(right5[i],key6)))\n",
        "            elif j == 10:\n",
        "                matrix1[i,j] = pair_id[i]\n",
        "            elif j == 11:\n",
        "                matrix1[i,j] = label[i]\n",
        "                \n",
        "    return matrix1\n",
        "\n",
        "\n",
        "# Calculates the Wiki-words-250-with-normalization matrix for two (2) pair attributes of a data set, and adds the label and stores them in a matrix [n,3].\n",
        "# Returns the matrix with the calucalted Word2Vec result for each pair of attributes.\n",
        "# Special Note: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# Version 1.0: 2020-08-09\n",
        "\n",
        "    \n",
        "\n",
        "def W2V_1 (dset,\n",
        "          left1,right1,\n",
        "          label):\n",
        "    rows=len(dset)\n",
        "    #rows=1\n",
        "    matrix1 = np.array(np.zeros(rows*3).reshape(rows,3),dtype=object)\n",
        "    embed = hub.load(\"https://tfhub.dev/google/Wiki-words-250-with-normalization/2\")\n",
        "    for i in range(rows):\n",
        "        for j in range(3):\n",
        "            if j == 0:\n",
        "                matrix1[i,j] = embed([left1[i]])\n",
        "            elif j == 1:\n",
        "                matrix1[i,j] = embed([right1[i]])\n",
        "            elif j == 2:\n",
        "                matrix1[i,j] = label[i]\n",
        "                \n",
        "    return matrix1\n",
        "\n",
        "# Function to create a new Data Frame with selected columns of a data set.\n",
        "# Returns the new data frame / data set with all the required columns of tuple.\n",
        "# Arguments: Data Set\n",
        "# Special Note: This function will only return as part of the new data frame:\n",
        "# Special Note2: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Will bring data from: \"right\" and \"left\" dat set tuple\n",
        "# Version 1.0: 2020-04-24\n",
        "\n",
        "\n",
        "def dataFileAll (df1):\n",
        "    idLeft = df1.id_left\n",
        "    idRight = df1.id_right\n",
        "    brandListLeft = df1.brand_left\n",
        "    brandListRight = df1.brand_right\n",
        "    categoryListLeft = df1.category_left\n",
        "    categoryListRight = df1.category_right\n",
        "    descriptionListLeft = df1.description_left\n",
        "    descriptionListRight = df1.description_right\n",
        "    titleListLeft = df1.title_left\n",
        "    titleListRight = df1.title_right\n",
        "    gtin8ListLeft = identifiersList(df1.identifiers_left,\"/gtin8\")\n",
        "    gtin8ListRight = identifiersList(df1.identifiers_right,\"/gtin8\")\n",
        "    gtin12ListLeft = identifiersList(df1.identifiers_left,\"/gtin12\")\n",
        "    gtin12ListRight = identifiersList(df1.identifiers_right,\"/gtin12\")\n",
        "    gtin13ListLeft = identifiersList(df1.identifiers_left,\"/gtin13\")\n",
        "    gtin13ListRight = identifiersList(df1.identifiers_right,\"/gtin13\")\n",
        "    gtin14ListLeft = identifiersList(df1.identifiers_left,\"/gtin14\")\n",
        "    gtin14ListRight = identifiersList(df1.identifiers_right,\"/gtin14\")\n",
        "    mpnListLeft = identifiersList(df1.identifiers_left,\"/mpn\")\n",
        "    mpnListRight = identifiersList(df1.identifiers_right,\"/mpn\")\n",
        "    skuListLeft = identifiersList(df1.identifiers_left,\"/sku\")\n",
        "    skuListRight = identifiersList(df1.identifiers_right,\"/sku\")\n",
        "    pairIdList = df1.pair_id\n",
        "    labelList = df1.label\n",
        "    \n",
        "    \n",
        "    zipList = list(zip(idLeft\n",
        "                       ,idRight\n",
        "                       ,brandListLeft\n",
        "                       ,brandListRight\n",
        "                       ,categoryListLeft\n",
        "                       ,categoryListRight\n",
        "                       ,descriptionListLeft\n",
        "                       ,descriptionListRight\n",
        "                       ,titleListLeft\n",
        "                       ,titleListRight\n",
        "                       ,gtin8ListLeft\n",
        "                       ,gtin8ListRight\n",
        "                       ,gtin12ListLeft\n",
        "                       ,gtin12ListRight\n",
        "                       ,gtin13ListLeft\n",
        "                       ,gtin13ListRight\n",
        "                       ,gtin14ListLeft\n",
        "                       ,gtin14ListRight\n",
        "                       ,mpnListLeft\n",
        "                       ,mpnListRight\n",
        "                       ,skuListLeft\n",
        "                       ,skuListRight\n",
        "                       ,pairIdList\n",
        "                       ,labelList\n",
        "                      )\n",
        "                  )\n",
        "    dataObjectLeft = pd.DataFrame(zipList ,columns = [\"idLeft\"\n",
        "                       ,\"idRight\"\n",
        "                       ,\"brandListLeft\"\n",
        "                       ,\"brandListRight\"\n",
        "                       ,\"categoryListLeft\"\n",
        "                       ,\"categoryListRight\"\n",
        "                       ,\"descriptionListLeft\"\n",
        "                       ,\"descriptionListRight\"\n",
        "                       ,\"titleListLeft\"\n",
        "                       ,\"titleListRight\"\n",
        "                       ,\"gtin8ListLeft\"\n",
        "                       ,\"gtin8ListRight\"\n",
        "                       ,\"gtin12ListLeft\"\n",
        "                       ,\"gtin12ListRight\"\n",
        "                       ,\"gtin13ListLeft\"\n",
        "                       ,\"gtin13ListRight\"\n",
        "                       ,\"gtin14ListLeft\"\n",
        "                       ,\"gtin14ListRight\"\n",
        "                       ,\"mpnListLeft\"\n",
        "                       ,\"mpnListRight\"\n",
        "                       ,\"skuListLeft\"\n",
        "                       ,\"skuListRight\"\n",
        "                       ,\"pairIdList\"\n",
        "                       ,\"labelList\"])\n",
        "\n",
        "    return dataObjectLeft"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZUrJW8mpgAT"
      },
      "source": [
        "# Initialize prepocess_dataset Word2Vec Matrix with \n",
        "\n",
        "TrainDataSetW2V = W2V_1(TrainDataSet,\n",
        "                     TrainDataSet.title_left,TrainDataSet.title_right,\n",
        "                     TrainDataSet.label)\n",
        "print (\"TrainDataSetW2V\")\n",
        "print (TrainDataSetW2V)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkbJqN6ur7-U"
      },
      "source": [
        "#TestDataSet10W2V save as numpy array npy in binary format\n",
        "np.save('/content/drive/My Drive/Python/20200720_DataAnalysis/TrainDataSetW2V', TrainDataSetW2V)\n",
        "#TrainDataSetW2V load numpy array npy in binary format\n",
        "TrainDataSetW2V = np.load('/content/drive/My Drive/Python/20200720_DataAnalysis/TrainDataSetW2V.npy',mmap_mode=None,allow_pickle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HM9ubuZsDyR"
      },
      "source": [
        "def w2vMatrix501 (npyArray):\n",
        "  rows = len(npyArray[:])\n",
        "  columns = len(npyArray[:][0])\n",
        "  newMatrix = np.array(np.zeros(rows*501).reshape(rows,501))\n",
        "  newMatrix.shape\n",
        "  print (\"rows=%s\" %(rows))\n",
        "  print (\"columns=%s\" %(columns))\n",
        "  for i in range(rows):\n",
        "    #print(\"i=%s\" %(i))\n",
        "    for j in range(columns):\n",
        "      #print(\"j=%s\" %(j))\n",
        "      if j == 2:\n",
        "        newMatrix[i,500] = npyArray[i,j]\n",
        "        #print (\"newMatrix[i,j]=%s\" %(newMatrix[i,j]))\n",
        "        #print (\"npyArray[i,j]=%s\" %(npyArray[i,j]))\n",
        "      else:\n",
        "        for k in range(250):\n",
        "          #print(\"k=%s\" %(k))\n",
        "          if j == 1:\n",
        "            k250=k+250\n",
        "            #print(\"k250=%s\" %(k250))\n",
        "            newMatrix[i,k250] = npyArray[i,j][0,k]\n",
        "            #print (\"newMatrix[i,k250]=%s\" %(newMatrix[0,k250]))\n",
        "            #print (\"npyArray[i,j][0,k]=%s\" %(npyArray[i,j][0,k]))\n",
        "          else:\n",
        "            newMatrix[i,k] = npyArray[i,j][0,k]\n",
        "            #print (\"newMatrix[i,k]=%s\" %(newMatrix[0,k]))\n",
        "            #print (\"npyArray[i,j][0,k]=%s\" %(npyArray[i,j][0,k]))\n",
        "  #print(newMatrix)\n",
        "  return (newMatrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilrKBrKRsMBo"
      },
      "source": [
        "TrainDataSetW2V_501 = w2vMatrix501(TrainDataSetW2V)\n",
        "TrainDataSetW2V_501.shape\n",
        "TrainDataSetW2V_501.dtype\n",
        "print (TrainDataSetW2V_501.shape)\n",
        "print (TrainDataSetW2V_501.dtype)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiwT9WXLsUE1"
      },
      "source": [
        "#TrainDataSetW2V_501 save as numpy array npy in binary format\n",
        "np.save('/content/drive/My Drive/Python/20200720_DataAnalysis/TrainDataSetW2V_501', TrainDataSetW2V_501)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5fQGNdvzEa6"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MABbG_Kgxsy9"
      },
      "source": [
        "# Preprocessing Data Corpus: Preprocessing of TestDataSet.pkl with Word2Vec v2\n",
        "2020-08-17\n",
        "JXHALLO: Preprocessing of TestDataSet.pkl with Word2Vec\n",
        "v2: Applied transformation to create matrix (n,501) for word2vec transformation where:\n",
        "image.png\n",
        "https://tfhub.dev/google/Wiki-words-250-with-normalization/2\n",
        "\n",
        "**Preprocessed Data Set Outputs:**\n",
        "\n",
        "* TestDataSetW2V_501"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9evpyuazN8k"
      },
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBGc4zmuzQFh"
      },
      "source": [
        "# 0.1 - Install whoosh\n",
        "!pip install whoosh\n",
        "# 1- Import Python Libraries\n",
        "import numpy as np\n",
        "import gensim as gs\n",
        "import re as re\n",
        "import string as st\n",
        "import codecs as co\n",
        "import glob as gl\n",
        "import logging as logger\n",
        "import multiprocessing as mult\n",
        "import os as os\n",
        "import pprint as pp\n",
        "import nltk\n",
        "import gensim.models.word2vec as w2v\n",
        "import sklearn.manifold\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import whoosh as ws\n",
        "import random as ra\n",
        "import csv as csv\n",
        "import scipy as sc\n",
        "import json as js\n",
        "import itertools "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9pweVrPzVMK"
      },
      "source": [
        "# 2- Import Python Functions\n",
        "from whoosh.fields import Schema, TEXT, KEYWORD, ID, STORED\n",
        "from whoosh.support.levenshtein import levenshtein\n",
        "from whoosh.support.levenshtein import damerau_levenshtein\n",
        "from IPython.display import clear_output\n",
        "from six.moves import urllib\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import ConfusionMatrixDisplay"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vMZq7a-zZgJ"
      },
      "source": [
        "# 3- Import Python tensorflow library\n",
        "import tensorflow as tf\n",
        "print(tf.version)  # make sure the version is 2.x\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_probability as tfp  # We are using a different module from tensorflow this time\n",
        "import tensorflow.compat.v2.feature_column as fc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USEPFN3pzbof"
      },
      "source": [
        "#2020-08-09 Reading TestDataSet10 using pickle from My drive Google Drive\n",
        "TestDataSet=pd.read_pickle('/content/drive/My Drive/Python/20200720_DataAnalysis/TestDataSet.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3yFIeWnzeDL"
      },
      "source": [
        "print (\"TestDataSet.shape\")\n",
        "print (TestDataSet.shape)\n",
        "print (\"TestDataSet.dtypes\")\n",
        "print (TestDataSet.dtypes)\n",
        "print (\"TestDataSet.isnull().sum()\")\n",
        "print (TestDataSet.isnull().sum())\n",
        "TestDataSet = TestDataSet.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3Fx-3jmz0kG"
      },
      "source": [
        "# 3- JXHALLO Personal Functions for Code\n",
        "\n",
        "# String Normalizer\n",
        "# Version 1.0: 2020-04-10\n",
        "# Returns normalized string without spaces and special characters using RegEx. Then sets lower case\n",
        "\n",
        "def norm (x):\n",
        "    return re.sub(r\"\\s|[^a-z0-9]\",\"\",x.lower(), flags=re.IGNORECASE)\n",
        "\n",
        "# String Exact Comparison\n",
        "# Version 1.0: 2020-04-10\n",
        "# Returns boolean if string comparison is exact.\n",
        "\n",
        "def exact(a,b):\n",
        "    if a is b:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "# Function to access a specific value within an object list\n",
        "# Returns the value of the record with the corresponding key.\n",
        "# Arguments: object that contain the list of keys and values, the key that you want to match to return the value\n",
        "# Special Note: This function will only return the first value of the list.\n",
        "# Special Note2: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Version 1.2: 2020-04-17\n",
        "\n",
        "def multiObjects(values,key):\n",
        "    val = None\n",
        "    for i in range(len(values)):\n",
        "        data = values[i]\n",
        "        for (k, v) in data.items():\n",
        "            if k == key:\n",
        "                val = list(v.split(\", \"))[0].replace(\"[\",\"\").replace(\"]\",\"\").strip()\n",
        "    return val\n",
        "    \n",
        "# Function to access a specific value within an object list\n",
        "# Returns the value of the record of the corresponding key.\n",
        "# Arguments: object that contain the list of keys and values, the key that you want to match to return the value\n",
        "# Special Note: This function will only return the first value of the list.\n",
        "# Special Note2: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Version 1.0: 2020-04-24\n",
        "\n",
        "def identifiersList (column,key):\n",
        "    lineLst = []\n",
        "    for i in range (len(column)):\n",
        "        mpn = multiObjects(column[i],key)\n",
        "        lineLst.append(mpn)\n",
        "    return lineLst\n",
        "    \n",
        "# Damerau–Levenshtein distance similarity function for normalized strings. Caluculates the Damerau–Levenshtein distance between two strings\n",
        "# Then caluclates the similarity dividing the Damerau–Levenshtein distance over the length of the first argument (string)\n",
        "# Returns 0 if any of the strings in the function arguments is None\n",
        "# Version 1.1: 2020-04-10\n",
        "# Returns Damerau–Levenshtein distance similarity [0-1]\n",
        "\n",
        "def DL (x,y):\n",
        "    if x is None or y is None:\n",
        "        return 0\n",
        "    else:\n",
        "        x = norm (x)\n",
        "        y = norm (y)\n",
        "        #return (1-(damerau_levenshtein (x,y)/len(x)))\n",
        "        return abs((1-(damerau_levenshtein (x,y)/len(x))))\n",
        "    \n",
        "# Calculates the DL for ten (10) pair attributes of a data set, and adds the label and stores them in a matrix [n,11] where n,11 is the label to identify if the reord is duplicated\n",
        "# Returns the matrix with the calucalted DL result for each pair of attributes.\n",
        "# Special Note: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Version 1.3: 2020-04-25\n",
        "\n",
        "    \n",
        "\n",
        "def DLM1 (dset,\n",
        "          left1,right1,\n",
        "          left2,right2,\n",
        "          left3,right3,\n",
        "          left4,right4,\n",
        "          left5,right5,\n",
        "          left6,right6,\n",
        "          left7,right7,\n",
        "          left8,right8,\n",
        "          left9,right9,\n",
        "          left10,right10,\n",
        "          label):\n",
        "    rows=len(dset)\n",
        "    #matrix1 = np.array(np.zeros(rows*11).reshape(rows,11),dtype=object)\n",
        "    matrix1 = np.zeros(rows*11).reshape(rows,11)\n",
        "    for i in range(rows):\n",
        "      if i % 10000 == 0:\n",
        "        print ('row number= ')\n",
        "        print (i)\n",
        "      for j in range(11):\n",
        "            if i % 10000 == 0:\n",
        "                print ('column number= ')\n",
        "                print (j)\n",
        "            if j == 0:\n",
        "                matrix1[i,j] = DL(left1[i],right1[i])\n",
        "            elif j == 1:\n",
        "                matrix1[i,j] = DL(left2[i],right2[i])\n",
        "            elif j == 2:\n",
        "                matrix1[i,j] = DL(left3[i],right3[i])\n",
        "            elif j == 3:\n",
        "                matrix1[i,j] = DL(left4[i],right4[i])\n",
        "            elif j == 4:\n",
        "                matrix1[i,j] = DL(left5[i],right5[i])\n",
        "            elif j == 5:\n",
        "                matrix1[i,j] = DL(left6[i],right6[i])\n",
        "            elif j == 6:\n",
        "                matrix1[i,j] = DL(left7[i],right7[i])\n",
        "            elif j == 7:\n",
        "                matrix1[i,j] = DL(left8[i],right8[i])\n",
        "            elif j == 8:\n",
        "                matrix1[i,j] = DL(left9[i],right9[i])\n",
        "            elif j == 9:\n",
        "                matrix1[i,j] = DL(left10[i],right10[i])\n",
        "            elif j == 10:\n",
        "                matrix1[i,j] = label[i]\n",
        "                \n",
        "    return matrix1\n",
        "    \n",
        "    \n",
        "# Calculates the DL for ten (10) pair attributes of a data set, and adds the pair_id and label and stores them in a matrix [n,12] where n,12 is the BIAS is the number of records\n",
        "# Returns the matrix with the calucalted DL result for each pair of attributes.\n",
        "# Special Note: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Version 1.3: 2020-04-25\n",
        "\n",
        "    \n",
        "\n",
        "def DLM2 (dset,\n",
        "          left1,right1,\n",
        "          left2,right2,\n",
        "          left3,right3,\n",
        "          left4,right4,\n",
        "          left5,right5,\n",
        "          left6,right6,\n",
        "          left7,right7,\n",
        "          left8,right8,\n",
        "          left9,right9,\n",
        "          left10,right10,\n",
        "          pair_id,\n",
        "          label):\n",
        "    rows=len(dset)\n",
        "    matrix1 = np.zeros(rows*12).reshape(rows,12)\n",
        "    for i in range(rows):\n",
        "        for j in range(12):\n",
        "            if j == 0:\n",
        "                matrix1[i,j] = DL(left1[i],right1[i])\n",
        "            elif j == 1:\n",
        "                matrix1[i,j] = DL(left2[i],right2[i])\n",
        "            elif j == 2:\n",
        "                matrix1[i,j] = DL(left3[i],right3[i])\n",
        "            elif j == 3:\n",
        "                matrix1[i,j] = DL(left4[i],right4[i])\n",
        "            elif j == 4:\n",
        "                matrix1[i,j] = DL(left5[i],right5[i])\n",
        "            elif j == 5:\n",
        "                matrix1[i,j] = DL(left6[i],right6[i])\n",
        "            elif j == 6:\n",
        "                matrix1[i,j] = DL(left7[i],right7[i])\n",
        "            elif j == 7:\n",
        "                matrix1[i,j] = DL(left8[i],right8[i])\n",
        "            elif j == 8:\n",
        "                matrix1[i,j] = DL(left9[i],right9[i])\n",
        "            elif j == 9:\n",
        "                matrix1[i,j] = DL(left10[i],right10[i])\n",
        "            elif j == 10:\n",
        "                matrix1[i,j] = pair_id[i]\n",
        "            elif j == 11:\n",
        "                matrix1[i,j] = label[i]\n",
        "                \n",
        "    return matrix1\n",
        "    \n",
        "    \n",
        "# Calculates the DL for ten (10) pair attributes of a data set, and adds the pair_id and label and stores them in a matrix [n,12] where n,12 is the BIAS is the number of records\n",
        "# Returns the matrix with the calucalted DL result for each pair of attributes.\n",
        "# Special Note: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Version 1.3: 2020-04-25\n",
        "\n",
        "    \n",
        "\n",
        "def DLM3 (dset,\n",
        "          left1,right1,\n",
        "          left2,right2,\n",
        "          left3,right3,\n",
        "          left4,right4,\n",
        "          left5,right5,\n",
        "          key1,\n",
        "          key2,\n",
        "          key3,\n",
        "          key4,\n",
        "          key5,\n",
        "          key6,\n",
        "          pair_id,\n",
        "          label):\n",
        "    rows=len(dset)\n",
        "    matrix1 = np.zeros(rows*12).reshape(rows,12)\n",
        "    for i in range(rows):\n",
        "        for j in range(12):\n",
        "            if j == 0:\n",
        "                matrix1[i,j] = DL(left1[i],right1[i])\n",
        "            elif j == 1:\n",
        "                matrix1[i,j] = DL(left2[i],right2[i])\n",
        "            elif j == 2:\n",
        "                matrix1[i,j] = DL(left3[i],right3[i])\n",
        "            elif j == 3:\n",
        "                matrix1[i,j] = DL(left4[i],right4[i])\n",
        "            elif j == 4:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key1)),(multiObjects(right5[i],key1)))\n",
        "            elif j == 5:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key2)),(multiObjects(right5[i],key2)))\n",
        "            elif j == 6:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key3)),(multiObjects(right5[i],key3)))\n",
        "            elif j == 7:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key4)),(multiObjects(right5[i],key4)))\n",
        "            elif j == 8:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key5)),(multiObjects(right5[i],key5)))\n",
        "            elif j == 9:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key6)),(multiObjects(right5[i],key6)))\n",
        "            elif j == 10:\n",
        "                matrix1[i,j] = pair_id[i]\n",
        "            elif j == 11:\n",
        "                matrix1[i,j] = label[i]\n",
        "                \n",
        "    return matrix1\n",
        "\n",
        "\n",
        "# Calculates the Wiki-words-250-with-normalization matrix for two (2) pair attributes of a data set, and adds the label and stores them in a matrix [n,3].\n",
        "# Returns the matrix with the calucalted Word2Vec result for each pair of attributes.\n",
        "# Special Note: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# Version 1.0: 2020-08-09\n",
        "\n",
        "    \n",
        "\n",
        "def W2V_1 (dset,\n",
        "          left1,right1,\n",
        "          label):\n",
        "    rows=len(dset)\n",
        "    #rows=1\n",
        "    matrix1 = np.array(np.zeros(rows*3).reshape(rows,3),dtype=object)\n",
        "    embed = hub.load(\"https://tfhub.dev/google/Wiki-words-250-with-normalization/2\")\n",
        "    for i in range(rows):\n",
        "        for j in range(3):\n",
        "            if j == 0:\n",
        "                matrix1[i,j] = embed([left1[i]])\n",
        "            elif j == 1:\n",
        "                matrix1[i,j] = embed([right1[i]])\n",
        "            elif j == 2:\n",
        "                matrix1[i,j] = label[i]\n",
        "                \n",
        "    return matrix1\n",
        "\n",
        "# Function to create a new Data Frame with selected columns of a data set.\n",
        "# Returns the new data frame / data set with all the required columns of tuple.\n",
        "# Arguments: Data Set\n",
        "# Special Note: This function will only return as part of the new data frame:\n",
        "# Special Note2: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Will bring data from: \"right\" and \"left\" dat set tuple\n",
        "# Version 1.0: 2020-04-24\n",
        "\n",
        "\n",
        "def dataFileAll (df1):\n",
        "    idLeft = df1.id_left\n",
        "    idRight = df1.id_right\n",
        "    brandListLeft = df1.brand_left\n",
        "    brandListRight = df1.brand_right\n",
        "    categoryListLeft = df1.category_left\n",
        "    categoryListRight = df1.category_right\n",
        "    descriptionListLeft = df1.description_left\n",
        "    descriptionListRight = df1.description_right\n",
        "    titleListLeft = df1.title_left\n",
        "    titleListRight = df1.title_right\n",
        "    gtin8ListLeft = identifiersList(df1.identifiers_left,\"/gtin8\")\n",
        "    gtin8ListRight = identifiersList(df1.identifiers_right,\"/gtin8\")\n",
        "    gtin12ListLeft = identifiersList(df1.identifiers_left,\"/gtin12\")\n",
        "    gtin12ListRight = identifiersList(df1.identifiers_right,\"/gtin12\")\n",
        "    gtin13ListLeft = identifiersList(df1.identifiers_left,\"/gtin13\")\n",
        "    gtin13ListRight = identifiersList(df1.identifiers_right,\"/gtin13\")\n",
        "    gtin14ListLeft = identifiersList(df1.identifiers_left,\"/gtin14\")\n",
        "    gtin14ListRight = identifiersList(df1.identifiers_right,\"/gtin14\")\n",
        "    mpnListLeft = identifiersList(df1.identifiers_left,\"/mpn\")\n",
        "    mpnListRight = identifiersList(df1.identifiers_right,\"/mpn\")\n",
        "    skuListLeft = identifiersList(df1.identifiers_left,\"/sku\")\n",
        "    skuListRight = identifiersList(df1.identifiers_right,\"/sku\")\n",
        "    pairIdList = df1.pair_id\n",
        "    labelList = df1.label\n",
        "    \n",
        "    \n",
        "    zipList = list(zip(idLeft\n",
        "                       ,idRight\n",
        "                       ,brandListLeft\n",
        "                       ,brandListRight\n",
        "                       ,categoryListLeft\n",
        "                       ,categoryListRight\n",
        "                       ,descriptionListLeft\n",
        "                       ,descriptionListRight\n",
        "                       ,titleListLeft\n",
        "                       ,titleListRight\n",
        "                       ,gtin8ListLeft\n",
        "                       ,gtin8ListRight\n",
        "                       ,gtin12ListLeft\n",
        "                       ,gtin12ListRight\n",
        "                       ,gtin13ListLeft\n",
        "                       ,gtin13ListRight\n",
        "                       ,gtin14ListLeft\n",
        "                       ,gtin14ListRight\n",
        "                       ,mpnListLeft\n",
        "                       ,mpnListRight\n",
        "                       ,skuListLeft\n",
        "                       ,skuListRight\n",
        "                       ,pairIdList\n",
        "                       ,labelList\n",
        "                      )\n",
        "                  )\n",
        "    dataObjectLeft = pd.DataFrame(zipList ,columns = [\"idLeft\"\n",
        "                       ,\"idRight\"\n",
        "                       ,\"brandListLeft\"\n",
        "                       ,\"brandListRight\"\n",
        "                       ,\"categoryListLeft\"\n",
        "                       ,\"categoryListRight\"\n",
        "                       ,\"descriptionListLeft\"\n",
        "                       ,\"descriptionListRight\"\n",
        "                       ,\"titleListLeft\"\n",
        "                       ,\"titleListRight\"\n",
        "                       ,\"gtin8ListLeft\"\n",
        "                       ,\"gtin8ListRight\"\n",
        "                       ,\"gtin12ListLeft\"\n",
        "                       ,\"gtin12ListRight\"\n",
        "                       ,\"gtin13ListLeft\"\n",
        "                       ,\"gtin13ListRight\"\n",
        "                       ,\"gtin14ListLeft\"\n",
        "                       ,\"gtin14ListRight\"\n",
        "                       ,\"mpnListLeft\"\n",
        "                       ,\"mpnListRight\"\n",
        "                       ,\"skuListLeft\"\n",
        "                       ,\"skuListRight\"\n",
        "                       ,\"pairIdList\"\n",
        "                       ,\"labelList\"])\n",
        "\n",
        "    return dataObjectLeft"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyfqHV2Nz4xx"
      },
      "source": [
        "# Initialize prepocess_dataset Word2Vec Matrix with \n",
        "\n",
        "TestDataSetW2V = W2V_1(TestDataSet,\n",
        "                     TestDataSet.title_left,TestDataSet.title_right,\n",
        "                     TestDataSet.label)\n",
        "print (\"TestDataSetW2V\")\n",
        "print (TestDataSetW2V)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCmdYz-7z7CH"
      },
      "source": [
        "#TestDataSetW2V save as numpy array npy in binary format\n",
        "np.save('/content/drive/My Drive/Python/20200720_DataAnalysis/TestDataSetW2V', TestDataSetW2V)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQGlukjF0BfL"
      },
      "source": [
        "#TestDataSetW2V load numpy array npy in binary format\n",
        "TestDataSetW2V = np.load('/content/drive/My Drive/Python/20200720_DataAnalysis/TestDataSetW2V.npy',mmap_mode=None,allow_pickle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXuHSaQf0DxQ"
      },
      "source": [
        "print (TestDataSetW2V.shape)\n",
        "print (TestDataSetW2V.dtype)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fnMXUsO0FhN"
      },
      "source": [
        "def w2vMatrix501 (npyArray):\n",
        "  rows = len(npyArray[:])\n",
        "  columns = len(npyArray[:][0])\n",
        "  newMatrix = np.array(np.zeros(rows*501).reshape(rows,501))\n",
        "  newMatrix.shape\n",
        "  print (\"rows=%s\" %(rows))\n",
        "  print (\"columns=%s\" %(columns))\n",
        "  for i in range(rows):\n",
        "    #print(\"i=%s\" %(i))\n",
        "    for j in range(columns):\n",
        "      #print(\"j=%s\" %(j))\n",
        "      if j == 2:\n",
        "        newMatrix[i,500] = npyArray[i,j]\n",
        "        #print (\"newMatrix[i,j]=%s\" %(newMatrix[i,j]))\n",
        "        #print (\"npyArray[i,j]=%s\" %(npyArray[i,j]))\n",
        "      else:\n",
        "        for k in range(250):\n",
        "          #print(\"k=%s\" %(k))\n",
        "          if j == 1:\n",
        "            k250=k+250\n",
        "            #print(\"k250=%s\" %(k250))\n",
        "            newMatrix[i,k250] = npyArray[i,j][0,k]\n",
        "            #print (\"newMatrix[i,k250]=%s\" %(newMatrix[0,k250]))\n",
        "            #print (\"npyArray[i,j][0,k]=%s\" %(npyArray[i,j][0,k]))\n",
        "          else:\n",
        "            newMatrix[i,k] = npyArray[i,j][0,k]\n",
        "            #print (\"newMatrix[i,k]=%s\" %(newMatrix[0,k]))\n",
        "            #print (\"npyArray[i,j][0,k]=%s\" %(npyArray[i,j][0,k]))\n",
        "  #print(newMatrix)\n",
        "  return (newMatrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6fPgDEC0HtI"
      },
      "source": [
        "TestDataSetW2V_501 = w2vMatrix501(TestDataSetW2V)\n",
        "TestDataSetW2V_501.shape\n",
        "TestDataSetW2V_501.dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5eSZaOn0KOr"
      },
      "source": [
        "print (TestDataSetW2V_501.shape)\n",
        "print (TestDataSetW2V_501.dtype)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1U9ds9Jm0MEc"
      },
      "source": [
        "#TestDataSet10W2V_501 save as numpy array npy in binary format\n",
        "np.save('/content/drive/My Drive/Python/20200720_DataAnalysis/TestDataSetW2V_501', TestDataSetW2V_501)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5V-ELxPHGfN9"
      },
      "source": [
        "# Preprocessing Data Corpus: Preprocessing of all_gsDataSet.pkl with Word2Vec v2\n",
        "2020-08-17 JXHALLO: Preprocessing of TrainDataSet.pkl with Word2Vec\n",
        "v2: Applied transformation to create matrix (n,501) for word2vec transformation where:\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "https://tfhub.dev/google/Wiki-words-250-with-normalization/2\n",
        "\n",
        "**Preprocessed Data Set Outputs:**\n",
        "\n",
        "* all_gsDataSetW2V_501\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6DKRmg1kM3O"
      },
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQ48fjWwjtUp"
      },
      "source": [
        "# 0.1 - Install whoosh\n",
        "!pip install whoosh\n",
        "# 1- Import Python Libraries\n",
        "import numpy as np\n",
        "import gensim as gs\n",
        "import re as re\n",
        "import string as st\n",
        "import codecs as co\n",
        "import glob as gl\n",
        "import logging as logger\n",
        "import multiprocessing as mult\n",
        "import os as os\n",
        "import pprint as pp\n",
        "import nltk\n",
        "import gensim.models.word2vec as w2v\n",
        "import sklearn.manifold\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import whoosh as ws\n",
        "import random as ra\n",
        "import csv as csv\n",
        "import scipy as sc\n",
        "import json as js\n",
        "import itertools \n",
        "# 2- Import Python Functions\n",
        "from whoosh.fields import Schema, TEXT, KEYWORD, ID, STORED\n",
        "from whoosh.support.levenshtein import levenshtein\n",
        "from whoosh.support.levenshtein import damerau_levenshtein\n",
        "from IPython.display import clear_output\n",
        "from six.moves import urllib\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "# 3- Import Python tensorflow library\n",
        "import tensorflow as tf\n",
        "print(tf.version)  # make sure the version is 2.x\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_probability as tfp  # We are using a different module from tensorflow this time\n",
        "import tensorflow.compat.v2.feature_column as fc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0c1_LqwFkhzQ"
      },
      "source": [
        "#2020-08-17 Reading all_gs.jason using pd.read_json from My drive Google Drive\n",
        "\n",
        "url = \"/content/drive/My Drive/Python/Corpus/all_gs.json\"\n",
        "\n",
        "all_gsDataSet = pd.read_json(url,lines=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQ5Eutc8R-Z6"
      },
      "source": [
        "print (\"all_gsDataSet.shape\")\n",
        "print (all_gsDataSet.shape)\n",
        "print (\"all_gsDataSet.dtypes\")\n",
        "print (all_gsDataSet.dtypes)\n",
        "print (\"all_gsDataSet.isnull().sum()\")\n",
        "print (all_gsDataSet.isnull().sum())\n",
        "all_gsDataSet = all_gsDataSet.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOWqclzQk35R"
      },
      "source": [
        "all_gsDataSet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZ2eUWKo1qBM"
      },
      "source": [
        "# 3- JXHALLO Personal Functions for Code\n",
        "\n",
        "# String Normalizer\n",
        "# Version 1.0: 2020-04-10\n",
        "# Returns normalized string without spaces and special characters using RegEx. Then sets lower case\n",
        "\n",
        "def norm (x):\n",
        "    return re.sub(r\"\\s|[^a-z0-9]\",\"\",x.lower(), flags=re.IGNORECASE)\n",
        "\n",
        "# String Exact Comparison\n",
        "# Version 1.0: 2020-04-10\n",
        "# Returns boolean if string comparison is exact.\n",
        "\n",
        "def exact(a,b):\n",
        "    if a is b:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "# Function to access a specific value within an object list\n",
        "# Returns the value of the record with the corresponding key.\n",
        "# Arguments: object that contain the list of keys and values, the key that you want to match to return the value\n",
        "# Special Note: This function will only return the first value of the list.\n",
        "# Special Note2: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Version 1.2: 2020-04-17\n",
        "\n",
        "def multiObjects(values,key):\n",
        "    val = None\n",
        "    for i in range(len(values)):\n",
        "        data = values[i]\n",
        "        for (k, v) in data.items():\n",
        "            if k == key:\n",
        "                val = list(v.split(\", \"))[0].replace(\"[\",\"\").replace(\"]\",\"\").strip()\n",
        "    return val\n",
        "    \n",
        "# Function to access a specific value within an object list\n",
        "# Returns the value of the record of the corresponding key.\n",
        "# Arguments: object that contain the list of keys and values, the key that you want to match to return the value\n",
        "# Special Note: This function will only return the first value of the list.\n",
        "# Special Note2: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Version 1.0: 2020-04-24\n",
        "\n",
        "def identifiersList (column,key):\n",
        "    lineLst = []\n",
        "    for i in range (len(column)):\n",
        "        mpn = multiObjects(column[i],key)\n",
        "        lineLst.append(mpn)\n",
        "    return lineLst\n",
        "    \n",
        "# Damerau–Levenshtein distance similarity function for normalized strings. Caluculates the Damerau–Levenshtein distance between two strings\n",
        "# Then caluclates the similarity dividing the Damerau–Levenshtein distance over the length of the first argument (string)\n",
        "# Returns 0 if any of the strings in the function arguments is None\n",
        "# Version 1.1: 2020-04-10\n",
        "# Returns Damerau–Levenshtein distance similarity [0-1]\n",
        "\n",
        "def DL (x,y):\n",
        "    if x is None or y is None:\n",
        "        return 0\n",
        "    else:\n",
        "        x = norm (x)\n",
        "        y = norm (y)\n",
        "        #return (1-(damerau_levenshtein (x,y)/len(x)))\n",
        "        return abs((1-(damerau_levenshtein (x,y)/len(x))))\n",
        "    \n",
        "# Calculates the DL for ten (10) pair attributes of a data set, and adds the label and stores them in a matrix [n,11] where n,11 is the label to identify if the reord is duplicated\n",
        "# Returns the matrix with the calucalted DL result for each pair of attributes.\n",
        "# Special Note: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Version 1.3: 2020-04-25\n",
        "\n",
        "    \n",
        "\n",
        "def DLM1 (dset,\n",
        "          left1,right1,\n",
        "          left2,right2,\n",
        "          left3,right3,\n",
        "          left4,right4,\n",
        "          left5,right5,\n",
        "          left6,right6,\n",
        "          left7,right7,\n",
        "          left8,right8,\n",
        "          left9,right9,\n",
        "          left10,right10,\n",
        "          label):\n",
        "    rows=len(dset)\n",
        "    #matrix1 = np.array(np.zeros(rows*11).reshape(rows,11),dtype=object)\n",
        "    matrix1 = np.zeros(rows*11).reshape(rows,11)\n",
        "    for i in range(rows):\n",
        "      if i % 10000 == 0:\n",
        "        print ('row number= ')\n",
        "        print (i)\n",
        "      for j in range(11):\n",
        "            if i % 10000 == 0:\n",
        "                print ('column number= ')\n",
        "                print (j)\n",
        "            if j == 0:\n",
        "                matrix1[i,j] = DL(left1[i],right1[i])\n",
        "            elif j == 1:\n",
        "                matrix1[i,j] = DL(left2[i],right2[i])\n",
        "            elif j == 2:\n",
        "                matrix1[i,j] = DL(left3[i],right3[i])\n",
        "            elif j == 3:\n",
        "                matrix1[i,j] = DL(left4[i],right4[i])\n",
        "            elif j == 4:\n",
        "                matrix1[i,j] = DL(left5[i],right5[i])\n",
        "            elif j == 5:\n",
        "                matrix1[i,j] = DL(left6[i],right6[i])\n",
        "            elif j == 6:\n",
        "                matrix1[i,j] = DL(left7[i],right7[i])\n",
        "            elif j == 7:\n",
        "                matrix1[i,j] = DL(left8[i],right8[i])\n",
        "            elif j == 8:\n",
        "                matrix1[i,j] = DL(left9[i],right9[i])\n",
        "            elif j == 9:\n",
        "                matrix1[i,j] = DL(left10[i],right10[i])\n",
        "            elif j == 10:\n",
        "                matrix1[i,j] = label[i]\n",
        "                \n",
        "    return matrix1\n",
        "    \n",
        "    \n",
        "# Calculates the DL for ten (10) pair attributes of a data set, and adds the pair_id and label and stores them in a matrix [n,12] where n,12 is the BIAS is the number of records\n",
        "# Returns the matrix with the calucalted DL result for each pair of attributes.\n",
        "# Special Note: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Version 1.3: 2020-04-25\n",
        "\n",
        "    \n",
        "\n",
        "def DLM2 (dset,\n",
        "          left1,right1,\n",
        "          left2,right2,\n",
        "          left3,right3,\n",
        "          left4,right4,\n",
        "          left5,right5,\n",
        "          left6,right6,\n",
        "          left7,right7,\n",
        "          left8,right8,\n",
        "          left9,right9,\n",
        "          left10,right10,\n",
        "          pair_id,\n",
        "          label):\n",
        "    rows=len(dset)\n",
        "    matrix1 = np.zeros(rows*12).reshape(rows,12)\n",
        "    for i in range(rows):\n",
        "        for j in range(12):\n",
        "            if j == 0:\n",
        "                matrix1[i,j] = DL(left1[i],right1[i])\n",
        "            elif j == 1:\n",
        "                matrix1[i,j] = DL(left2[i],right2[i])\n",
        "            elif j == 2:\n",
        "                matrix1[i,j] = DL(left3[i],right3[i])\n",
        "            elif j == 3:\n",
        "                matrix1[i,j] = DL(left4[i],right4[i])\n",
        "            elif j == 4:\n",
        "                matrix1[i,j] = DL(left5[i],right5[i])\n",
        "            elif j == 5:\n",
        "                matrix1[i,j] = DL(left6[i],right6[i])\n",
        "            elif j == 6:\n",
        "                matrix1[i,j] = DL(left7[i],right7[i])\n",
        "            elif j == 7:\n",
        "                matrix1[i,j] = DL(left8[i],right8[i])\n",
        "            elif j == 8:\n",
        "                matrix1[i,j] = DL(left9[i],right9[i])\n",
        "            elif j == 9:\n",
        "                matrix1[i,j] = DL(left10[i],right10[i])\n",
        "            elif j == 10:\n",
        "                matrix1[i,j] = pair_id[i]\n",
        "            elif j == 11:\n",
        "                matrix1[i,j] = label[i]\n",
        "                \n",
        "    return matrix1\n",
        "    \n",
        "    \n",
        "# Calculates the DL for ten (10) pair attributes of a data set, and adds the pair_id and label and stores them in a matrix [n,12] where n,12 is the BIAS is the number of records\n",
        "# Returns the matrix with the calucalted DL result for each pair of attributes.\n",
        "# Special Note: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Version 1.3: 2020-04-25\n",
        "\n",
        "    \n",
        "\n",
        "def DLM3 (dset,\n",
        "          left1,right1,\n",
        "          left2,right2,\n",
        "          left3,right3,\n",
        "          left4,right4,\n",
        "          left5,right5,\n",
        "          key1,\n",
        "          key2,\n",
        "          key3,\n",
        "          key4,\n",
        "          key5,\n",
        "          key6,\n",
        "          pair_id,\n",
        "          label):\n",
        "    rows=len(dset)\n",
        "    matrix1 = np.zeros(rows*12).reshape(rows,12)\n",
        "    for i in range(rows):\n",
        "        for j in range(12):\n",
        "            if j == 0:\n",
        "                matrix1[i,j] = DL(left1[i],right1[i])\n",
        "            elif j == 1:\n",
        "                matrix1[i,j] = DL(left2[i],right2[i])\n",
        "            elif j == 2:\n",
        "                matrix1[i,j] = DL(left3[i],right3[i])\n",
        "            elif j == 3:\n",
        "                matrix1[i,j] = DL(left4[i],right4[i])\n",
        "            elif j == 4:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key1)),(multiObjects(right5[i],key1)))\n",
        "            elif j == 5:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key2)),(multiObjects(right5[i],key2)))\n",
        "            elif j == 6:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key3)),(multiObjects(right5[i],key3)))\n",
        "            elif j == 7:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key4)),(multiObjects(right5[i],key4)))\n",
        "            elif j == 8:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key5)),(multiObjects(right5[i],key5)))\n",
        "            elif j == 9:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key6)),(multiObjects(right5[i],key6)))\n",
        "            elif j == 10:\n",
        "                matrix1[i,j] = pair_id[i]\n",
        "            elif j == 11:\n",
        "                matrix1[i,j] = label[i]\n",
        "                \n",
        "    return matrix1\n",
        "\n",
        "\n",
        "# Calculates the Wiki-words-250-with-normalization matrix for two (2) pair attributes of a data set, and adds the label and stores them in a matrix [n,3].\n",
        "# Returns the matrix with the calucalted Word2Vec result for each pair of attributes.\n",
        "# Special Note: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# Version 1.0: 2020-08-09\n",
        "\n",
        "    \n",
        "\n",
        "def W2V_1 (dset,\n",
        "          left1,right1,\n",
        "          label):\n",
        "    rows=len(dset)\n",
        "    #rows=1\n",
        "    matrix1 = np.array(np.zeros(rows*3).reshape(rows,3),dtype=object)\n",
        "    embed = hub.load(\"https://tfhub.dev/google/Wiki-words-250-with-normalization/2\")\n",
        "    for i in range(rows):\n",
        "        for j in range(3):\n",
        "            if j == 0:\n",
        "                matrix1[i,j] = embed([left1[i]])\n",
        "            elif j == 1:\n",
        "                matrix1[i,j] = embed([right1[i]])\n",
        "            elif j == 2:\n",
        "                matrix1[i,j] = label[i]\n",
        "                \n",
        "    return matrix1\n",
        "\n",
        "# Function to create a new Data Frame with selected columns of a data set.\n",
        "# Returns the new data frame / data set with all the required columns of tuple.\n",
        "# Arguments: Data Set\n",
        "# Special Note: This function will only return as part of the new data frame:\n",
        "# Special Note2: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Will bring data from: \"right\" and \"left\" dat set tuple\n",
        "# Version 1.0: 2020-04-24\n",
        "\n",
        "\n",
        "def dataFileAll (df1):\n",
        "    idLeft = df1.id_left\n",
        "    idRight = df1.id_right\n",
        "    brandListLeft = df1.brand_left\n",
        "    brandListRight = df1.brand_right\n",
        "    categoryListLeft = df1.category_left\n",
        "    categoryListRight = df1.category_right\n",
        "    descriptionListLeft = df1.description_left\n",
        "    descriptionListRight = df1.description_right\n",
        "    titleListLeft = df1.title_left\n",
        "    titleListRight = df1.title_right\n",
        "    gtin8ListLeft = identifiersList(df1.identifiers_left,\"/gtin8\")\n",
        "    gtin8ListRight = identifiersList(df1.identifiers_right,\"/gtin8\")\n",
        "    gtin12ListLeft = identifiersList(df1.identifiers_left,\"/gtin12\")\n",
        "    gtin12ListRight = identifiersList(df1.identifiers_right,\"/gtin12\")\n",
        "    gtin13ListLeft = identifiersList(df1.identifiers_left,\"/gtin13\")\n",
        "    gtin13ListRight = identifiersList(df1.identifiers_right,\"/gtin13\")\n",
        "    gtin14ListLeft = identifiersList(df1.identifiers_left,\"/gtin14\")\n",
        "    gtin14ListRight = identifiersList(df1.identifiers_right,\"/gtin14\")\n",
        "    mpnListLeft = identifiersList(df1.identifiers_left,\"/mpn\")\n",
        "    mpnListRight = identifiersList(df1.identifiers_right,\"/mpn\")\n",
        "    skuListLeft = identifiersList(df1.identifiers_left,\"/sku\")\n",
        "    skuListRight = identifiersList(df1.identifiers_right,\"/sku\")\n",
        "    pairIdList = df1.pair_id\n",
        "    labelList = df1.label\n",
        "    \n",
        "    \n",
        "    zipList = list(zip(idLeft\n",
        "                       ,idRight\n",
        "                       ,brandListLeft\n",
        "                       ,brandListRight\n",
        "                       ,categoryListLeft\n",
        "                       ,categoryListRight\n",
        "                       ,descriptionListLeft\n",
        "                       ,descriptionListRight\n",
        "                       ,titleListLeft\n",
        "                       ,titleListRight\n",
        "                       ,gtin8ListLeft\n",
        "                       ,gtin8ListRight\n",
        "                       ,gtin12ListLeft\n",
        "                       ,gtin12ListRight\n",
        "                       ,gtin13ListLeft\n",
        "                       ,gtin13ListRight\n",
        "                       ,gtin14ListLeft\n",
        "                       ,gtin14ListRight\n",
        "                       ,mpnListLeft\n",
        "                       ,mpnListRight\n",
        "                       ,skuListLeft\n",
        "                       ,skuListRight\n",
        "                       ,pairIdList\n",
        "                       ,labelList\n",
        "                      )\n",
        "                  )\n",
        "    dataObjectLeft = pd.DataFrame(zipList ,columns = [\"idLeft\"\n",
        "                       ,\"idRight\"\n",
        "                       ,\"brandListLeft\"\n",
        "                       ,\"brandListRight\"\n",
        "                       ,\"categoryListLeft\"\n",
        "                       ,\"categoryListRight\"\n",
        "                       ,\"descriptionListLeft\"\n",
        "                       ,\"descriptionListRight\"\n",
        "                       ,\"titleListLeft\"\n",
        "                       ,\"titleListRight\"\n",
        "                       ,\"gtin8ListLeft\"\n",
        "                       ,\"gtin8ListRight\"\n",
        "                       ,\"gtin12ListLeft\"\n",
        "                       ,\"gtin12ListRight\"\n",
        "                       ,\"gtin13ListLeft\"\n",
        "                       ,\"gtin13ListRight\"\n",
        "                       ,\"gtin14ListLeft\"\n",
        "                       ,\"gtin14ListRight\"\n",
        "                       ,\"mpnListLeft\"\n",
        "                       ,\"mpnListRight\"\n",
        "                       ,\"skuListLeft\"\n",
        "                       ,\"skuListRight\"\n",
        "                       ,\"pairIdList\"\n",
        "                       ,\"labelList\"])\n",
        "\n",
        "    return dataObjectLeft"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBgn2wVTssH5"
      },
      "source": [
        "all_gsDataSet.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l94zcQG-sxiV"
      },
      "source": [
        "all_gsDataSet.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXHO2UA0s3Ow"
      },
      "source": [
        "all_gsDataSet.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSwjuOZZrnFE"
      },
      "source": [
        "# Initialize prepocess_dataset Word2Vec Matrix with \n",
        "\n",
        "all_gsDataSetW2V = W2V_1(all_gsDataSet,\n",
        "                     all_gsDataSet.title_left,all_gsDataSet.title_right,\n",
        "                     all_gsDataSet.label)\n",
        "print (\"all_gsDataSetW2V\")\n",
        "print (all_gsDataSetW2V)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWUukP963oph"
      },
      "source": [
        "all_gsDataSetW2V.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwrxLqoU8k_R"
      },
      "source": [
        "all_gsDataSetW2V[0,2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLnlc_DM81Ur"
      },
      "source": [
        "all_gsDataSet.label.loc[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njxAbHPgKTrm"
      },
      "source": [
        "all_gsDataSetW2V[0,1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "736CCdGkO-TY"
      },
      "source": [
        "#TestDataSet10W2V save as numpy array npy in binary format\n",
        "np.save('/content/drive/My Drive/Python/20200720_DataAnalysis/all_gsDataSetW2V', all_gsDataSetW2V)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pm26805ccV0L"
      },
      "source": [
        "#TrainDataSetW2V load numpy array npy in binary format\n",
        "all_gsDataSetW2V = np.load('/content/drive/My Drive/Python/20200720_DataAnalysis/all_gsDataSetW2V.npy',mmap_mode=None,allow_pickle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAgoGuhyccya"
      },
      "source": [
        "print (all_gsDataSetW2V.shape)\n",
        "print (all_gsDataSetW2V.dtype)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRCruoCjcdZE"
      },
      "source": [
        "def w2vMatrix501 (npyArray):\n",
        "  rows = len(npyArray[:])\n",
        "  columns = len(npyArray[:][0])\n",
        "  newMatrix = np.array(np.zeros(rows*501).reshape(rows,501))\n",
        "  newMatrix.shape\n",
        "  print (\"rows=%s\" %(rows))\n",
        "  print (\"columns=%s\" %(columns))\n",
        "  for i in range(rows):\n",
        "    #print(\"i=%s\" %(i))\n",
        "    for j in range(columns):\n",
        "      #print(\"j=%s\" %(j))\n",
        "      if j == 2:\n",
        "        newMatrix[i,500] = npyArray[i,j]\n",
        "        #print (\"newMatrix[i,j]=%s\" %(newMatrix[i,j]))\n",
        "        #print (\"npyArray[i,j]=%s\" %(npyArray[i,j]))\n",
        "      else:\n",
        "        for k in range(250):\n",
        "          #print(\"k=%s\" %(k))\n",
        "          if j == 1:\n",
        "            k250=k+250\n",
        "            #print(\"k250=%s\" %(k250))\n",
        "            newMatrix[i,k250] = npyArray[i,j][0,k]\n",
        "            #print (\"newMatrix[i,k250]=%s\" %(newMatrix[0,k250]))\n",
        "            #print (\"npyArray[i,j][0,k]=%s\" %(npyArray[i,j][0,k]))\n",
        "          else:\n",
        "            newMatrix[i,k] = npyArray[i,j][0,k]\n",
        "            #print (\"newMatrix[i,k]=%s\" %(newMatrix[0,k]))\n",
        "            #print (\"npyArray[i,j][0,k]=%s\" %(npyArray[i,j][0,k]))\n",
        "  #print(newMatrix)\n",
        "  return (newMatrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fU_M8bUPcgoa"
      },
      "source": [
        "all_gsDataSetW2V_501 = w2vMatrix501(all_gsDataSetW2V)\n",
        "all_gsDataSetW2V_501.shape\n",
        "all_gsDataSetW2V_501.dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-63eJ4fcjNj"
      },
      "source": [
        "print (all_gsDataSetW2V_501.shape)\n",
        "print (all_gsDataSetW2V_501.dtype)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNuZZurScl7H"
      },
      "source": [
        "all_gsDataSetW2V[4399,2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmvJ6Pq-cnq2"
      },
      "source": [
        "all_gsDataSetW2V[4399,1][0,249]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfXxMBxpcprv"
      },
      "source": [
        "all_gsDataSetW2V_501[4399,500]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYaIshTbcsI3"
      },
      "source": [
        "#TrainDataSetW2V_501 save as numpy array npy in binary format\n",
        "np.save('/content/drive/My Drive/Python/20200720_DataAnalysis/all_gsDataSetW2V_501', all_gsDataSetW2V_501)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iV6a17HnHjrf"
      },
      "source": [
        "# Preprocessing Data Corpus: Preprocessing of TrainDataSet.pkl to Create 90% Hyperparameter Training Data Set with Word2Vec v2\n",
        "2020-11-07 JXHALLO: Preprocessing of TrainDataSet90.pkl with Word2Vec\n",
        "v2: Applied transformation to create matrix (n,501) for word2vec transformation where:\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "https://tfhub.dev/google/Wiki-words-250-with-normalization/2\n",
        "\n",
        "**Preprocessed Data Set Outputs:**\n",
        "\n",
        "* TrainDataSet90W2V_501"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGxYsO4FI0i7"
      },
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwmd_IFWI0i7"
      },
      "source": [
        "# 0.1 - Install whoosh\n",
        "!pip install whoosh\n",
        "# 1- Import Python Libraries\n",
        "import numpy as np\n",
        "import gensim as gs\n",
        "import re as re\n",
        "import string as st\n",
        "import codecs as co\n",
        "import glob as gl\n",
        "import logging as logger\n",
        "import multiprocessing as mult\n",
        "import os as os\n",
        "import pprint as pp\n",
        "import nltk\n",
        "import gensim.models.word2vec as w2v\n",
        "import sklearn.manifold\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import whoosh as ws\n",
        "import random as ra\n",
        "import csv as csv\n",
        "import scipy as sc\n",
        "import json as js\n",
        "import itertools \n",
        "# 2- Import Python Functions\n",
        "from whoosh.fields import Schema, TEXT, KEYWORD, ID, STORED\n",
        "from whoosh.support.levenshtein import levenshtein\n",
        "from whoosh.support.levenshtein import damerau_levenshtein\n",
        "from IPython.display import clear_output\n",
        "from six.moves import urllib\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "# 3- Import Python tensorflow library\n",
        "import tensorflow as tf\n",
        "print(tf.version)  # make sure the version is 2.x\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_probability as tfp  # We are using a different module from tensorflow this time\n",
        "import tensorflow.compat.v2.feature_column as fc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iWVOMiHI0i8"
      },
      "source": [
        "#2020-08-09 Reading TestDataSet10 using pickle from My drive Google Drive\n",
        "ValidationDataSet10=pd.read_pickle('/content/drive/My Drive/Python/20200720_DataAnalysis/ValidationDataSet10.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGVEoAeZI0i9"
      },
      "source": [
        "ValidationDataSet10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKrb7J4n1bJO"
      },
      "source": [
        "#2020-08-07 Reading TrainDataSet using pickle from My drive Google Drive\n",
        "TrainDataSet=pd.read_pickle('/content/drive/My Drive/Python/20200720_DataAnalysis/TrainDataSet.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2cTuxj01qBV"
      },
      "source": [
        "print (\"TrainDataSet.shape\")\n",
        "print (TrainDataSet.shape)\n",
        "print (\"TrainDataSet.dtypes\")\n",
        "print (TrainDataSet.dtypes)\n",
        "print (\"TrainDataSet.isnull().sum()\")\n",
        "print (TrainDataSet.isnull().sum())\n",
        "TrainDataSet = TrainDataSet.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2JQsmnctYUf"
      },
      "source": [
        "print (\"ValidationDataSet10.shape\")\n",
        "print (ValidationDataSet10.shape)\n",
        "print (\"ValidationDataSet10.dtypes\")\n",
        "print (ValidationDataSet10.dtypes)\n",
        "print (\"ValidationDataSet10.isnull().sum()\")\n",
        "print (ValidationDataSet10.isnull().sum())\n",
        "ValidationDataSet10 = ValidationDataSet10.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGstrsskyOyb"
      },
      "source": [
        "#2020-11-07 JXHALLO: Removing from TrainDataSet the ValidationDataSet10 records.\n",
        "#TrainDataSet90 = pd.merge (TrainDataSet, ValidationDataSet10, how='outer', indicator=True)\n",
        "cond = TrainDataSet['pair_id'].isin(ValidationDataSet10['pair_id'])\n",
        "TrainDataSet.drop(TrainDataSet[cond].index, inplace = True)\n",
        "TrainDataSet90 = TrainDataSet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VUV62UzySxj"
      },
      "source": [
        "print (\"TrainDataSet90.shape\")\n",
        "print (TrainDataSet90.shape)\n",
        "print (\"TrainDataSet90.dtypes\")\n",
        "print (TrainDataSet90.dtypes)\n",
        "print (\"TrainDataSet90.isnull().sum()\")\n",
        "print (TrainDataSet90.isnull().sum())\n",
        "TrainDataSet90 = TrainDataSet90.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x55gXkHxyVCX"
      },
      "source": [
        "#2020-11-07 Saving TrainDataSet90 using pickle from My drive Google Drive\n",
        "TrainDataSet90.to_pickle('/content/drive/My Drive/Python/20200720_DataAnalysis/TrainDataSet90.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41s9O5jyI0i-"
      },
      "source": [
        "# 3- JXHALLO Personal Functions for Code\n",
        "\n",
        "# String Normalizer\n",
        "# Version 1.0: 2020-04-10\n",
        "# Returns normalized string without spaces and special characters using RegEx. Then sets lower case\n",
        "\n",
        "def norm (x):\n",
        "    return re.sub(r\"\\s|[^a-z0-9]\",\"\",x.lower(), flags=re.IGNORECASE)\n",
        "\n",
        "# String Exact Comparison\n",
        "# Version 1.0: 2020-04-10\n",
        "# Returns boolean if string comparison is exact.\n",
        "\n",
        "def exact(a,b):\n",
        "    if a is b:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "# Function to access a specific value within an object list\n",
        "# Returns the value of the record with the corresponding key.\n",
        "# Arguments: object that contain the list of keys and values, the key that you want to match to return the value\n",
        "# Special Note: This function will only return the first value of the list.\n",
        "# Special Note2: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Version 1.2: 2020-04-17\n",
        "\n",
        "def multiObjects(values,key):\n",
        "    val = None\n",
        "    for i in range(len(values)):\n",
        "        data = values[i]\n",
        "        for (k, v) in data.items():\n",
        "            if k == key:\n",
        "                val = list(v.split(\", \"))[0].replace(\"[\",\"\").replace(\"]\",\"\").strip()\n",
        "    return val\n",
        "    \n",
        "# Function to access a specific value within an object list\n",
        "# Returns the value of the record of the corresponding key.\n",
        "# Arguments: object that contain the list of keys and values, the key that you want to match to return the value\n",
        "# Special Note: This function will only return the first value of the list.\n",
        "# Special Note2: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Version 1.0: 2020-04-24\n",
        "\n",
        "def identifiersList (column,key):\n",
        "    lineLst = []\n",
        "    for i in range (len(column)):\n",
        "        mpn = multiObjects(column[i],key)\n",
        "        lineLst.append(mpn)\n",
        "    return lineLst\n",
        "    \n",
        "# Damerau–Levenshtein distance similarity function for normalized strings. Caluculates the Damerau–Levenshtein distance between two strings\n",
        "# Then caluclates the similarity dividing the Damerau–Levenshtein distance over the length of the argument (string) with max length\n",
        "# Returns 0 if any of the strings in the function arguments is None\n",
        "# Version 1.2: 2020-10-23\n",
        "# Returns Damerau–Levenshtein distance similarity [0-1]\n",
        "\n",
        "def DL (x,y):\n",
        "    if x is None or y is None:\n",
        "        return 0\n",
        "    else:\n",
        "        x = norm (x)\n",
        "        y = norm (y)\n",
        "        z = max((len(x)),(len(y)))\n",
        "        #return (1-(damerau_levenshtein (x,y)/len(x)))\n",
        "        return abs((1-(damerau_levenshtein (x,y)/z)))\n",
        "    \n",
        "# Calculates the DL for ten (10) pair attributes of a data set, and adds the label and stores them in a matrix [n,11] where n,11 is the label to identify if the reord is duplicated\n",
        "# Returns the matrix with the calucalted DL result for each pair of attributes.\n",
        "# Special Note: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Version 1.3: 2020-04-25\n",
        "\n",
        "    \n",
        "\n",
        "def DLM1 (dset,\n",
        "          left1,right1,\n",
        "          left2,right2,\n",
        "          left3,right3,\n",
        "          left4,right4,\n",
        "          left5,right5,\n",
        "          left6,right6,\n",
        "          left7,right7,\n",
        "          left8,right8,\n",
        "          left9,right9,\n",
        "          left10,right10,\n",
        "          label):\n",
        "    rows=len(dset)\n",
        "    #matrix1 = np.array(np.zeros(rows*11).reshape(rows,11),dtype=object)\n",
        "    matrix1 = np.zeros(rows*11).reshape(rows,11)\n",
        "    for i in range(rows):\n",
        "      if i % 10000 == 0:\n",
        "        print ('row number= ')\n",
        "        print (i)\n",
        "      for j in range(11):\n",
        "            if i % 10000 == 0:\n",
        "                print ('column number= ')\n",
        "                print (j)\n",
        "            if j == 0:\n",
        "                matrix1[i,j] = DL(left1[i],right1[i])\n",
        "            elif j == 1:\n",
        "                matrix1[i,j] = DL(left2[i],right2[i])\n",
        "            elif j == 2:\n",
        "                matrix1[i,j] = DL(left3[i],right3[i])\n",
        "            elif j == 3:\n",
        "                matrix1[i,j] = DL(left4[i],right4[i])\n",
        "            elif j == 4:\n",
        "                matrix1[i,j] = DL(left5[i],right5[i])\n",
        "            elif j == 5:\n",
        "                matrix1[i,j] = DL(left6[i],right6[i])\n",
        "            elif j == 6:\n",
        "                matrix1[i,j] = DL(left7[i],right7[i])\n",
        "            elif j == 7:\n",
        "                matrix1[i,j] = DL(left8[i],right8[i])\n",
        "            elif j == 8:\n",
        "                matrix1[i,j] = DL(left9[i],right9[i])\n",
        "            elif j == 9:\n",
        "                matrix1[i,j] = DL(left10[i],right10[i])\n",
        "            elif j == 10:\n",
        "                matrix1[i,j] = label[i]\n",
        "                \n",
        "    return matrix1\n",
        "    \n",
        "    \n",
        "# Calculates the DL for ten (10) pair attributes of a data set, and adds the pair_id and label and stores them in a matrix [n,12] where n,12 is the BIAS is the number of records\n",
        "# Returns the matrix with the calucalted DL result for each pair of attributes.\n",
        "# Special Note: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Version 1.3: 2020-04-25\n",
        "\n",
        "    \n",
        "\n",
        "def DLM2 (dset,\n",
        "          left1,right1,\n",
        "          left2,right2,\n",
        "          left3,right3,\n",
        "          left4,right4,\n",
        "          left5,right5,\n",
        "          left6,right6,\n",
        "          left7,right7,\n",
        "          left8,right8,\n",
        "          left9,right9,\n",
        "          left10,right10,\n",
        "          pair_id,\n",
        "          label):\n",
        "    rows=len(dset)\n",
        "    matrix1 = np.zeros(rows*12).reshape(rows,12)\n",
        "    for i in range(rows):\n",
        "        for j in range(12):\n",
        "            if j == 0:\n",
        "                matrix1[i,j] = DL(left1[i],right1[i])\n",
        "            elif j == 1:\n",
        "                matrix1[i,j] = DL(left2[i],right2[i])\n",
        "            elif j == 2:\n",
        "                matrix1[i,j] = DL(left3[i],right3[i])\n",
        "            elif j == 3:\n",
        "                matrix1[i,j] = DL(left4[i],right4[i])\n",
        "            elif j == 4:\n",
        "                matrix1[i,j] = DL(left5[i],right5[i])\n",
        "            elif j == 5:\n",
        "                matrix1[i,j] = DL(left6[i],right6[i])\n",
        "            elif j == 6:\n",
        "                matrix1[i,j] = DL(left7[i],right7[i])\n",
        "            elif j == 7:\n",
        "                matrix1[i,j] = DL(left8[i],right8[i])\n",
        "            elif j == 8:\n",
        "                matrix1[i,j] = DL(left9[i],right9[i])\n",
        "            elif j == 9:\n",
        "                matrix1[i,j] = DL(left10[i],right10[i])\n",
        "            elif j == 10:\n",
        "                matrix1[i,j] = pair_id[i]\n",
        "            elif j == 11:\n",
        "                matrix1[i,j] = label[i]\n",
        "                \n",
        "    return matrix1\n",
        "    \n",
        "    \n",
        "# Calculates the DL for ten (10) pair attributes of a data set, and adds the pair_id and label and stores them in a matrix [n,12] where n,12 is the BIAS is the number of records\n",
        "# Returns the matrix with the calucalted DL result for each pair of attributes.\n",
        "# Special Note: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Version 1.3: 2020-04-25\n",
        "\n",
        "    \n",
        "\n",
        "def DLM3 (dset,\n",
        "          left1,right1,\n",
        "          left2,right2,\n",
        "          left3,right3,\n",
        "          left4,right4,\n",
        "          left5,right5,\n",
        "          key1,\n",
        "          key2,\n",
        "          key3,\n",
        "          key4,\n",
        "          key5,\n",
        "          key6,\n",
        "          pair_id,\n",
        "          label):\n",
        "    rows=len(dset)\n",
        "    matrix1 = np.zeros(rows*12).reshape(rows,12)\n",
        "    for i in range(rows):\n",
        "        for j in range(12):\n",
        "            if j == 0:\n",
        "                matrix1[i,j] = DL(left1[i],right1[i])\n",
        "            elif j == 1:\n",
        "                matrix1[i,j] = DL(left2[i],right2[i])\n",
        "            elif j == 2:\n",
        "                matrix1[i,j] = DL(left3[i],right3[i])\n",
        "            elif j == 3:\n",
        "                matrix1[i,j] = DL(left4[i],right4[i])\n",
        "            elif j == 4:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key1)),(multiObjects(right5[i],key1)))\n",
        "            elif j == 5:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key2)),(multiObjects(right5[i],key2)))\n",
        "            elif j == 6:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key3)),(multiObjects(right5[i],key3)))\n",
        "            elif j == 7:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key4)),(multiObjects(right5[i],key4)))\n",
        "            elif j == 8:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key5)),(multiObjects(right5[i],key5)))\n",
        "            elif j == 9:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key6)),(multiObjects(right5[i],key6)))\n",
        "            elif j == 10:\n",
        "                matrix1[i,j] = pair_id[i]\n",
        "            elif j == 11:\n",
        "                matrix1[i,j] = label[i]\n",
        "                \n",
        "    return matrix1\n",
        "\n",
        "\n",
        "# Calculates the Wiki-words-250-with-normalization matrix for two (2) pair attributes of a data set, and adds the label and stores them in a matrix [n,3].\n",
        "# Returns the matrix with the calucalted Word2Vec result for each pair of attributes.\n",
        "# Special Note: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# Version 1.0: 2020-08-09\n",
        "\n",
        "    \n",
        "\n",
        "def W2V_1 (dset,\n",
        "          left1,right1,\n",
        "          label):\n",
        "    rows=len(dset)\n",
        "    #rows=1\n",
        "    matrix1 = np.array(np.zeros(rows*3).reshape(rows,3),dtype=object)\n",
        "    embed = hub.load(\"https://tfhub.dev/google/Wiki-words-250-with-normalization/2\")\n",
        "    for i in range(rows):\n",
        "        for j in range(3):\n",
        "            if j == 0:\n",
        "                matrix1[i,j] = embed([left1[i]])\n",
        "            elif j == 1:\n",
        "                matrix1[i,j] = embed([right1[i]])\n",
        "            elif j == 2:\n",
        "                matrix1[i,j] = label[i]\n",
        "                \n",
        "    return matrix1\n",
        "\n",
        "# Function to create a new Data Frame with selected columns of a data set.\n",
        "# Returns the new data frame / data set with all the required columns of tuple.\n",
        "# Arguments: Data Set\n",
        "# Special Note: This function will only return as part of the new data frame:\n",
        "# Special Note2: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Will bring data from: \"right\" and \"left\" dat set tuple\n",
        "# Version 1.0: 2020-04-24\n",
        "\n",
        "\n",
        "def dataFileAll (df1):\n",
        "    idLeft = df1.id_left\n",
        "    idRight = df1.id_right\n",
        "    brandListLeft = df1.brand_left\n",
        "    brandListRight = df1.brand_right\n",
        "    categoryListLeft = df1.category_left\n",
        "    categoryListRight = df1.category_right\n",
        "    descriptionListLeft = df1.description_left\n",
        "    descriptionListRight = df1.description_right\n",
        "    titleListLeft = df1.title_left\n",
        "    titleListRight = df1.title_right\n",
        "    gtin8ListLeft = identifiersList(df1.identifiers_left,\"/gtin8\")\n",
        "    gtin8ListRight = identifiersList(df1.identifiers_right,\"/gtin8\")\n",
        "    gtin12ListLeft = identifiersList(df1.identifiers_left,\"/gtin12\")\n",
        "    gtin12ListRight = identifiersList(df1.identifiers_right,\"/gtin12\")\n",
        "    gtin13ListLeft = identifiersList(df1.identifiers_left,\"/gtin13\")\n",
        "    gtin13ListRight = identifiersList(df1.identifiers_right,\"/gtin13\")\n",
        "    gtin14ListLeft = identifiersList(df1.identifiers_left,\"/gtin14\")\n",
        "    gtin14ListRight = identifiersList(df1.identifiers_right,\"/gtin14\")\n",
        "    mpnListLeft = identifiersList(df1.identifiers_left,\"/mpn\")\n",
        "    mpnListRight = identifiersList(df1.identifiers_right,\"/mpn\")\n",
        "    skuListLeft = identifiersList(df1.identifiers_left,\"/sku\")\n",
        "    skuListRight = identifiersList(df1.identifiers_right,\"/sku\")\n",
        "    pairIdList = df1.pair_id\n",
        "    labelList = df1.label\n",
        "    \n",
        "    \n",
        "    zipList = list(zip(idLeft\n",
        "                       ,idRight\n",
        "                       ,brandListLeft\n",
        "                       ,brandListRight\n",
        "                       ,categoryListLeft\n",
        "                       ,categoryListRight\n",
        "                       ,descriptionListLeft\n",
        "                       ,descriptionListRight\n",
        "                       ,titleListLeft\n",
        "                       ,titleListRight\n",
        "                       ,gtin8ListLeft\n",
        "                       ,gtin8ListRight\n",
        "                       ,gtin12ListLeft\n",
        "                       ,gtin12ListRight\n",
        "                       ,gtin13ListLeft\n",
        "                       ,gtin13ListRight\n",
        "                       ,gtin14ListLeft\n",
        "                       ,gtin14ListRight\n",
        "                       ,mpnListLeft\n",
        "                       ,mpnListRight\n",
        "                       ,skuListLeft\n",
        "                       ,skuListRight\n",
        "                       ,pairIdList\n",
        "                       ,labelList\n",
        "                      )\n",
        "                  )\n",
        "    dataObjectLeft = pd.DataFrame(zipList ,columns = [\"idLeft\"\n",
        "                       ,\"idRight\"\n",
        "                       ,\"brandListLeft\"\n",
        "                       ,\"brandListRight\"\n",
        "                       ,\"categoryListLeft\"\n",
        "                       ,\"categoryListRight\"\n",
        "                       ,\"descriptionListLeft\"\n",
        "                       ,\"descriptionListRight\"\n",
        "                       ,\"titleListLeft\"\n",
        "                       ,\"titleListRight\"\n",
        "                       ,\"gtin8ListLeft\"\n",
        "                       ,\"gtin8ListRight\"\n",
        "                       ,\"gtin12ListLeft\"\n",
        "                       ,\"gtin12ListRight\"\n",
        "                       ,\"gtin13ListLeft\"\n",
        "                       ,\"gtin13ListRight\"\n",
        "                       ,\"gtin14ListLeft\"\n",
        "                       ,\"gtin14ListRight\"\n",
        "                       ,\"mpnListLeft\"\n",
        "                       ,\"mpnListRight\"\n",
        "                       ,\"skuListLeft\"\n",
        "                       ,\"skuListRight\"\n",
        "                       ,\"pairIdList\"\n",
        "                       ,\"labelList\"])\n",
        "\n",
        "    return dataObjectLeft"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGLJ_7VdI0i-"
      },
      "source": [
        "TrainDataSet90.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qsnvkMnI0jA"
      },
      "source": [
        "TrainDataSet90.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKp0DtI4I0jA"
      },
      "source": [
        "TrainDataSet90.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvRIgbJqI0jA"
      },
      "source": [
        "# Initialize prepocess_dataset Word2Vec Matrix with \n",
        "\n",
        "TrainDataSet90W2V = W2V_1(TrainDataSet90,\n",
        "                     TrainDataSet90.title_left,TrainDataSet90.title_right,\n",
        "                     TrainDataSet90.label)\n",
        "print (\"TrainDataSet90\")\n",
        "print (TrainDataSet90)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lt2zDKndI0jA"
      },
      "source": [
        "TrainDataSet90W2V.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiPcyqkPI0jB"
      },
      "source": [
        "TrainDataSet90W2V[0,2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_XjC2slI0jB"
      },
      "source": [
        "TrainDataSet90W2V.label.loc[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-Ul91f2I0jB"
      },
      "source": [
        "TrainDataSet90W2V[0,1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnubEm7RI0jB"
      },
      "source": [
        "#TestDataSet10W2V save as numpy array npy in binary format\n",
        "np.save('/content/drive/My Drive/Python/20200720_DataAnalysis/TrainDataSet90W2V', TrainDataSet90W2V)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8kgrJhHR7e4"
      },
      "source": [
        "#TestDataSet10W2V load numpy array npy in binary format\n",
        "TrainDataSet90W2V = np.load('/content/drive/My Drive/Python/20200720_DataAnalysis/TrainDataSet90W2V.npy',mmap_mode=None,allow_pickle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azuRyAdOTFRG"
      },
      "source": [
        "a = TrainDataSet90W2V[0]\n",
        "-5.41110002e-02"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jib3pfUZc4Al"
      },
      "source": [
        "row_count = len(TrainDataSet90W2V[:])\n",
        "col_count = len(TrainDataSet90W2V[:][0])\n",
        "print (\"Row_Count:%d   Col_Count:%d \" %(row_count,col_count))\n",
        "\n",
        "row_count = len(a[:])\n",
        "col_count = len(a[:][0])\n",
        "print (\"Row_Count:%d   Col_Count:%d \" %(row_count,col_count))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gu4_zcMzbumJ"
      },
      "source": [
        "a = a.reshape(1,3)\n",
        "row_count = len(a[:])\n",
        "col_count = len(a[:][0])\n",
        "print (\"Row_Count:%d   Col_Count:%d \" %(row_count,col_count))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ljs1owHmZxBy"
      },
      "source": [
        "a[0,0][0,0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJuK7fegbFiq"
      },
      "source": [
        "b [0,4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swzjLRmCbXv2"
      },
      "source": [
        "a.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAHQEdPCY0F4"
      },
      "source": [
        "b = np.array(np.zeros(1*501).reshape(1,501))\n",
        "b[0,0] = TrainDataSet90W2V[0][0][0][0]\n",
        "b[0,0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWC7ozDY7T1p"
      },
      "source": [
        "b = np.array(np.zeros(1*501).reshape(1,501))\n",
        "b.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDelh8PbmwMp"
      },
      "source": [
        "rows = len(TrainDataSet90W2V[:])\n",
        "columns = len(TrainDataSet90W2V[:][0])\n",
        "b = np.array(np.zeros(rows*501).reshape(rows,501))\n",
        "b.shape\n",
        "print (\"rows=%s\" %(rows))\n",
        "print (\"columns=%s\" %(columns))\n",
        "for i in range(rows):\n",
        "  print(\"i=%s\" %(i))\n",
        "  for j in range(columns):\n",
        "    print(\"j=%s\" %(j))\n",
        "    if j == 2:\n",
        "      b[i,j] = ValidationDataSet10W2V[i,j]\n",
        "      print (\"b[i,j]=%s\" %(b[i,j]))\n",
        "      print (\"ValidationDataSet10W2V[i,j]=%s\" %(ValidationDataSet10W2V[i,j]))\n",
        "    else:\n",
        "      for k in range(250):\n",
        "        print(\"k=%s\" %(k))\n",
        "        b[i,k] = ValidationDataSet10W2V[i,j][0,k]\n",
        "        print (\"b[i,k]=%s\" %(b[0,k]))\n",
        "        print (\"ValidationDataSet10W2V[i,j][0,k]=%s\" %(ValidationDataSet10W2V[i,j][0,k]))\n",
        "print(b)\n",
        " \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItBzrOBVo90N"
      },
      "source": [
        "def w2vMatrix501 (npyArray):\n",
        "  rows = len(npyArray[:])\n",
        "  columns = len(npyArray[:][0])\n",
        "  newMatrix = np.array(np.zeros(rows*501).reshape(rows,501))\n",
        "  newMatrix.shape\n",
        "  print (\"rows=%s\" %(rows))\n",
        "  print (\"columns=%s\" %(columns))\n",
        "  for i in range(rows):\n",
        "    #print(\"i=%s\" %(i))\n",
        "    for j in range(columns):\n",
        "      #print(\"j=%s\" %(j))\n",
        "      if j == 2:\n",
        "        newMatrix[i,500] = npyArray[i,j]\n",
        "        #print (\"newMatrix[i,j]=%s\" %(newMatrix[i,j]))\n",
        "        #print (\"npyArray[i,j]=%s\" %(npyArray[i,j]))\n",
        "      else:\n",
        "        for k in range(250):\n",
        "          #print(\"k=%s\" %(k))\n",
        "          if j == 1:\n",
        "            k250=k+250\n",
        "            #print(\"k250=%s\" %(k250))\n",
        "            newMatrix[i,k250] = npyArray[i,j][0,k]\n",
        "            #print (\"newMatrix[i,k250]=%s\" %(newMatrix[0,k250]))\n",
        "            #print (\"npyArray[i,j][0,k]=%s\" %(npyArray[i,j][0,k]))\n",
        "          else:\n",
        "            newMatrix[i,k] = npyArray[i,j][0,k]\n",
        "            #print (\"newMatrix[i,k]=%s\" %(newMatrix[0,k]))\n",
        "            #print (\"npyArray[i,j][0,k]=%s\" %(npyArray[i,j][0,k]))\n",
        "  #print(newMatrix)\n",
        "  return (newMatrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-RdrlQGC1nM"
      },
      "source": [
        "TrainDataSet90W2V_501 = w2vMatrix501(TrainDataSet90W2V)\n",
        "TrainDataSet90W2V_501.shape\n",
        "TrainDataSet90W2V_501.dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-uSqaKVD014"
      },
      "source": [
        "print (TrainDataSet90W2V_501.shape)\n",
        "print (TrainDataSet90W2V_501.dtype)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEzgtvASPO9j"
      },
      "source": [
        "TrainDataSet90W2V[3544,2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQxHEpSd7vFg"
      },
      "source": [
        "TrainDataSet90W2V[3544,1][0,249]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqfKknSNENAO"
      },
      "source": [
        "TrainDataSet90W2V_501[3544,500]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "az_AvlhlRju5"
      },
      "source": [
        "#TestDataSet10W2V_501 save as numpy array npy in binary format\n",
        "np.save('/content/drive/My Drive/Python/20200720_DataAnalysis/TrainDataSet90W2V_501', TrainDataSet90W2V_501)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7l4eFt_xJXfc"
      },
      "source": [
        "#Preprocessing of ValidationDataSet10.pkl with Word2Vec v2 to Create 10% Hyperparameter Validation Data Set with Word2Vec v2\n",
        "\n",
        "2020-10-23 JXHALLO: Applied transformation to create matrix (n,501) for word2vec transformation where:\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "https://tfhub.dev/google/Wiki-words-250-with-normalization/2\n",
        "\n",
        "**Preprocessed Data Set Outputs:**\n",
        "\n",
        "* ValidationDataSet10W2V_501"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_NsPJY-KM3l"
      },
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnPhk23EKM3m"
      },
      "source": [
        "# 0.1 - Install whoosh\n",
        "!pip install whoosh\n",
        "# 1- Import Python Libraries\n",
        "import numpy as np\n",
        "import gensim as gs\n",
        "import re as re\n",
        "import string as st\n",
        "import codecs as co\n",
        "import glob as gl\n",
        "import logging as logger\n",
        "import multiprocessing as mult\n",
        "import os as os\n",
        "import pprint as pp\n",
        "import nltk\n",
        "import gensim.models.word2vec as w2v\n",
        "import sklearn.manifold\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import whoosh as ws\n",
        "import random as ra\n",
        "import csv as csv\n",
        "import scipy as sc\n",
        "import json as js\n",
        "import itertools "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xw5Kt9yOkBLD"
      },
      "source": [
        "# 2- Import Python Functions\n",
        "from whoosh.fields import Schema, TEXT, KEYWORD, ID, STORED\n",
        "from whoosh.support.levenshtein import levenshtein\n",
        "from whoosh.support.levenshtein import damerau_levenshtein\n",
        "from IPython.display import clear_output\n",
        "from six.moves import urllib\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import ConfusionMatrixDisplay"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrU-i5YhkCNW"
      },
      "source": [
        "# 3- Import Python tensorflow library\n",
        "import tensorflow as tf\n",
        "print(tf.version)  # make sure the version is 2.x\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_probability as tfp  # We are using a different module from tensorflow this time\n",
        "import tensorflow.compat.v2.feature_column as fc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kw7sbop8KM3m"
      },
      "source": [
        "#2020-08-09 Reading TestDataSet10 using pickle from My drive Google Drive\n",
        "ValidationDataSet10=pd.read_pickle('/content/drive/My Drive/Python/20200720_DataAnalysis/ValidationDataSet10.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTJQrUIRKM3n"
      },
      "source": [
        "ValidationDataSet10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBj_g1wSKM3n"
      },
      "source": [
        "# 3- JXHALLO Personal Functions for Code\n",
        "\n",
        "# String Normalizer\n",
        "# Version 1.0: 2020-04-10\n",
        "# Returns normalized string without spaces and special characters using RegEx. Then sets lower case\n",
        "\n",
        "def norm (x):\n",
        "    return re.sub(r\"\\s|[^a-z0-9]\",\"\",x.lower(), flags=re.IGNORECASE)\n",
        "\n",
        "# String Exact Comparison\n",
        "# Version 1.0: 2020-04-10\n",
        "# Returns boolean if string comparison is exact.\n",
        "\n",
        "def exact(a,b):\n",
        "    if a is b:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "# Function to access a specific value within an object list\n",
        "# Returns the value of the record with the corresponding key.\n",
        "# Arguments: object that contain the list of keys and values, the key that you want to match to return the value\n",
        "# Special Note: This function will only return the first value of the list.\n",
        "# Special Note2: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Version 1.2: 2020-04-17\n",
        "\n",
        "def multiObjects(values,key):\n",
        "    val = None\n",
        "    for i in range(len(values)):\n",
        "        data = values[i]\n",
        "        for (k, v) in data.items():\n",
        "            if k == key:\n",
        "                val = list(v.split(\", \"))[0].replace(\"[\",\"\").replace(\"]\",\"\").strip()\n",
        "    return val\n",
        "    \n",
        "# Function to access a specific value within an object list\n",
        "# Returns the value of the record of the corresponding key.\n",
        "# Arguments: object that contain the list of keys and values, the key that you want to match to return the value\n",
        "# Special Note: This function will only return the first value of the list.\n",
        "# Special Note2: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Version 1.0: 2020-04-24\n",
        "\n",
        "def identifiersList (column,key):\n",
        "    lineLst = []\n",
        "    for i in range (len(column)):\n",
        "        mpn = multiObjects(column[i],key)\n",
        "        lineLst.append(mpn)\n",
        "    return lineLst\n",
        "    \n",
        "# Damerau–Levenshtein distance similarity function for normalized strings. Caluculates the Damerau–Levenshtein distance between two strings\n",
        "# Then caluclates the similarity dividing the Damerau–Levenshtein distance over the length of the argument (string) with max length\n",
        "# Returns 0 if any of the strings in the function arguments is None\n",
        "# Version 1.2: 2020-10-23\n",
        "# Returns Damerau–Levenshtein distance similarity [0-1]\n",
        "\n",
        "def DL (x,y):\n",
        "    if x is None or y is None:\n",
        "        return 0\n",
        "    else:\n",
        "        x = norm (x)\n",
        "        y = norm (y)\n",
        "        z = max((len(x)),(len(y)))\n",
        "        #return (1-(damerau_levenshtein (x,y)/len(x)))\n",
        "        return abs((1-(damerau_levenshtein (x,y)/z)))\n",
        "    \n",
        "# Calculates the DL for ten (10) pair attributes of a data set, and adds the label and stores them in a matrix [n,11] where n,11 is the label to identify if the reord is duplicated\n",
        "# Returns the matrix with the calucalted DL result for each pair of attributes.\n",
        "# Special Note: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Version 1.3: 2020-04-25\n",
        "\n",
        "    \n",
        "\n",
        "def DLM1 (dset,\n",
        "          left1,right1,\n",
        "          left2,right2,\n",
        "          left3,right3,\n",
        "          left4,right4,\n",
        "          left5,right5,\n",
        "          left6,right6,\n",
        "          left7,right7,\n",
        "          left8,right8,\n",
        "          left9,right9,\n",
        "          left10,right10,\n",
        "          label):\n",
        "    rows=len(dset)\n",
        "    #matrix1 = np.array(np.zeros(rows*11).reshape(rows,11),dtype=object)\n",
        "    matrix1 = np.zeros(rows*11).reshape(rows,11)\n",
        "    for i in range(rows):\n",
        "      if i % 10000 == 0:\n",
        "        print ('row number= ')\n",
        "        print (i)\n",
        "      for j in range(11):\n",
        "            if i % 10000 == 0:\n",
        "                print ('column number= ')\n",
        "                print (j)\n",
        "            if j == 0:\n",
        "                matrix1[i,j] = DL(left1[i],right1[i])\n",
        "            elif j == 1:\n",
        "                matrix1[i,j] = DL(left2[i],right2[i])\n",
        "            elif j == 2:\n",
        "                matrix1[i,j] = DL(left3[i],right3[i])\n",
        "            elif j == 3:\n",
        "                matrix1[i,j] = DL(left4[i],right4[i])\n",
        "            elif j == 4:\n",
        "                matrix1[i,j] = DL(left5[i],right5[i])\n",
        "            elif j == 5:\n",
        "                matrix1[i,j] = DL(left6[i],right6[i])\n",
        "            elif j == 6:\n",
        "                matrix1[i,j] = DL(left7[i],right7[i])\n",
        "            elif j == 7:\n",
        "                matrix1[i,j] = DL(left8[i],right8[i])\n",
        "            elif j == 8:\n",
        "                matrix1[i,j] = DL(left9[i],right9[i])\n",
        "            elif j == 9:\n",
        "                matrix1[i,j] = DL(left10[i],right10[i])\n",
        "            elif j == 10:\n",
        "                matrix1[i,j] = label[i]\n",
        "                \n",
        "    return matrix1\n",
        "    \n",
        "    \n",
        "# Calculates the DL for ten (10) pair attributes of a data set, and adds the pair_id and label and stores them in a matrix [n,12] where n,12 is the BIAS is the number of records\n",
        "# Returns the matrix with the calucalted DL result for each pair of attributes.\n",
        "# Special Note: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Version 1.3: 2020-04-25\n",
        "\n",
        "    \n",
        "\n",
        "def DLM2 (dset,\n",
        "          left1,right1,\n",
        "          left2,right2,\n",
        "          left3,right3,\n",
        "          left4,right4,\n",
        "          left5,right5,\n",
        "          left6,right6,\n",
        "          left7,right7,\n",
        "          left8,right8,\n",
        "          left9,right9,\n",
        "          left10,right10,\n",
        "          pair_id,\n",
        "          label):\n",
        "    rows=len(dset)\n",
        "    matrix1 = np.zeros(rows*12).reshape(rows,12)\n",
        "    for i in range(rows):\n",
        "        for j in range(12):\n",
        "            if j == 0:\n",
        "                matrix1[i,j] = DL(left1[i],right1[i])\n",
        "            elif j == 1:\n",
        "                matrix1[i,j] = DL(left2[i],right2[i])\n",
        "            elif j == 2:\n",
        "                matrix1[i,j] = DL(left3[i],right3[i])\n",
        "            elif j == 3:\n",
        "                matrix1[i,j] = DL(left4[i],right4[i])\n",
        "            elif j == 4:\n",
        "                matrix1[i,j] = DL(left5[i],right5[i])\n",
        "            elif j == 5:\n",
        "                matrix1[i,j] = DL(left6[i],right6[i])\n",
        "            elif j == 6:\n",
        "                matrix1[i,j] = DL(left7[i],right7[i])\n",
        "            elif j == 7:\n",
        "                matrix1[i,j] = DL(left8[i],right8[i])\n",
        "            elif j == 8:\n",
        "                matrix1[i,j] = DL(left9[i],right9[i])\n",
        "            elif j == 9:\n",
        "                matrix1[i,j] = DL(left10[i],right10[i])\n",
        "            elif j == 10:\n",
        "                matrix1[i,j] = pair_id[i]\n",
        "            elif j == 11:\n",
        "                matrix1[i,j] = label[i]\n",
        "                \n",
        "    return matrix1\n",
        "    \n",
        "    \n",
        "# Calculates the DL for ten (10) pair attributes of a data set, and adds the pair_id and label and stores them in a matrix [n,12] where n,12 is the BIAS is the number of records\n",
        "# Returns the matrix with the calucalted DL result for each pair of attributes.\n",
        "# Special Note: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Version 1.3: 2020-04-25\n",
        "\n",
        "    \n",
        "\n",
        "def DLM3 (dset,\n",
        "          left1,right1,\n",
        "          left2,right2,\n",
        "          left3,right3,\n",
        "          left4,right4,\n",
        "          left5,right5,\n",
        "          key1,\n",
        "          key2,\n",
        "          key3,\n",
        "          key4,\n",
        "          key5,\n",
        "          key6,\n",
        "          pair_id,\n",
        "          label):\n",
        "    rows=len(dset)\n",
        "    matrix1 = np.zeros(rows*12).reshape(rows,12)\n",
        "    for i in range(rows):\n",
        "        for j in range(12):\n",
        "            if j == 0:\n",
        "                matrix1[i,j] = DL(left1[i],right1[i])\n",
        "            elif j == 1:\n",
        "                matrix1[i,j] = DL(left2[i],right2[i])\n",
        "            elif j == 2:\n",
        "                matrix1[i,j] = DL(left3[i],right3[i])\n",
        "            elif j == 3:\n",
        "                matrix1[i,j] = DL(left4[i],right4[i])\n",
        "            elif j == 4:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key1)),(multiObjects(right5[i],key1)))\n",
        "            elif j == 5:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key2)),(multiObjects(right5[i],key2)))\n",
        "            elif j == 6:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key3)),(multiObjects(right5[i],key3)))\n",
        "            elif j == 7:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key4)),(multiObjects(right5[i],key4)))\n",
        "            elif j == 8:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key5)),(multiObjects(right5[i],key5)))\n",
        "            elif j == 9:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key6)),(multiObjects(right5[i],key6)))\n",
        "            elif j == 10:\n",
        "                matrix1[i,j] = pair_id[i]\n",
        "            elif j == 11:\n",
        "                matrix1[i,j] = label[i]\n",
        "                \n",
        "    return matrix1\n",
        "\n",
        "\n",
        "# Calculates the Wiki-words-250-with-normalization matrix for two (2) pair attributes of a data set, and adds the label and stores them in a matrix [n,3].\n",
        "# Returns the matrix with the calucalted Word2Vec result for each pair of attributes.\n",
        "# Special Note: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# Version 1.0: 2020-08-09\n",
        "\n",
        "    \n",
        "\n",
        "def W2V_1 (dset,\n",
        "          left1,right1,\n",
        "          label):\n",
        "    rows=len(dset)\n",
        "    #rows=1\n",
        "    matrix1 = np.array(np.zeros(rows*3).reshape(rows,3),dtype=object)\n",
        "    embed = hub.load(\"https://tfhub.dev/google/Wiki-words-250-with-normalization/2\")\n",
        "    for i in range(rows):\n",
        "        for j in range(3):\n",
        "            if j == 0:\n",
        "                matrix1[i,j] = embed([left1[i]])\n",
        "            elif j == 1:\n",
        "                matrix1[i,j] = embed([right1[i]])\n",
        "            elif j == 2:\n",
        "                matrix1[i,j] = label[i]\n",
        "                \n",
        "    return matrix1\n",
        "\n",
        "# Function to create a new Data Frame with selected columns of a data set.\n",
        "# Returns the new data frame / data set with all the required columns of tuple.\n",
        "# Arguments: Data Set\n",
        "# Special Note: This function will only return as part of the new data frame:\n",
        "# Special Note2: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Will bring data from: \"right\" and \"left\" dat set tuple\n",
        "# Version 1.0: 2020-04-24\n",
        "\n",
        "\n",
        "def dataFileAll (df1):\n",
        "    idLeft = df1.id_left\n",
        "    idRight = df1.id_right\n",
        "    brandListLeft = df1.brand_left\n",
        "    brandListRight = df1.brand_right\n",
        "    categoryListLeft = df1.category_left\n",
        "    categoryListRight = df1.category_right\n",
        "    descriptionListLeft = df1.description_left\n",
        "    descriptionListRight = df1.description_right\n",
        "    titleListLeft = df1.title_left\n",
        "    titleListRight = df1.title_right\n",
        "    gtin8ListLeft = identifiersList(df1.identifiers_left,\"/gtin8\")\n",
        "    gtin8ListRight = identifiersList(df1.identifiers_right,\"/gtin8\")\n",
        "    gtin12ListLeft = identifiersList(df1.identifiers_left,\"/gtin12\")\n",
        "    gtin12ListRight = identifiersList(df1.identifiers_right,\"/gtin12\")\n",
        "    gtin13ListLeft = identifiersList(df1.identifiers_left,\"/gtin13\")\n",
        "    gtin13ListRight = identifiersList(df1.identifiers_right,\"/gtin13\")\n",
        "    gtin14ListLeft = identifiersList(df1.identifiers_left,\"/gtin14\")\n",
        "    gtin14ListRight = identifiersList(df1.identifiers_right,\"/gtin14\")\n",
        "    mpnListLeft = identifiersList(df1.identifiers_left,\"/mpn\")\n",
        "    mpnListRight = identifiersList(df1.identifiers_right,\"/mpn\")\n",
        "    skuListLeft = identifiersList(df1.identifiers_left,\"/sku\")\n",
        "    skuListRight = identifiersList(df1.identifiers_right,\"/sku\")\n",
        "    pairIdList = df1.pair_id\n",
        "    labelList = df1.label\n",
        "    \n",
        "    \n",
        "    zipList = list(zip(idLeft\n",
        "                       ,idRight\n",
        "                       ,brandListLeft\n",
        "                       ,brandListRight\n",
        "                       ,categoryListLeft\n",
        "                       ,categoryListRight\n",
        "                       ,descriptionListLeft\n",
        "                       ,descriptionListRight\n",
        "                       ,titleListLeft\n",
        "                       ,titleListRight\n",
        "                       ,gtin8ListLeft\n",
        "                       ,gtin8ListRight\n",
        "                       ,gtin12ListLeft\n",
        "                       ,gtin12ListRight\n",
        "                       ,gtin13ListLeft\n",
        "                       ,gtin13ListRight\n",
        "                       ,gtin14ListLeft\n",
        "                       ,gtin14ListRight\n",
        "                       ,mpnListLeft\n",
        "                       ,mpnListRight\n",
        "                       ,skuListLeft\n",
        "                       ,skuListRight\n",
        "                       ,pairIdList\n",
        "                       ,labelList\n",
        "                      )\n",
        "                  )\n",
        "    dataObjectLeft = pd.DataFrame(zipList ,columns = [\"idLeft\"\n",
        "                       ,\"idRight\"\n",
        "                       ,\"brandListLeft\"\n",
        "                       ,\"brandListRight\"\n",
        "                       ,\"categoryListLeft\"\n",
        "                       ,\"categoryListRight\"\n",
        "                       ,\"descriptionListLeft\"\n",
        "                       ,\"descriptionListRight\"\n",
        "                       ,\"titleListLeft\"\n",
        "                       ,\"titleListRight\"\n",
        "                       ,\"gtin8ListLeft\"\n",
        "                       ,\"gtin8ListRight\"\n",
        "                       ,\"gtin12ListLeft\"\n",
        "                       ,\"gtin12ListRight\"\n",
        "                       ,\"gtin13ListLeft\"\n",
        "                       ,\"gtin13ListRight\"\n",
        "                       ,\"gtin14ListLeft\"\n",
        "                       ,\"gtin14ListRight\"\n",
        "                       ,\"mpnListLeft\"\n",
        "                       ,\"mpnListRight\"\n",
        "                       ,\"skuListLeft\"\n",
        "                       ,\"skuListRight\"\n",
        "                       ,\"pairIdList\"\n",
        "                       ,\"labelList\"])\n",
        "\n",
        "    return dataObjectLeft"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdUymwu_KM3n"
      },
      "source": [
        "ValidationDataSet10.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10XBl9h-KM3n"
      },
      "source": [
        "ValidationDataSet10.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_az18GrKM3n"
      },
      "source": [
        "ValidationDataSet10.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHjHDiYiKM3o"
      },
      "source": [
        "# Initialize prepocess_dataset Word2Vec Matrix with \n",
        "\n",
        "ValidationDataSet10W2V = W2V_1(ValidationDataSet10,\n",
        "                     ValidationDataSet10.title_left,ValidationDataSet10.title_right,\n",
        "                     ValidationDataSet10.label)\n",
        "print (\"ValidationDataSet10\")\n",
        "print (ValidationDataSet10)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QalX4qtyKM3o"
      },
      "source": [
        "ValidationDataSet10W2V.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMlzQO4uKM3o"
      },
      "source": [
        "ValidationDataSet10W2V[0,2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87VVEO-PKM3o"
      },
      "source": [
        "ValidationDataSet10.label.loc[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCTc-KCuKM3o"
      },
      "source": [
        "ValidationDataSet10W2V[0,1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muqfxJNsKM3o"
      },
      "source": [
        "#TestDataSet10W2V save as numpy array npy in binary format\n",
        "np.save('/content/drive/My Drive/Python/20200720_DataAnalysis/ValidationDataSet10W2V', ValidationDataSet10W2V)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etvTlevIKM3o"
      },
      "source": [
        "#TestDataSet10W2V load numpy array npy in binary format\n",
        "ValidationDataSet10W2V = np.load('/content/drive/My Drive/Python/20200720_DataAnalysis/ValidationDataSet10W2V.npy',mmap_mode=None,allow_pickle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4ZpjIJqKM3o"
      },
      "source": [
        "a = ValidationDataSet10W2V[0]\n",
        "-5.41110002e-02"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIe92acPKM3p"
      },
      "source": [
        "row_count = len(ValidationDataSet10W2V[:])\n",
        "col_count = len(ValidationDataSet10W2V[:][0])\n",
        "print (\"Row_Count:%d   Col_Count:%d \" %(row_count,col_count))\n",
        "\n",
        "row_count = len(a[:])\n",
        "col_count = len(a[:][0])\n",
        "print (\"Row_Count:%d   Col_Count:%d \" %(row_count,col_count))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGHXu1UrKM3p"
      },
      "source": [
        "a = a.reshape(1,3)\n",
        "row_count = len(a[:])\n",
        "col_count = len(a[:][0])\n",
        "print (\"Row_Count:%d   Col_Count:%d \" %(row_count,col_count))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49XMgr2XKM3p"
      },
      "source": [
        "a[0,0][0,0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rv-vfp_6KM3p"
      },
      "source": [
        "b [0,4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "xewe3GkxKM3p",
        "outputId": "5383c8db-da2c-4363-8cb4-5d30539cbf21"
      },
      "source": [
        "a.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0bJo5ERKM3p"
      },
      "source": [
        "b = np.array(np.zeros(1*501).reshape(1,501))\n",
        "b[0,0] = ValidationDataSet10W2V[0][0][0][0]\n",
        "b[0,0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNcbLnOlKM3p"
      },
      "source": [
        "b = np.array(np.zeros(1*501).reshape(1,501))\n",
        "b.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7c0SZn5KM3q"
      },
      "source": [
        "rows = len(ValidationDataSet10W2V[:])\n",
        "columns = len(ValidationDataSet10W2V[:][0])\n",
        "b = np.array(np.zeros(rows*501).reshape(rows,501))\n",
        "b.shape\n",
        "print (\"rows=%s\" %(rows))\n",
        "print (\"columns=%s\" %(columns))\n",
        "for i in range(rows):\n",
        "  print(\"i=%s\" %(i))\n",
        "  for j in range(columns):\n",
        "    print(\"j=%s\" %(j))\n",
        "    if j == 2:\n",
        "      b[i,j] = ValidationDataSet10W2V[i,j]\n",
        "      print (\"b[i,j]=%s\" %(b[i,j]))\n",
        "      print (\"ValidationDataSet10W2V[i,j]=%s\" %(ValidationDataSet10W2V[i,j]))\n",
        "    else:\n",
        "      for k in range(250):\n",
        "        print(\"k=%s\" %(k))\n",
        "        b[i,k] = ValidationDataSet10W2V[i,j][0,k]\n",
        "        print (\"b[i,k]=%s\" %(b[0,k]))\n",
        "        print (\"ValidationDataSet10W2V[i,j][0,k]=%s\" %(ValidationDataSet10W2V[i,j][0,k]))\n",
        "print(b)\n",
        " \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5lmUBFFKM3q"
      },
      "source": [
        "def w2vMatrix501 (npyArray):\n",
        "  rows = len(npyArray[:])\n",
        "  columns = len(npyArray[:][0])\n",
        "  newMatrix = np.array(np.zeros(rows*501).reshape(rows,501))\n",
        "  newMatrix.shape\n",
        "  print (\"rows=%s\" %(rows))\n",
        "  print (\"columns=%s\" %(columns))\n",
        "  for i in range(rows):\n",
        "    #print(\"i=%s\" %(i))\n",
        "    for j in range(columns):\n",
        "      #print(\"j=%s\" %(j))\n",
        "      if j == 2:\n",
        "        newMatrix[i,500] = npyArray[i,j]\n",
        "        #print (\"newMatrix[i,j]=%s\" %(newMatrix[i,j]))\n",
        "        #print (\"npyArray[i,j]=%s\" %(npyArray[i,j]))\n",
        "      else:\n",
        "        for k in range(250):\n",
        "          #print(\"k=%s\" %(k))\n",
        "          if j == 1:\n",
        "            k250=k+250\n",
        "            #print(\"k250=%s\" %(k250))\n",
        "            newMatrix[i,k250] = npyArray[i,j][0,k]\n",
        "            #print (\"newMatrix[i,k250]=%s\" %(newMatrix[0,k250]))\n",
        "            #print (\"npyArray[i,j][0,k]=%s\" %(npyArray[i,j][0,k]))\n",
        "          else:\n",
        "            newMatrix[i,k] = npyArray[i,j][0,k]\n",
        "            #print (\"newMatrix[i,k]=%s\" %(newMatrix[0,k]))\n",
        "            #print (\"npyArray[i,j][0,k]=%s\" %(npyArray[i,j][0,k]))\n",
        "  #print(newMatrix)\n",
        "  return (newMatrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYxH-Sk5KM3q"
      },
      "source": [
        "ValidationDataSet10W2V_501 = w2vMatrix501(ValidationDataSet10W2V)\n",
        "ValidationDataSet10W2V_501.shape\n",
        "ValidationDataSet10W2V_501.dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6i4-sHrWKM3q"
      },
      "source": [
        "print (ValidationDataSet10W2V_501.shape)\n",
        "print (ValidationDataSet10W2V_501.dtype)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUr_txpmKM3q"
      },
      "source": [
        "ValidationDataSet10W2V[3544,2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81w4bdkyKM3q"
      },
      "source": [
        "ValidationDataSet10W2V[3544,1][0,249]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQfn_dT_KM3q"
      },
      "source": [
        "ValidationDataSet10W2V_501[3544,500]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbkQCcblKM3q"
      },
      "source": [
        "#TestDataSet10W2V_501 save as numpy array npy in binary format\n",
        "np.save('/content/drive/My Drive/Python/20200720_DataAnalysis/ValidationDataSet10W2V_501', ValidationDataSet10W2V_501)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RO4KrHeLwxY"
      },
      "source": [
        "# ***Preprocessing Data Corpus***\n",
        "\n",
        "DL Similarity Matrix Data Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jg95lAUTMFK2"
      },
      "source": [
        "#Preprocessing of TrainDataSet.pkl with DL Similarity Matrix\n",
        "2020-10-23 JXHALLO: Re Preprocesing DL TrainingDataSet\n",
        "Adjusting DL Function to use max len of strings as denominator in order to ensure DL returns a number between [0,1]\n",
        "\n",
        "**Preprocessed Data Set Outputs:**\n",
        "\n",
        "* TrainDataSetDL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZDPvOC62fE_"
      },
      "source": [
        "# 0.1 - Import Python Libraries\n",
        "!pip install whoosh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXBKsvix1qBB"
      },
      "source": [
        "# 1- Import Python Libraries\n",
        "import numpy as np\n",
        "import gensim as gs\n",
        "import re as re\n",
        "import string as st\n",
        "import codecs as co\n",
        "import glob as gl\n",
        "import logging as logger\n",
        "import multiprocessing as mult\n",
        "import os as os\n",
        "import pprint as pp\n",
        "import nltk\n",
        "import gensim.models.word2vec as w2v\n",
        "import sklearn.manifold\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import whoosh as ws\n",
        "import random as ra\n",
        "import csv as csv\n",
        "import scipy as sc\n",
        "import json as js\n",
        "import itertools "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkHJuQL11qBE"
      },
      "source": [
        "# 2- Import Python Functions\n",
        "from whoosh.fields import Schema, TEXT, KEYWORD, ID, STORED\n",
        "from whoosh.support.levenshtein import levenshtein\n",
        "from whoosh.support.levenshtein import damerau_levenshtein\n",
        "from IPython.display import clear_output\n",
        "from six.moves import urllib\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import ConfusionMatrixDisplay"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUYCAevw1qBH"
      },
      "source": [
        "# 3- Import Python tensorflow library\n",
        "import tensorflow as tf\n",
        "print(tf.version)  # make sure the version is 2.x\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_probability as tfp  # We are using a different module from tensorflow this time\n",
        "import tensorflow.compat.v2.feature_column as fc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEJUhJvW1xQ0"
      },
      "source": [
        "# 3.1 - Importing drive from google.colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnlCEYXKUCld"
      },
      "source": [
        "x = 'JULIO'\n",
        "y = 'HALLOLARREA'\n",
        "lenx = len(x)\n",
        "print (lenx)\n",
        "leny = len(y)\n",
        "print (len(y))\n",
        "z = max ((len(x)),(len(y)))\n",
        "print (z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T94TVkscOKTO"
      },
      "source": [
        "# 3- JXHALLO Personal Functions for Code\n",
        "\n",
        "# String Normalizer\n",
        "# Version 1.0: 2020-04-10\n",
        "# Returns normalized string without spaces and special characters using RegEx. Then sets lower case\n",
        "\n",
        "def norm (x):\n",
        "    return re.sub(r\"\\s|[^a-z0-9]\",\"\",x.lower(), flags=re.IGNORECASE)\n",
        "\n",
        "# String Exact Comparison\n",
        "# Version 1.0: 2020-04-10\n",
        "# Returns boolean if string comparison is exact.\n",
        "\n",
        "def exact(a,b):\n",
        "    if a is b:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "# Function to access a specific value within an object list\n",
        "# Returns the value of the record with the corresponding key.\n",
        "# Arguments: object that contain the list of keys and values, the key that you want to match to return the value\n",
        "# Special Note: This function will only return the first value of the list.\n",
        "# Special Note2: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Version 1.2: 2020-04-17\n",
        "\n",
        "def multiObjects(values,key):\n",
        "    val = None\n",
        "    for i in range(len(values)):\n",
        "        data = values[i]\n",
        "        for (k, v) in data.items():\n",
        "            if k == key:\n",
        "                val = list(v.split(\", \"))[0].replace(\"[\",\"\").replace(\"]\",\"\").strip()\n",
        "    return val\n",
        "    \n",
        "# Function to access a specific value within an object list\n",
        "# Returns the value of the record of the corresponding key.\n",
        "# Arguments: object that contain the list of keys and values, the key that you want to match to return the value\n",
        "# Special Note: This function will only return the first value of the list.\n",
        "# Special Note2: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Version 1.0: 2020-04-24\n",
        "\n",
        "def identifiersList (column,key):\n",
        "    lineLst = []\n",
        "    for i in range (len(column)):\n",
        "        mpn = multiObjects(column[i],key)\n",
        "        lineLst.append(mpn)\n",
        "    return lineLst\n",
        "    \n",
        "# Damerau–Levenshtein distance similarity function for normalized strings. Caluculates the Damerau–Levenshtein distance between two strings\n",
        "# Then caluclates the similarity dividing the Damerau–Levenshtein distance over the length of the argument (string) with max length\n",
        "# Returns 0 if any of the strings in the function arguments is None\n",
        "# Version 1.2: 2020-10-23\n",
        "# Returns Damerau–Levenshtein distance similarity [0-1]\n",
        "\n",
        "def DL (x,y):\n",
        "    if x is None or y is None:\n",
        "        return 0\n",
        "    else:\n",
        "        x = norm (x)\n",
        "        y = norm (y)\n",
        "        z = max((len(x)),(len(y)))\n",
        "        #return (1-(damerau_levenshtein (x,y)/len(x)))\n",
        "        return abs((1-(damerau_levenshtein (x,y)/z)))\n",
        "    \n",
        "# Calculates the DL for ten (10) pair attributes of a data set, and adds the label and stores them in a matrix [n,11] where n,11 is the label to identify if the reord is duplicated\n",
        "# Returns the matrix with the calucalted DL result for each pair of attributes.\n",
        "# Special Note: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Version 1.3: 2020-04-25\n",
        "\n",
        "    \n",
        "\n",
        "def DLM1 (dset,\n",
        "          left1,right1,\n",
        "          left2,right2,\n",
        "          left3,right3,\n",
        "          left4,right4,\n",
        "          left5,right5,\n",
        "          left6,right6,\n",
        "          left7,right7,\n",
        "          left8,right8,\n",
        "          left9,right9,\n",
        "          left10,right10,\n",
        "          label):\n",
        "    rows=len(dset)\n",
        "    #matrix1 = np.array(np.zeros(rows*11).reshape(rows,11),dtype=object)\n",
        "    matrix1 = np.zeros(rows*11).reshape(rows,11)\n",
        "    for i in range(rows):\n",
        "      if i % 10000 == 0:\n",
        "        print ('row number= ')\n",
        "        print (i)\n",
        "      for j in range(11):\n",
        "            if i % 10000 == 0:\n",
        "                print ('column number= ')\n",
        "                print (j)\n",
        "            if j == 0:\n",
        "                matrix1[i,j] = DL(left1[i],right1[i])\n",
        "            elif j == 1:\n",
        "                matrix1[i,j] = DL(left2[i],right2[i])\n",
        "            elif j == 2:\n",
        "                matrix1[i,j] = DL(left3[i],right3[i])\n",
        "            elif j == 3:\n",
        "                matrix1[i,j] = DL(left4[i],right4[i])\n",
        "            elif j == 4:\n",
        "                matrix1[i,j] = DL(left5[i],right5[i])\n",
        "            elif j == 5:\n",
        "                matrix1[i,j] = DL(left6[i],right6[i])\n",
        "            elif j == 6:\n",
        "                matrix1[i,j] = DL(left7[i],right7[i])\n",
        "            elif j == 7:\n",
        "                matrix1[i,j] = DL(left8[i],right8[i])\n",
        "            elif j == 8:\n",
        "                matrix1[i,j] = DL(left9[i],right9[i])\n",
        "            elif j == 9:\n",
        "                matrix1[i,j] = DL(left10[i],right10[i])\n",
        "            elif j == 10:\n",
        "                matrix1[i,j] = label[i]\n",
        "                \n",
        "    return matrix1\n",
        "    \n",
        "    \n",
        "# Calculates the DL for ten (10) pair attributes of a data set, and adds the pair_id and label and stores them in a matrix [n,12] where n,12 is the BIAS is the number of records\n",
        "# Returns the matrix with the calucalted DL result for each pair of attributes.\n",
        "# Special Note: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Version 1.3: 2020-04-25\n",
        "\n",
        "    \n",
        "\n",
        "def DLM2 (dset,\n",
        "          left1,right1,\n",
        "          left2,right2,\n",
        "          left3,right3,\n",
        "          left4,right4,\n",
        "          left5,right5,\n",
        "          left6,right6,\n",
        "          left7,right7,\n",
        "          left8,right8,\n",
        "          left9,right9,\n",
        "          left10,right10,\n",
        "          pair_id,\n",
        "          label):\n",
        "    rows=len(dset)\n",
        "    matrix1 = np.zeros(rows*12).reshape(rows,12)\n",
        "    for i in range(rows):\n",
        "        for j in range(12):\n",
        "            if j == 0:\n",
        "                matrix1[i,j] = DL(left1[i],right1[i])\n",
        "            elif j == 1:\n",
        "                matrix1[i,j] = DL(left2[i],right2[i])\n",
        "            elif j == 2:\n",
        "                matrix1[i,j] = DL(left3[i],right3[i])\n",
        "            elif j == 3:\n",
        "                matrix1[i,j] = DL(left4[i],right4[i])\n",
        "            elif j == 4:\n",
        "                matrix1[i,j] = DL(left5[i],right5[i])\n",
        "            elif j == 5:\n",
        "                matrix1[i,j] = DL(left6[i],right6[i])\n",
        "            elif j == 6:\n",
        "                matrix1[i,j] = DL(left7[i],right7[i])\n",
        "            elif j == 7:\n",
        "                matrix1[i,j] = DL(left8[i],right8[i])\n",
        "            elif j == 8:\n",
        "                matrix1[i,j] = DL(left9[i],right9[i])\n",
        "            elif j == 9:\n",
        "                matrix1[i,j] = DL(left10[i],right10[i])\n",
        "            elif j == 10:\n",
        "                matrix1[i,j] = pair_id[i]\n",
        "            elif j == 11:\n",
        "                matrix1[i,j] = label[i]\n",
        "                \n",
        "    return matrix1\n",
        "    \n",
        "    \n",
        "# Calculates the DL for ten (10) pair attributes of a data set, and adds the pair_id and label and stores them in a matrix [n,12] where n,12 is the BIAS is the number of records\n",
        "# Returns the matrix with the calucalted DL result for each pair of attributes.\n",
        "# Special Note: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Version 1.3: 2020-04-25\n",
        "\n",
        "    \n",
        "\n",
        "def DLM3 (dset,\n",
        "          left1,right1,\n",
        "          left2,right2,\n",
        "          left3,right3,\n",
        "          left4,right4,\n",
        "          left5,right5,\n",
        "          key1,\n",
        "          key2,\n",
        "          key3,\n",
        "          key4,\n",
        "          key5,\n",
        "          key6,\n",
        "          pair_id,\n",
        "          label):\n",
        "    rows=len(dset)\n",
        "    matrix1 = np.zeros(rows*12).reshape(rows,12)\n",
        "    for i in range(rows):\n",
        "        for j in range(12):\n",
        "            if j == 0:\n",
        "                matrix1[i,j] = DL(left1[i],right1[i])\n",
        "            elif j == 1:\n",
        "                matrix1[i,j] = DL(left2[i],right2[i])\n",
        "            elif j == 2:\n",
        "                matrix1[i,j] = DL(left3[i],right3[i])\n",
        "            elif j == 3:\n",
        "                matrix1[i,j] = DL(left4[i],right4[i])\n",
        "            elif j == 4:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key1)),(multiObjects(right5[i],key1)))\n",
        "            elif j == 5:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key2)),(multiObjects(right5[i],key2)))\n",
        "            elif j == 6:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key3)),(multiObjects(right5[i],key3)))\n",
        "            elif j == 7:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key4)),(multiObjects(right5[i],key4)))\n",
        "            elif j == 8:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key5)),(multiObjects(right5[i],key5)))\n",
        "            elif j == 9:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key6)),(multiObjects(right5[i],key6)))\n",
        "            elif j == 10:\n",
        "                matrix1[i,j] = pair_id[i]\n",
        "            elif j == 11:\n",
        "                matrix1[i,j] = label[i]\n",
        "                \n",
        "    return matrix1\n",
        "\n",
        "# Function to create a new Data Frame with selected columns of a data set.\n",
        "# Returns the new data frame / data set with all the required columns of tuple.\n",
        "# Arguments: Data Set\n",
        "# Special Note: This function will only return as part of the new data frame:\n",
        "# Special Note2: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Will bring data from: \"right\" and \"left\" dat set tuple\n",
        "# Version 1.0: 2020-04-24\n",
        "\n",
        "\n",
        "def dataFileAll (df1):\n",
        "    idLeft = df1.id_left\n",
        "    idRight = df1.id_right\n",
        "    brandListLeft = df1.brand_left\n",
        "    brandListRight = df1.brand_right\n",
        "    categoryListLeft = df1.category_left\n",
        "    categoryListRight = df1.category_right\n",
        "    descriptionListLeft = df1.description_left\n",
        "    descriptionListRight = df1.description_right\n",
        "    titleListLeft = df1.title_left\n",
        "    titleListRight = df1.title_right\n",
        "    gtin8ListLeft = identifiersList(df1.identifiers_left,\"/gtin8\")\n",
        "    gtin8ListRight = identifiersList(df1.identifiers_right,\"/gtin8\")\n",
        "    gtin12ListLeft = identifiersList(df1.identifiers_left,\"/gtin12\")\n",
        "    gtin12ListRight = identifiersList(df1.identifiers_right,\"/gtin12\")\n",
        "    gtin13ListLeft = identifiersList(df1.identifiers_left,\"/gtin13\")\n",
        "    gtin13ListRight = identifiersList(df1.identifiers_right,\"/gtin13\")\n",
        "    gtin14ListLeft = identifiersList(df1.identifiers_left,\"/gtin14\")\n",
        "    gtin14ListRight = identifiersList(df1.identifiers_right,\"/gtin14\")\n",
        "    mpnListLeft = identifiersList(df1.identifiers_left,\"/mpn\")\n",
        "    mpnListRight = identifiersList(df1.identifiers_right,\"/mpn\")\n",
        "    skuListLeft = identifiersList(df1.identifiers_left,\"/sku\")\n",
        "    skuListRight = identifiersList(df1.identifiers_right,\"/sku\")\n",
        "    pairIdList = df1.pair_id\n",
        "    labelList = df1.label\n",
        "    \n",
        "    \n",
        "    zipList = list(zip(idLeft\n",
        "                       ,idRight\n",
        "                       ,brandListLeft\n",
        "                       ,brandListRight\n",
        "                       ,categoryListLeft\n",
        "                       ,categoryListRight\n",
        "                       ,descriptionListLeft\n",
        "                       ,descriptionListRight\n",
        "                       ,titleListLeft\n",
        "                       ,titleListRight\n",
        "                       ,gtin8ListLeft\n",
        "                       ,gtin8ListRight\n",
        "                       ,gtin12ListLeft\n",
        "                       ,gtin12ListRight\n",
        "                       ,gtin13ListLeft\n",
        "                       ,gtin13ListRight\n",
        "                       ,gtin14ListLeft\n",
        "                       ,gtin14ListRight\n",
        "                       ,mpnListLeft\n",
        "                       ,mpnListRight\n",
        "                       ,skuListLeft\n",
        "                       ,skuListRight\n",
        "                       ,pairIdList\n",
        "                       ,labelList\n",
        "                      )\n",
        "                  )\n",
        "    dataObjectLeft = pd.DataFrame(zipList ,columns = [\"idLeft\"\n",
        "                       ,\"idRight\"\n",
        "                       ,\"brandListLeft\"\n",
        "                       ,\"brandListRight\"\n",
        "                       ,\"categoryListLeft\"\n",
        "                       ,\"categoryListRight\"\n",
        "                       ,\"descriptionListLeft\"\n",
        "                       ,\"descriptionListRight\"\n",
        "                       ,\"titleListLeft\"\n",
        "                       ,\"titleListRight\"\n",
        "                       ,\"gtin8ListLeft\"\n",
        "                       ,\"gtin8ListRight\"\n",
        "                       ,\"gtin12ListLeft\"\n",
        "                       ,\"gtin12ListRight\"\n",
        "                       ,\"gtin13ListLeft\"\n",
        "                       ,\"gtin13ListRight\"\n",
        "                       ,\"gtin14ListLeft\"\n",
        "                       ,\"gtin14ListRight\"\n",
        "                       ,\"mpnListLeft\"\n",
        "                       ,\"mpnListRight\"\n",
        "                       ,\"skuListLeft\"\n",
        "                       ,\"skuListRight\"\n",
        "                       ,\"pairIdList\"\n",
        "                       ,\"labelList\"])\n",
        "\n",
        "    return dataObjectLeft"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlN1hiR21qBQ"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWciVFOz1qBS"
      },
      "source": [
        "#2020-07-20 Reading AppendedDataFile using pickle\n",
        "#TestDataSet=pd.read_pickle('/Users/juliohallo/Documents/Personal/Maestria 2018/Python/20200720_DataAnalysis/TestDataSet.pkl')\n",
        "import io\n",
        "\n",
        "TestDataSet=pd.read_pickle(io.BytesIO(uploaded['TestDataSet.pkl']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vxs7xXNMknG"
      },
      "source": [
        "TestDataSet=pd.DataFrame(None)\n",
        "print (\"TestDataSet.shape\")\n",
        "print (TestDataSet.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74O00zJVOKTO"
      },
      "source": [
        "#2020-08-07 Reading TrainDataSet using pickle from My drive Google Drive\n",
        "TrainDataSet=pd.read_pickle('/content/drive/My Drive/Python/20200720_DataAnalysis/TrainDataSet.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMY_J02vOKTP"
      },
      "source": [
        "print (\"TrainDataSet.shape\")\n",
        "print (TrainDataSet.shape)\n",
        "print (\"TrainDataSet.dtypes\")\n",
        "print (TrainDataSet.dtypes)\n",
        "print (\"TrainDataSet.isnull().sum()\")\n",
        "print (TrainDataSet.isnull().sum())\n",
        "TrainDataSet = TrainDataSet.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SauF4Qgn1qBY"
      },
      "source": [
        "# 4.1- JXHALLO Preprocess Data Corpus to dataFileAll\n",
        "\n",
        "# all_train_xlarge_sample.json\n",
        "# Complete Data Catalog available at: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# Data Corpus Explanation available at: http://webdatacommons.org/largescaleproductcorpus/v2/index.html\n",
        "# Will just create a [n,24] dataframe\n",
        "\n",
        "data2 = dataFileAll(TrainDataSet)\n",
        "print (data2.shape)\n",
        "print (data2.dtypes)\n",
        "print (data2.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpIRQhvR1qBa"
      },
      "source": [
        "# Initialize prepocess_dataset DL Similarity Matrix \n",
        "\n",
        "TrainDataSetDL = DLM1(data2,\n",
        "                     data2.brandListLeft,data2.brandListRight,\n",
        "                     data2.categoryListLeft,data2.categoryListRight,\n",
        "                     data2.descriptionListLeft,data2.descriptionListRight,\n",
        "                     data2.titleListLeft,data2.titleListRight,\n",
        "                     data2.gtin8ListLeft,data2.gtin8ListRight,\n",
        "                     data2.gtin12ListLeft,data2.gtin12ListRight,\n",
        "                     data2.gtin13ListLeft,data2.gtin13ListRight,\n",
        "                     data2.gtin14ListLeft,data2.gtin14ListRight,\n",
        "                     data2.mpnListLeft,data2.mpnListRight,\n",
        "                     data2.skuListLeft,data2.skuListRight,\n",
        "                     data2.labelList)\n",
        "print (\"TrainDataSetDL\")\n",
        "print (TrainDataSetDL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i32Wla57GkZS"
      },
      "source": [
        "TrainDataSetDL[35563]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqtj0ukw1qBc"
      },
      "source": [
        "print (data2.labelList[35563])\n",
        "print (data2.categoryListLeft[35563])\n",
        "print (data2.categoryListRight[35563])\n",
        "print (DL(data2.categoryListLeft[35563],data2.categoryListRight[35563]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3VBPD2D1qBg"
      },
      "source": [
        "print (data2.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ng9pjwWJpoSX"
      },
      "source": [
        "\n",
        "print (data2.dtypes)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOuHIefEpo7e"
      },
      "source": [
        "\n",
        "print (data2.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAfhWl6Of5cW"
      },
      "source": [
        "#numpy.save(file, arr, allow_pickle=True, fix_imports=True)[source]\n",
        "\n",
        "np.save('/content/drive/My Drive/Python/20200720_DataAnalysis/TrainDataSetDL', TrainDataSetDL)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtvU82pDOexM"
      },
      "source": [
        "#Preprocessing of TestDataSet10.pkl with DL Similarity Matrix\n",
        "2020-10-23 JXHALLO: Re Preprocesing DL TestDataSet\n",
        "Adjusting DL Function to use max len of strings as denominator in order to ensure DL returns a number between [0,1]\n",
        "\n",
        "**Preprocessed Data Set Outputs:**\n",
        "\n",
        "* TestDataSetDL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQSC25WPOvqY"
      },
      "source": [
        "# 0.1 - Import Python Libraries\n",
        "!pip install whoosh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwxujkitOvqY"
      },
      "source": [
        "# 1- Import Python Libraries\n",
        "import numpy as np\n",
        "import gensim as gs\n",
        "import re as re\n",
        "import string as st\n",
        "import codecs as co\n",
        "import glob as gl\n",
        "import logging as logger\n",
        "import multiprocessing as mult\n",
        "import os as os\n",
        "import pprint as pp\n",
        "import nltk\n",
        "import gensim.models.word2vec as w2v\n",
        "import sklearn.manifold\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import whoosh as ws\n",
        "import random as ra\n",
        "import csv as csv\n",
        "import scipy as sc\n",
        "import json as js\n",
        "import itertools "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7vT5ltDOvqZ"
      },
      "source": [
        "# 2- Import Python Functions\n",
        "from whoosh.fields import Schema, TEXT, KEYWORD, ID, STORED\n",
        "from whoosh.support.levenshtein import levenshtein\n",
        "from whoosh.support.levenshtein import damerau_levenshtein\n",
        "from IPython.display import clear_output\n",
        "from six.moves import urllib\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import ConfusionMatrixDisplay"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddMwmgqHOvqZ"
      },
      "source": [
        "# 3- Import Python tensorflow library\n",
        "import tensorflow as tf\n",
        "print(tf.version)  # make sure the version is 2.x\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_probability as tfp  # We are using a different module from tensorflow this time\n",
        "import tensorflow.compat.v2.feature_column as fc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hH4zX6WvOvqZ"
      },
      "source": [
        "# 3.1 - Importing drive from google.colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrXwHB_MOvqZ"
      },
      "source": [
        "# 3- JXHALLO Personal Functions for Code\n",
        "\n",
        "# String Normalizer\n",
        "# Version 1.0: 2020-04-10\n",
        "# Returns normalized string without spaces and special characters using RegEx. Then sets lower case\n",
        "\n",
        "def norm (x):\n",
        "    return re.sub(r\"\\s|[^a-z0-9]\",\"\",x.lower(), flags=re.IGNORECASE)\n",
        "\n",
        "# String Exact Comparison\n",
        "# Version 1.0: 2020-04-10\n",
        "# Returns boolean if string comparison is exact.\n",
        "\n",
        "def exact(a,b):\n",
        "    if a is b:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "# Function to access a specific value within an object list\n",
        "# Returns the value of the record with the corresponding key.\n",
        "# Arguments: object that contain the list of keys and values, the key that you want to match to return the value\n",
        "# Special Note: This function will only return the first value of the list.\n",
        "# Special Note2: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Version 1.2: 2020-04-17\n",
        "\n",
        "def multiObjects(values,key):\n",
        "    val = None\n",
        "    for i in range(len(values)):\n",
        "        data = values[i]\n",
        "        for (k, v) in data.items():\n",
        "            if k == key:\n",
        "                val = list(v.split(\", \"))[0].replace(\"[\",\"\").replace(\"]\",\"\").strip()\n",
        "    return val\n",
        "    \n",
        "# Function to access a specific value within an object list\n",
        "# Returns the value of the record of the corresponding key.\n",
        "# Arguments: object that contain the list of keys and values, the key that you want to match to return the value\n",
        "# Special Note: This function will only return the first value of the list.\n",
        "# Special Note2: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Version 1.0: 2020-04-24\n",
        "\n",
        "def identifiersList (column,key):\n",
        "    lineLst = []\n",
        "    for i in range (len(column)):\n",
        "        mpn = multiObjects(column[i],key)\n",
        "        lineLst.append(mpn)\n",
        "    return lineLst\n",
        "    \n",
        "# Damerau–Levenshtein distance similarity function for normalized strings. Caluculates the Damerau–Levenshtein distance between two strings\n",
        "# Then caluclates the similarity dividing the Damerau–Levenshtein distance over the length of the argument (string) with max length\n",
        "# Returns 0 if any of the strings in the function arguments is None\n",
        "# Version 1.2: 2020-10-23\n",
        "# Returns Damerau–Levenshtein distance similarity [0-1]\n",
        "\n",
        "def DL (x,y):\n",
        "    if x is None or y is None:\n",
        "        return 0\n",
        "    else:\n",
        "        x = norm (x)\n",
        "        y = norm (y)\n",
        "        z = max((len(x)),(len(y)))\n",
        "        #return (1-(damerau_levenshtein (x,y)/len(x)))\n",
        "        return abs((1-(damerau_levenshtein (x,y)/z)))\n",
        "    \n",
        "# Calculates the DL for ten (10) pair attributes of a data set, and adds the label and stores them in a matrix [n,11] where n,11 is the label to identify if the reord is duplicated\n",
        "# Returns the matrix with the calucalted DL result for each pair of attributes.\n",
        "# Special Note: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Version 1.3: 2020-04-25\n",
        "\n",
        "    \n",
        "\n",
        "def DLM1 (dset,\n",
        "          left1,right1,\n",
        "          left2,right2,\n",
        "          left3,right3,\n",
        "          left4,right4,\n",
        "          left5,right5,\n",
        "          left6,right6,\n",
        "          left7,right7,\n",
        "          left8,right8,\n",
        "          left9,right9,\n",
        "          left10,right10,\n",
        "          label):\n",
        "    rows=len(dset)\n",
        "    #matrix1 = np.array(np.zeros(rows*11).reshape(rows,11),dtype=object)\n",
        "    matrix1 = np.zeros(rows*11).reshape(rows,11)\n",
        "    for i in range(rows):\n",
        "      if i % 10000 == 0:\n",
        "        print ('row number= ')\n",
        "        print (i)\n",
        "      for j in range(11):\n",
        "            if i % 10000 == 0:\n",
        "                print ('column number= ')\n",
        "                print (j)\n",
        "            if j == 0:\n",
        "                matrix1[i,j] = DL(left1[i],right1[i])\n",
        "            elif j == 1:\n",
        "                matrix1[i,j] = DL(left2[i],right2[i])\n",
        "            elif j == 2:\n",
        "                matrix1[i,j] = DL(left3[i],right3[i])\n",
        "            elif j == 3:\n",
        "                matrix1[i,j] = DL(left4[i],right4[i])\n",
        "            elif j == 4:\n",
        "                matrix1[i,j] = DL(left5[i],right5[i])\n",
        "            elif j == 5:\n",
        "                matrix1[i,j] = DL(left6[i],right6[i])\n",
        "            elif j == 6:\n",
        "                matrix1[i,j] = DL(left7[i],right7[i])\n",
        "            elif j == 7:\n",
        "                matrix1[i,j] = DL(left8[i],right8[i])\n",
        "            elif j == 8:\n",
        "                matrix1[i,j] = DL(left9[i],right9[i])\n",
        "            elif j == 9:\n",
        "                matrix1[i,j] = DL(left10[i],right10[i])\n",
        "            elif j == 10:\n",
        "                matrix1[i,j] = label[i]\n",
        "                \n",
        "    return matrix1\n",
        "    \n",
        "    \n",
        "# Calculates the DL for ten (10) pair attributes of a data set, and adds the pair_id and label and stores them in a matrix [n,12] where n,12 is the BIAS is the number of records\n",
        "# Returns the matrix with the calucalted DL result for each pair of attributes.\n",
        "# Special Note: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Version 1.3: 2020-04-25\n",
        "\n",
        "    \n",
        "\n",
        "def DLM2 (dset,\n",
        "          left1,right1,\n",
        "          left2,right2,\n",
        "          left3,right3,\n",
        "          left4,right4,\n",
        "          left5,right5,\n",
        "          left6,right6,\n",
        "          left7,right7,\n",
        "          left8,right8,\n",
        "          left9,right9,\n",
        "          left10,right10,\n",
        "          pair_id,\n",
        "          label):\n",
        "    rows=len(dset)\n",
        "    matrix1 = np.zeros(rows*12).reshape(rows,12)\n",
        "    for i in range(rows):\n",
        "        for j in range(12):\n",
        "            if j == 0:\n",
        "                matrix1[i,j] = DL(left1[i],right1[i])\n",
        "            elif j == 1:\n",
        "                matrix1[i,j] = DL(left2[i],right2[i])\n",
        "            elif j == 2:\n",
        "                matrix1[i,j] = DL(left3[i],right3[i])\n",
        "            elif j == 3:\n",
        "                matrix1[i,j] = DL(left4[i],right4[i])\n",
        "            elif j == 4:\n",
        "                matrix1[i,j] = DL(left5[i],right5[i])\n",
        "            elif j == 5:\n",
        "                matrix1[i,j] = DL(left6[i],right6[i])\n",
        "            elif j == 6:\n",
        "                matrix1[i,j] = DL(left7[i],right7[i])\n",
        "            elif j == 7:\n",
        "                matrix1[i,j] = DL(left8[i],right8[i])\n",
        "            elif j == 8:\n",
        "                matrix1[i,j] = DL(left9[i],right9[i])\n",
        "            elif j == 9:\n",
        "                matrix1[i,j] = DL(left10[i],right10[i])\n",
        "            elif j == 10:\n",
        "                matrix1[i,j] = pair_id[i]\n",
        "            elif j == 11:\n",
        "                matrix1[i,j] = label[i]\n",
        "                \n",
        "    return matrix1\n",
        "    \n",
        "    \n",
        "# Calculates the DL for ten (10) pair attributes of a data set, and adds the pair_id and label and stores them in a matrix [n,12] where n,12 is the BIAS is the number of records\n",
        "# Returns the matrix with the calucalted DL result for each pair of attributes.\n",
        "# Special Note: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Version 1.3: 2020-04-25\n",
        "\n",
        "    \n",
        "\n",
        "def DLM3 (dset,\n",
        "          left1,right1,\n",
        "          left2,right2,\n",
        "          left3,right3,\n",
        "          left4,right4,\n",
        "          left5,right5,\n",
        "          key1,\n",
        "          key2,\n",
        "          key3,\n",
        "          key4,\n",
        "          key5,\n",
        "          key6,\n",
        "          pair_id,\n",
        "          label):\n",
        "    rows=len(dset)\n",
        "    matrix1 = np.zeros(rows*12).reshape(rows,12)\n",
        "    for i in range(rows):\n",
        "        for j in range(12):\n",
        "            if j == 0:\n",
        "                matrix1[i,j] = DL(left1[i],right1[i])\n",
        "            elif j == 1:\n",
        "                matrix1[i,j] = DL(left2[i],right2[i])\n",
        "            elif j == 2:\n",
        "                matrix1[i,j] = DL(left3[i],right3[i])\n",
        "            elif j == 3:\n",
        "                matrix1[i,j] = DL(left4[i],right4[i])\n",
        "            elif j == 4:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key1)),(multiObjects(right5[i],key1)))\n",
        "            elif j == 5:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key2)),(multiObjects(right5[i],key2)))\n",
        "            elif j == 6:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key3)),(multiObjects(right5[i],key3)))\n",
        "            elif j == 7:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key4)),(multiObjects(right5[i],key4)))\n",
        "            elif j == 8:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key5)),(multiObjects(right5[i],key5)))\n",
        "            elif j == 9:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key6)),(multiObjects(right5[i],key6)))\n",
        "            elif j == 10:\n",
        "                matrix1[i,j] = pair_id[i]\n",
        "            elif j == 11:\n",
        "                matrix1[i,j] = label[i]\n",
        "                \n",
        "    return matrix1\n",
        "\n",
        "# Function to create a new Data Frame with selected columns of a data set.\n",
        "# Returns the new data frame / data set with all the required columns of tuple.\n",
        "# Arguments: Data Set\n",
        "# Special Note: This function will only return as part of the new data frame:\n",
        "# Special Note2: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Will bring data from: \"right\" and \"left\" dat set tuple\n",
        "# Version 1.0: 2020-04-24\n",
        "\n",
        "\n",
        "def dataFileAll (df1):\n",
        "    idLeft = df1.id_left\n",
        "    idRight = df1.id_right\n",
        "    brandListLeft = df1.brand_left\n",
        "    brandListRight = df1.brand_right\n",
        "    categoryListLeft = df1.category_left\n",
        "    categoryListRight = df1.category_right\n",
        "    descriptionListLeft = df1.description_left\n",
        "    descriptionListRight = df1.description_right\n",
        "    titleListLeft = df1.title_left\n",
        "    titleListRight = df1.title_right\n",
        "    gtin8ListLeft = identifiersList(df1.identifiers_left,\"/gtin8\")\n",
        "    gtin8ListRight = identifiersList(df1.identifiers_right,\"/gtin8\")\n",
        "    gtin12ListLeft = identifiersList(df1.identifiers_left,\"/gtin12\")\n",
        "    gtin12ListRight = identifiersList(df1.identifiers_right,\"/gtin12\")\n",
        "    gtin13ListLeft = identifiersList(df1.identifiers_left,\"/gtin13\")\n",
        "    gtin13ListRight = identifiersList(df1.identifiers_right,\"/gtin13\")\n",
        "    gtin14ListLeft = identifiersList(df1.identifiers_left,\"/gtin14\")\n",
        "    gtin14ListRight = identifiersList(df1.identifiers_right,\"/gtin14\")\n",
        "    mpnListLeft = identifiersList(df1.identifiers_left,\"/mpn\")\n",
        "    mpnListRight = identifiersList(df1.identifiers_right,\"/mpn\")\n",
        "    skuListLeft = identifiersList(df1.identifiers_left,\"/sku\")\n",
        "    skuListRight = identifiersList(df1.identifiers_right,\"/sku\")\n",
        "    pairIdList = df1.pair_id\n",
        "    labelList = df1.label\n",
        "    \n",
        "    \n",
        "    zipList = list(zip(idLeft\n",
        "                       ,idRight\n",
        "                       ,brandListLeft\n",
        "                       ,brandListRight\n",
        "                       ,categoryListLeft\n",
        "                       ,categoryListRight\n",
        "                       ,descriptionListLeft\n",
        "                       ,descriptionListRight\n",
        "                       ,titleListLeft\n",
        "                       ,titleListRight\n",
        "                       ,gtin8ListLeft\n",
        "                       ,gtin8ListRight\n",
        "                       ,gtin12ListLeft\n",
        "                       ,gtin12ListRight\n",
        "                       ,gtin13ListLeft\n",
        "                       ,gtin13ListRight\n",
        "                       ,gtin14ListLeft\n",
        "                       ,gtin14ListRight\n",
        "                       ,mpnListLeft\n",
        "                       ,mpnListRight\n",
        "                       ,skuListLeft\n",
        "                       ,skuListRight\n",
        "                       ,pairIdList\n",
        "                       ,labelList\n",
        "                      )\n",
        "                  )\n",
        "    dataObjectLeft = pd.DataFrame(zipList ,columns = [\"idLeft\"\n",
        "                       ,\"idRight\"\n",
        "                       ,\"brandListLeft\"\n",
        "                       ,\"brandListRight\"\n",
        "                       ,\"categoryListLeft\"\n",
        "                       ,\"categoryListRight\"\n",
        "                       ,\"descriptionListLeft\"\n",
        "                       ,\"descriptionListRight\"\n",
        "                       ,\"titleListLeft\"\n",
        "                       ,\"titleListRight\"\n",
        "                       ,\"gtin8ListLeft\"\n",
        "                       ,\"gtin8ListRight\"\n",
        "                       ,\"gtin12ListLeft\"\n",
        "                       ,\"gtin12ListRight\"\n",
        "                       ,\"gtin13ListLeft\"\n",
        "                       ,\"gtin13ListRight\"\n",
        "                       ,\"gtin14ListLeft\"\n",
        "                       ,\"gtin14ListRight\"\n",
        "                       ,\"mpnListLeft\"\n",
        "                       ,\"mpnListRight\"\n",
        "                       ,\"skuListLeft\"\n",
        "                       ,\"skuListRight\"\n",
        "                       ,\"pairIdList\"\n",
        "                       ,\"labelList\"])\n",
        "\n",
        "    return dataObjectLeft"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXdh16SfOvqa"
      },
      "source": [
        "#from google.colab import files\n",
        "#uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBgrLPD1Ovqa"
      },
      "source": [
        "#2020-07-20 Reading AppendedDataFile using pickle\n",
        "#TestDataSet=pd.read_pickle('/Users/juliohallo/Documents/Personal/Maestria 2018/Python/20200720_DataAnalysis/TestDataSet.pkl')\n",
        "import io\n",
        "\n",
        "TestDataSet=pd.read_pickle(io.BytesIO(uploaded['TestDataSet.pkl']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmDtFKC9Ovqa"
      },
      "source": [
        "TestDataSet=pd.DataFrame(None)\n",
        "print (\"TestDataSet.shape\")\n",
        "print (TestDataSet.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ly9cXQY1Ovqa"
      },
      "source": [
        "#2020-08-07 Reading AppendedDataFile using pickle from My drive Google Drive\n",
        "TestDataSet=pd.read_pickle('/content/drive/My Drive/Python/20200720_DataAnalysis/TestDataSet.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkqnJqutOvqa"
      },
      "source": [
        "print (\"TestDataSet.shape\")\n",
        "print (TestDataSet.shape)\n",
        "print (\"TestDataSet.dtypes\")\n",
        "print (TestDataSet.dtypes)\n",
        "print (\"TestDataSet.isnull().sum()\")\n",
        "print (TestDataSet.isnull().sum())\n",
        "TestDataSet = TestDataSet.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoxLczW2Ovqa"
      },
      "source": [
        "# 4.1- JXHALLO Preprocess Data Corpus to dataFileAll\n",
        "\n",
        "# all_train_xlarge_sample.json\n",
        "# Complete Data Catalog available at: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# Data Corpus Explanation available at: http://webdatacommons.org/largescaleproductcorpus/v2/index.html\n",
        "# Will just create a [n,24] dataframe\n",
        "\n",
        "data2 = dataFileAll(TestDataSet)\n",
        "print (data2.shape)\n",
        "print (data2.dtypes)\n",
        "print (data2.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47hjjyC8Ovqb"
      },
      "source": [
        "# Initialize prepocess_dataset DL Similarity Matrix \n",
        "\n",
        "TestDataSetDL2 = DLM1(data2,\n",
        "                     data2.brandListLeft,data2.brandListRight,\n",
        "                     data2.categoryListLeft,data2.categoryListRight,\n",
        "                     data2.descriptionListLeft,data2.descriptionListRight,\n",
        "                     data2.titleListLeft,data2.titleListRight,\n",
        "                     data2.gtin8ListLeft,data2.gtin8ListRight,\n",
        "                     data2.gtin12ListLeft,data2.gtin12ListRight,\n",
        "                     data2.gtin13ListLeft,data2.gtin13ListRight,\n",
        "                     data2.gtin14ListLeft,data2.gtin14ListRight,\n",
        "                     data2.mpnListLeft,data2.mpnListRight,\n",
        "                     data2.skuListLeft,data2.skuListRight,\n",
        "                     data2.labelList)\n",
        "print (\"TestDataSetDL2\")\n",
        "print (TestDataSetDL2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7guoAoB9ZzYn"
      },
      "source": [
        "TestDataSetDL = TestDataSetDL2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M56I4qRZcbHK"
      },
      "source": [
        "print (\"TestDataSetDL\")\n",
        "print (TestDataSetDL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78U5YFdKOvqb"
      },
      "source": [
        "TestDataSetDL[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWATLoM0Ovqb"
      },
      "source": [
        "print (data2.labelList[0])\n",
        "print (data2.categoryListLeft[0])\n",
        "print (data2.categoryListRight[0])\n",
        "print (DL(data2.categoryListLeft[0],data2.categoryListRight[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYx1-_Z0VuYs"
      },
      "source": [
        "print (data2.labelList[0])\n",
        "print (data2.descriptionListLeft[0])\n",
        "print (data2.descriptionListRight[0])\n",
        "print (DL(data2.descriptionListLeft[0],data2.descriptionListRight[0]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ybr824JZWFy"
      },
      "source": [
        "print (len(data2.descriptionListLeft[0]))\n",
        "print (len(data2.descriptionListRight[0]))\n",
        "print (damerau_levenshtein (data2.descriptionListLeft[0],data2.descriptionListRight[0]))\n",
        "print ((damerau_levenshtein (data2.descriptionListLeft[0],data2.descriptionListRight[0]))/(len(data2.descriptionListRight[0])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0B_7VxwOvqe"
      },
      "source": [
        "#numpy.save(file, arr, allow_pickle=True, fix_imports=True)[source]\n",
        "#TestDataSet10DL = asarray (TestDataSet10DL)\n",
        "np.save('/content/drive/My Drive/Python/20200720_DataAnalysis/TestDataSetDL', TestDataSetDL)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQnimQ1wPhT1"
      },
      "source": [
        "#Preprocessing of all_gsDataSet with DL Similarity Matrix\n",
        "2020-10-23 JXHALLO: Re Preprocesing DL all_gsDataSet\n",
        "Adjusting DL Function to use max len of strings as denominator in order to ensure DL returns a number between [0,1]\n",
        "\n",
        "**Preprocessed Data Set Outputs:**\n",
        "\n",
        "* all_gsDataSetDL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUHO1YLHQn-Z"
      },
      "source": [
        "# 0.1 - Import Python Libraries\n",
        "!pip install whoosh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGQvUZazQn-Z"
      },
      "source": [
        "# 1- Import Python Libraries\n",
        "import numpy as np\n",
        "import gensim as gs\n",
        "import re as re\n",
        "import string as st\n",
        "import codecs as co\n",
        "import glob as gl\n",
        "import logging as logger\n",
        "import multiprocessing as mult\n",
        "import os as os\n",
        "import pprint as pp\n",
        "import nltk\n",
        "import gensim.models.word2vec as w2v\n",
        "import sklearn.manifold\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import whoosh as ws\n",
        "import random as ra\n",
        "import csv as csv\n",
        "import scipy as sc\n",
        "import json as js\n",
        "import itertools "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ktir3PFQn-Z"
      },
      "source": [
        "# 2- Import Python Functions\n",
        "from whoosh.fields import Schema, TEXT, KEYWORD, ID, STORED\n",
        "from whoosh.support.levenshtein import levenshtein\n",
        "from whoosh.support.levenshtein import damerau_levenshtein\n",
        "from IPython.display import clear_output\n",
        "from six.moves import urllib\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import ConfusionMatrixDisplay"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "OlBZBfiiQn-Z",
        "outputId": "2fda1037-d449-4d67-ec90-8d1bcf8c12a1"
      },
      "source": [
        "# 3- Import Python tensorflow library\n",
        "import tensorflow as tf\n",
        "print(tf.version)  # make sure the version is 2.x\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_probability as tfp  # We are using a different module from tensorflow this time\n",
        "import tensorflow.compat.v2.feature_column as fc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<module 'tensorflow._api.v2.version' from '/usr/local/lib/python3.6/dist-packages/tensorflow/_api/v2/version/__init__.py'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "ZqIimnIfQn-a",
        "outputId": "c48dae8b-31a1-47d5-a137-896b703bd1e4"
      },
      "source": [
        "# 3.1 - Importing drive from google.colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aUfvEcYQn-a"
      },
      "source": [
        "# 3- JXHALLO Personal Functions for Code\n",
        "\n",
        "# String Normalizer\n",
        "# Version 1.0: 2020-04-10\n",
        "# Returns normalized string without spaces and special characters using RegEx. Then sets lower case\n",
        "\n",
        "def norm (x):\n",
        "    return re.sub(r\"\\s|[^a-z0-9]\",\"\",x.lower(), flags=re.IGNORECASE)\n",
        "\n",
        "# String Exact Comparison\n",
        "# Version 1.0: 2020-04-10\n",
        "# Returns boolean if string comparison is exact.\n",
        "\n",
        "def exact(a,b):\n",
        "    if a is b:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "# Function to access a specific value within an object list\n",
        "# Returns the value of the record with the corresponding key.\n",
        "# Arguments: object that contain the list of keys and values, the key that you want to match to return the value\n",
        "# Special Note: This function will only return the first value of the list.\n",
        "# Special Note2: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Version 1.2: 2020-04-17\n",
        "\n",
        "def multiObjects(values,key):\n",
        "    val = None\n",
        "    for i in range(len(values)):\n",
        "        data = values[i]\n",
        "        for (k, v) in data.items():\n",
        "            if k == key:\n",
        "                val = list(v.split(\", \"))[0].replace(\"[\",\"\").replace(\"]\",\"\").strip()\n",
        "    return val\n",
        "    \n",
        "# Function to access a specific value within an object list\n",
        "# Returns the value of the record of the corresponding key.\n",
        "# Arguments: object that contain the list of keys and values, the key that you want to match to return the value\n",
        "# Special Note: This function will only return the first value of the list.\n",
        "# Special Note2: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Version 1.0: 2020-04-24\n",
        "\n",
        "def identifiersList (column,key):\n",
        "    lineLst = []\n",
        "    for i in range (len(column)):\n",
        "        mpn = multiObjects(column[i],key)\n",
        "        lineLst.append(mpn)\n",
        "    return lineLst\n",
        "    \n",
        "# Damerau–Levenshtein distance similarity function for normalized strings. Caluculates the Damerau–Levenshtein distance between two strings\n",
        "# Then caluclates the similarity dividing the Damerau–Levenshtein distance over the length of the argument (string) with max length\n",
        "# Returns 0 if any of the strings in the function arguments is None\n",
        "# Version 1.2: 2020-10-23\n",
        "# Returns Damerau–Levenshtein distance similarity [0-1]\n",
        "\n",
        "def DL (x,y):\n",
        "    if x is None or y is None:\n",
        "        return 0\n",
        "    else:\n",
        "        x = norm (x)\n",
        "        y = norm (y)\n",
        "        z = max((len(x)),(len(y)))\n",
        "        #return (1-(damerau_levenshtein (x,y)/len(x)))\n",
        "        return abs((1-(damerau_levenshtein (x,y)/z)))\n",
        "    \n",
        "# Calculates the DL for ten (10) pair attributes of a data set, and adds the label and stores them in a matrix [n,11] where n,11 is the label to identify if the reord is duplicated\n",
        "# Returns the matrix with the calucalted DL result for each pair of attributes.\n",
        "# Special Note: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Version 1.3: 2020-04-25\n",
        "\n",
        "    \n",
        "\n",
        "def DLM1 (dset,\n",
        "          left1,right1,\n",
        "          left2,right2,\n",
        "          left3,right3,\n",
        "          left4,right4,\n",
        "          left5,right5,\n",
        "          left6,right6,\n",
        "          left7,right7,\n",
        "          left8,right8,\n",
        "          left9,right9,\n",
        "          left10,right10,\n",
        "          label):\n",
        "    rows=len(dset)\n",
        "    #matrix1 = np.array(np.zeros(rows*11).reshape(rows,11),dtype=object)\n",
        "    matrix1 = np.zeros(rows*11).reshape(rows,11)\n",
        "    for i in range(rows):\n",
        "      if i % 10000 == 0:\n",
        "        print ('row number= ')\n",
        "        print (i)\n",
        "      for j in range(11):\n",
        "            if i % 10000 == 0:\n",
        "                print ('column number= ')\n",
        "                print (j)\n",
        "            if j == 0:\n",
        "                matrix1[i,j] = DL(left1[i],right1[i])\n",
        "            elif j == 1:\n",
        "                matrix1[i,j] = DL(left2[i],right2[i])\n",
        "            elif j == 2:\n",
        "                matrix1[i,j] = DL(left3[i],right3[i])\n",
        "            elif j == 3:\n",
        "                matrix1[i,j] = DL(left4[i],right4[i])\n",
        "            elif j == 4:\n",
        "                matrix1[i,j] = DL(left5[i],right5[i])\n",
        "            elif j == 5:\n",
        "                matrix1[i,j] = DL(left6[i],right6[i])\n",
        "            elif j == 6:\n",
        "                matrix1[i,j] = DL(left7[i],right7[i])\n",
        "            elif j == 7:\n",
        "                matrix1[i,j] = DL(left8[i],right8[i])\n",
        "            elif j == 8:\n",
        "                matrix1[i,j] = DL(left9[i],right9[i])\n",
        "            elif j == 9:\n",
        "                matrix1[i,j] = DL(left10[i],right10[i])\n",
        "            elif j == 10:\n",
        "                matrix1[i,j] = label[i]\n",
        "                \n",
        "    return matrix1\n",
        "    \n",
        "    \n",
        "# Calculates the DL for ten (10) pair attributes of a data set, and adds the pair_id and label and stores them in a matrix [n,12] where n,12 is the BIAS is the number of records\n",
        "# Returns the matrix with the calucalted DL result for each pair of attributes.\n",
        "# Special Note: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Version 1.3: 2020-04-25\n",
        "\n",
        "    \n",
        "\n",
        "def DLM2 (dset,\n",
        "          left1,right1,\n",
        "          left2,right2,\n",
        "          left3,right3,\n",
        "          left4,right4,\n",
        "          left5,right5,\n",
        "          left6,right6,\n",
        "          left7,right7,\n",
        "          left8,right8,\n",
        "          left9,right9,\n",
        "          left10,right10,\n",
        "          pair_id,\n",
        "          label):\n",
        "    rows=len(dset)\n",
        "    matrix1 = np.zeros(rows*12).reshape(rows,12)\n",
        "    for i in range(rows):\n",
        "        for j in range(12):\n",
        "            if j == 0:\n",
        "                matrix1[i,j] = DL(left1[i],right1[i])\n",
        "            elif j == 1:\n",
        "                matrix1[i,j] = DL(left2[i],right2[i])\n",
        "            elif j == 2:\n",
        "                matrix1[i,j] = DL(left3[i],right3[i])\n",
        "            elif j == 3:\n",
        "                matrix1[i,j] = DL(left4[i],right4[i])\n",
        "            elif j == 4:\n",
        "                matrix1[i,j] = DL(left5[i],right5[i])\n",
        "            elif j == 5:\n",
        "                matrix1[i,j] = DL(left6[i],right6[i])\n",
        "            elif j == 6:\n",
        "                matrix1[i,j] = DL(left7[i],right7[i])\n",
        "            elif j == 7:\n",
        "                matrix1[i,j] = DL(left8[i],right8[i])\n",
        "            elif j == 8:\n",
        "                matrix1[i,j] = DL(left9[i],right9[i])\n",
        "            elif j == 9:\n",
        "                matrix1[i,j] = DL(left10[i],right10[i])\n",
        "            elif j == 10:\n",
        "                matrix1[i,j] = pair_id[i]\n",
        "            elif j == 11:\n",
        "                matrix1[i,j] = label[i]\n",
        "                \n",
        "    return matrix1\n",
        "    \n",
        "    \n",
        "# Calculates the DL for ten (10) pair attributes of a data set, and adds the pair_id and label and stores them in a matrix [n,12] where n,12 is the BIAS is the number of records\n",
        "# Returns the matrix with the calucalted DL result for each pair of attributes.\n",
        "# Special Note: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Version 1.3: 2020-04-25\n",
        "\n",
        "    \n",
        "\n",
        "def DLM3 (dset,\n",
        "          left1,right1,\n",
        "          left2,right2,\n",
        "          left3,right3,\n",
        "          left4,right4,\n",
        "          left5,right5,\n",
        "          key1,\n",
        "          key2,\n",
        "          key3,\n",
        "          key4,\n",
        "          key5,\n",
        "          key6,\n",
        "          pair_id,\n",
        "          label):\n",
        "    rows=len(dset)\n",
        "    matrix1 = np.zeros(rows*12).reshape(rows,12)\n",
        "    for i in range(rows):\n",
        "        for j in range(12):\n",
        "            if j == 0:\n",
        "                matrix1[i,j] = DL(left1[i],right1[i])\n",
        "            elif j == 1:\n",
        "                matrix1[i,j] = DL(left2[i],right2[i])\n",
        "            elif j == 2:\n",
        "                matrix1[i,j] = DL(left3[i],right3[i])\n",
        "            elif j == 3:\n",
        "                matrix1[i,j] = DL(left4[i],right4[i])\n",
        "            elif j == 4:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key1)),(multiObjects(right5[i],key1)))\n",
        "            elif j == 5:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key2)),(multiObjects(right5[i],key2)))\n",
        "            elif j == 6:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key3)),(multiObjects(right5[i],key3)))\n",
        "            elif j == 7:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key4)),(multiObjects(right5[i],key4)))\n",
        "            elif j == 8:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key5)),(multiObjects(right5[i],key5)))\n",
        "            elif j == 9:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key6)),(multiObjects(right5[i],key6)))\n",
        "            elif j == 10:\n",
        "                matrix1[i,j] = pair_id[i]\n",
        "            elif j == 11:\n",
        "                matrix1[i,j] = label[i]\n",
        "                \n",
        "    return matrix1\n",
        "\n",
        "# Function to create a new Data Frame with selected columns of a data set.\n",
        "# Returns the new data frame / data set with all the required columns of tuple.\n",
        "# Arguments: Data Set\n",
        "# Special Note: This function will only return as part of the new data frame:\n",
        "# Special Note2: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Will bring data from: \"right\" and \"left\" dat set tuple\n",
        "# Version 1.0: 2020-04-24\n",
        "\n",
        "\n",
        "def dataFileAll (df1):\n",
        "    idLeft = df1.id_left\n",
        "    idRight = df1.id_right\n",
        "    brandListLeft = df1.brand_left\n",
        "    brandListRight = df1.brand_right\n",
        "    categoryListLeft = df1.category_left\n",
        "    categoryListRight = df1.category_right\n",
        "    descriptionListLeft = df1.description_left\n",
        "    descriptionListRight = df1.description_right\n",
        "    titleListLeft = df1.title_left\n",
        "    titleListRight = df1.title_right\n",
        "    gtin8ListLeft = identifiersList(df1.identifiers_left,\"/gtin8\")\n",
        "    gtin8ListRight = identifiersList(df1.identifiers_right,\"/gtin8\")\n",
        "    gtin12ListLeft = identifiersList(df1.identifiers_left,\"/gtin12\")\n",
        "    gtin12ListRight = identifiersList(df1.identifiers_right,\"/gtin12\")\n",
        "    gtin13ListLeft = identifiersList(df1.identifiers_left,\"/gtin13\")\n",
        "    gtin13ListRight = identifiersList(df1.identifiers_right,\"/gtin13\")\n",
        "    gtin14ListLeft = identifiersList(df1.identifiers_left,\"/gtin14\")\n",
        "    gtin14ListRight = identifiersList(df1.identifiers_right,\"/gtin14\")\n",
        "    mpnListLeft = identifiersList(df1.identifiers_left,\"/mpn\")\n",
        "    mpnListRight = identifiersList(df1.identifiers_right,\"/mpn\")\n",
        "    skuListLeft = identifiersList(df1.identifiers_left,\"/sku\")\n",
        "    skuListRight = identifiersList(df1.identifiers_right,\"/sku\")\n",
        "    pairIdList = df1.pair_id\n",
        "    labelList = df1.label\n",
        "    \n",
        "    \n",
        "    zipList = list(zip(idLeft\n",
        "                       ,idRight\n",
        "                       ,brandListLeft\n",
        "                       ,brandListRight\n",
        "                       ,categoryListLeft\n",
        "                       ,categoryListRight\n",
        "                       ,descriptionListLeft\n",
        "                       ,descriptionListRight\n",
        "                       ,titleListLeft\n",
        "                       ,titleListRight\n",
        "                       ,gtin8ListLeft\n",
        "                       ,gtin8ListRight\n",
        "                       ,gtin12ListLeft\n",
        "                       ,gtin12ListRight\n",
        "                       ,gtin13ListLeft\n",
        "                       ,gtin13ListRight\n",
        "                       ,gtin14ListLeft\n",
        "                       ,gtin14ListRight\n",
        "                       ,mpnListLeft\n",
        "                       ,mpnListRight\n",
        "                       ,skuListLeft\n",
        "                       ,skuListRight\n",
        "                       ,pairIdList\n",
        "                       ,labelList\n",
        "                      )\n",
        "                  )\n",
        "    dataObjectLeft = pd.DataFrame(zipList ,columns = [\"idLeft\"\n",
        "                       ,\"idRight\"\n",
        "                       ,\"brandListLeft\"\n",
        "                       ,\"brandListRight\"\n",
        "                       ,\"categoryListLeft\"\n",
        "                       ,\"categoryListRight\"\n",
        "                       ,\"descriptionListLeft\"\n",
        "                       ,\"descriptionListRight\"\n",
        "                       ,\"titleListLeft\"\n",
        "                       ,\"titleListRight\"\n",
        "                       ,\"gtin8ListLeft\"\n",
        "                       ,\"gtin8ListRight\"\n",
        "                       ,\"gtin12ListLeft\"\n",
        "                       ,\"gtin12ListRight\"\n",
        "                       ,\"gtin13ListLeft\"\n",
        "                       ,\"gtin13ListRight\"\n",
        "                       ,\"gtin14ListLeft\"\n",
        "                       ,\"gtin14ListRight\"\n",
        "                       ,\"mpnListLeft\"\n",
        "                       ,\"mpnListRight\"\n",
        "                       ,\"skuListLeft\"\n",
        "                       ,\"skuListRight\"\n",
        "                       ,\"pairIdList\"\n",
        "                       ,\"labelList\"])\n",
        "\n",
        "    return dataObjectLeft"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9SJvCF_Qn-a"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8syTPvf2Qn-a"
      },
      "source": [
        "#2020-07-20 Reading AppendedDataFile using pickle\n",
        "#TestDataSet=pd.read_pickle('/Users/juliohallo/Documents/Personal/Maestria 2018/Python/20200720_DataAnalysis/TestDataSet.pkl')\n",
        "import io\n",
        "\n",
        "TestDataSet=pd.read_pickle(io.BytesIO(uploaded['TestDataSet.pkl']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58OqF0YkQn-a"
      },
      "source": [
        "TestDataSet=pd.DataFrame(None)\n",
        "print (\"TestDataSet.shape\")\n",
        "print (TestDataSet.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odV6Ebu_Qn-b"
      },
      "source": [
        "#2020-08-17 Reading all_gs using pickle from My drive Google Drive\n",
        "#all_gsDataSet=pd.read_pickle('/content/drive/My Drive/Python/20200720_DataAnalysis/TrainDataSet.pkl')\n",
        "\n",
        "url = \"/content/drive/My Drive/Python/Corpus/all_gs.json\"\n",
        "\n",
        "all_gsDataSet = pd.read_json(url,lines=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Y-Z-CwXQn-b"
      },
      "source": [
        "print (\"all_gsDataSet.shape\")\n",
        "print (all_gsDataSet.shape)\n",
        "print (\"all_gsDataSet.dtypes\")\n",
        "print (all_gsDataSet.dtypes)\n",
        "print (\"all_gsDataSet.isnull().sum()\")\n",
        "print (all_gsDataSet.isnull().sum())\n",
        "all_gsDataSet = all_gsDataSet.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uoeq2hiEQn-b"
      },
      "source": [
        "# 4.1- JXHALLO Preprocess Data Corpus to dataFileAll\n",
        "\n",
        "# all_train_xlarge_sample.json\n",
        "# Complete Data Catalog available at: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# Data Corpus Explanation available at: http://webdatacommons.org/largescaleproductcorpus/v2/index.html\n",
        "# Will just create a [n,24] dataframe\n",
        "\n",
        "data2 = dataFileAll(all_gsDataSet)\n",
        "print (data2.shape)\n",
        "print (data2.dtypes)\n",
        "print (data2.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IAGtyw5Qn-b"
      },
      "source": [
        "# Initialize prepocess_dataset DL Similarity Matrix \n",
        "\n",
        "all_gsDataSetDL = DLM1(data2,\n",
        "                     data2.brandListLeft,data2.brandListRight,\n",
        "                     data2.categoryListLeft,data2.categoryListRight,\n",
        "                     data2.descriptionListLeft,data2.descriptionListRight,\n",
        "                     data2.titleListLeft,data2.titleListRight,\n",
        "                     data2.gtin8ListLeft,data2.gtin8ListRight,\n",
        "                     data2.gtin12ListLeft,data2.gtin12ListRight,\n",
        "                     data2.gtin13ListLeft,data2.gtin13ListRight,\n",
        "                     data2.gtin14ListLeft,data2.gtin14ListRight,\n",
        "                     data2.mpnListLeft,data2.mpnListRight,\n",
        "                     data2.skuListLeft,data2.skuListRight,\n",
        "                     data2.labelList)\n",
        "print (\"all_gsDataSetDL\")\n",
        "print (all_gsDataSetDL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0unPsXFHQn-b"
      },
      "source": [
        "all_gsDataSetDL[4399]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTFm8poLQn-b"
      },
      "source": [
        "print (data2.labelList[0])\n",
        "print (data2.categoryListLeft[0])\n",
        "print (data2.categoryListRight[0])\n",
        "print (DL(data2.categoryListLeft[0],data2.categoryListRight[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UprB3o6eQn-b"
      },
      "source": [
        "print (data2.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsCbgwi0Qn-c"
      },
      "source": [
        "\n",
        "print (data2.dtypes)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mmpDdy3Qn-c"
      },
      "source": [
        "\n",
        "print (data2.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9rBEzbnQn-c"
      },
      "source": [
        "#numpy.save(file, arr, allow_pickle=True, fix_imports=True)[source]\n",
        "\n",
        "np.save('/content/drive/My Drive/Python/20200720_DataAnalysis/all_gsDataSetDL', all_gsDataSetDL)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAl_r7xp9pE1"
      },
      "source": [
        "all_gsDataSetDL[0]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvwhZnxY9qyv"
      },
      "source": [
        "all_gsDataSetDL.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rdGCc7kQ2WM"
      },
      "source": [
        "# Preprocessing Data Corpus: Preprocessing of TrainDataSet.pkl to Create 90% Hyperparameter Training Data Set with DL Similarity Matrix\n",
        "2020-11-07 JXHALLO: Re Preprocesing DL TrainingDataSet\n",
        "Adjusting DL Function to use max len of strings as denominator in order to ensure DL returns a number between [0,1]\n",
        "Removing from train data set the validation data set records (10%) to have a clean 90%\n",
        "\n",
        "\n",
        "**Preprocessed Data Set Outputs:**\n",
        "\n",
        "* TrainDataSet90DL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x61YBXTsRjPm"
      },
      "source": [
        "# 0.1 - Import Python Libraries\n",
        "!pip install whoosh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deTCQt7VRjPn"
      },
      "source": [
        "# 1- Import Python Libraries\n",
        "import numpy as np\n",
        "import gensim as gs\n",
        "import re as re\n",
        "import string as st\n",
        "import codecs as co\n",
        "import glob as gl\n",
        "import logging as logger\n",
        "import multiprocessing as mult\n",
        "import os as os\n",
        "import pprint as pp\n",
        "import nltk\n",
        "import gensim.models.word2vec as w2v\n",
        "import sklearn.manifold\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import whoosh as ws\n",
        "import random as ra\n",
        "import csv as csv\n",
        "import scipy as sc\n",
        "import json as js\n",
        "import itertools "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGXZZAvQRjPn"
      },
      "source": [
        "# 2- Import Python Functions\n",
        "from whoosh.fields import Schema, TEXT, KEYWORD, ID, STORED\n",
        "from whoosh.support.levenshtein import levenshtein\n",
        "from whoosh.support.levenshtein import damerau_levenshtein\n",
        "from IPython.display import clear_output\n",
        "from six.moves import urllib\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import ConfusionMatrixDisplay"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3023kNCRjPn"
      },
      "source": [
        "# 3- Import Python tensorflow library\n",
        "import tensorflow as tf\n",
        "print(tf.version)  # make sure the version is 2.x\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_probability as tfp  # We are using a different module from tensorflow this time\n",
        "import tensorflow.compat.v2.feature_column as fc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXEV1yRVRjPo"
      },
      "source": [
        "# 3.1 - Importing drive from google.colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Na_SyzH5RjPo"
      },
      "source": [
        "# 3- JXHALLO Personal Functions for Code\n",
        "\n",
        "# String Normalizer\n",
        "# Version 1.0: 2020-04-10\n",
        "# Returns normalized string without spaces and special characters using RegEx. Then sets lower case\n",
        "\n",
        "def norm (x):\n",
        "    return re.sub(r\"\\s|[^a-z0-9]\",\"\",x.lower(), flags=re.IGNORECASE)\n",
        "\n",
        "# String Exact Comparison\n",
        "# Version 1.0: 2020-04-10\n",
        "# Returns boolean if string comparison is exact.\n",
        "\n",
        "def exact(a,b):\n",
        "    if a is b:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "# Function to access a specific value within an object list\n",
        "# Returns the value of the record with the corresponding key.\n",
        "# Arguments: object that contain the list of keys and values, the key that you want to match to return the value\n",
        "# Special Note: This function will only return the first value of the list.\n",
        "# Special Note2: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Version 1.2: 2020-04-17\n",
        "\n",
        "def multiObjects(values,key):\n",
        "    val = None\n",
        "    for i in range(len(values)):\n",
        "        data = values[i]\n",
        "        for (k, v) in data.items():\n",
        "            if k == key:\n",
        "                val = list(v.split(\", \"))[0].replace(\"[\",\"\").replace(\"]\",\"\").strip()\n",
        "    return val\n",
        "    \n",
        "# Function to access a specific value within an object list\n",
        "# Returns the value of the record of the corresponding key.\n",
        "# Arguments: object that contain the list of keys and values, the key that you want to match to return the value\n",
        "# Special Note: This function will only return the first value of the list.\n",
        "# Special Note2: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Version 1.0: 2020-04-24\n",
        "\n",
        "def identifiersList (column,key):\n",
        "    lineLst = []\n",
        "    for i in range (len(column)):\n",
        "        mpn = multiObjects(column[i],key)\n",
        "        lineLst.append(mpn)\n",
        "    return lineLst\n",
        "    \n",
        "# Damerau–Levenshtein distance similarity function for normalized strings. Caluculates the Damerau–Levenshtein distance between two strings\n",
        "# Then caluclates the similarity dividing the Damerau–Levenshtein distance over the length of the argument (string) with max length\n",
        "# Returns 0 if any of the strings in the function arguments is None\n",
        "# Version 1.2: 2020-10-23\n",
        "# Returns Damerau–Levenshtein distance similarity [0-1]\n",
        "\n",
        "def DL (x,y):\n",
        "    if x is None or y is None:\n",
        "        return 0\n",
        "    else:\n",
        "        x = norm (x)\n",
        "        y = norm (y)\n",
        "        z = max((len(x)),(len(y)))\n",
        "        #return (1-(damerau_levenshtein (x,y)/len(x)))\n",
        "        return abs((1-(damerau_levenshtein (x,y)/z)))\n",
        "    \n",
        "# Calculates the DL for ten (10) pair attributes of a data set, and adds the label and stores them in a matrix [n,11] where n,11 is the label to identify if the reord is duplicated\n",
        "# Returns the matrix with the calucalted DL result for each pair of attributes.\n",
        "# Special Note: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Version 1.3: 2020-04-25\n",
        "\n",
        "    \n",
        "\n",
        "def DLM1 (dset,\n",
        "          left1,right1,\n",
        "          left2,right2,\n",
        "          left3,right3,\n",
        "          left4,right4,\n",
        "          left5,right5,\n",
        "          left6,right6,\n",
        "          left7,right7,\n",
        "          left8,right8,\n",
        "          left9,right9,\n",
        "          left10,right10,\n",
        "          label):\n",
        "    rows=len(dset)\n",
        "    #matrix1 = np.array(np.zeros(rows*11).reshape(rows,11),dtype=object)\n",
        "    matrix1 = np.zeros(rows*11).reshape(rows,11)\n",
        "    for i in range(rows):\n",
        "      if i % 10000 == 0:\n",
        "        print ('row number= ')\n",
        "        print (i)\n",
        "      for j in range(11):\n",
        "            if i % 10000 == 0:\n",
        "                print ('column number= ')\n",
        "                print (j)\n",
        "            if j == 0:\n",
        "                matrix1[i,j] = DL(left1[i],right1[i])\n",
        "            elif j == 1:\n",
        "                matrix1[i,j] = DL(left2[i],right2[i])\n",
        "            elif j == 2:\n",
        "                matrix1[i,j] = DL(left3[i],right3[i])\n",
        "            elif j == 3:\n",
        "                matrix1[i,j] = DL(left4[i],right4[i])\n",
        "            elif j == 4:\n",
        "                matrix1[i,j] = DL(left5[i],right5[i])\n",
        "            elif j == 5:\n",
        "                matrix1[i,j] = DL(left6[i],right6[i])\n",
        "            elif j == 6:\n",
        "                matrix1[i,j] = DL(left7[i],right7[i])\n",
        "            elif j == 7:\n",
        "                matrix1[i,j] = DL(left8[i],right8[i])\n",
        "            elif j == 8:\n",
        "                matrix1[i,j] = DL(left9[i],right9[i])\n",
        "            elif j == 9:\n",
        "                matrix1[i,j] = DL(left10[i],right10[i])\n",
        "            elif j == 10:\n",
        "                matrix1[i,j] = label[i]\n",
        "                \n",
        "    return matrix1\n",
        "    \n",
        "    \n",
        "# Calculates the DL for ten (10) pair attributes of a data set, and adds the pair_id and label and stores them in a matrix [n,12] where n,12 is the BIAS is the number of records\n",
        "# Returns the matrix with the calucalted DL result for each pair of attributes.\n",
        "# Special Note: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Version 1.3: 2020-04-25\n",
        "\n",
        "    \n",
        "\n",
        "def DLM2 (dset,\n",
        "          left1,right1,\n",
        "          left2,right2,\n",
        "          left3,right3,\n",
        "          left4,right4,\n",
        "          left5,right5,\n",
        "          left6,right6,\n",
        "          left7,right7,\n",
        "          left8,right8,\n",
        "          left9,right9,\n",
        "          left10,right10,\n",
        "          pair_id,\n",
        "          label):\n",
        "    rows=len(dset)\n",
        "    matrix1 = np.zeros(rows*12).reshape(rows,12)\n",
        "    for i in range(rows):\n",
        "        for j in range(12):\n",
        "            if j == 0:\n",
        "                matrix1[i,j] = DL(left1[i],right1[i])\n",
        "            elif j == 1:\n",
        "                matrix1[i,j] = DL(left2[i],right2[i])\n",
        "            elif j == 2:\n",
        "                matrix1[i,j] = DL(left3[i],right3[i])\n",
        "            elif j == 3:\n",
        "                matrix1[i,j] = DL(left4[i],right4[i])\n",
        "            elif j == 4:\n",
        "                matrix1[i,j] = DL(left5[i],right5[i])\n",
        "            elif j == 5:\n",
        "                matrix1[i,j] = DL(left6[i],right6[i])\n",
        "            elif j == 6:\n",
        "                matrix1[i,j] = DL(left7[i],right7[i])\n",
        "            elif j == 7:\n",
        "                matrix1[i,j] = DL(left8[i],right8[i])\n",
        "            elif j == 8:\n",
        "                matrix1[i,j] = DL(left9[i],right9[i])\n",
        "            elif j == 9:\n",
        "                matrix1[i,j] = DL(left10[i],right10[i])\n",
        "            elif j == 10:\n",
        "                matrix1[i,j] = pair_id[i]\n",
        "            elif j == 11:\n",
        "                matrix1[i,j] = label[i]\n",
        "                \n",
        "    return matrix1\n",
        "    \n",
        "    \n",
        "# Calculates the DL for ten (10) pair attributes of a data set, and adds the pair_id and label and stores them in a matrix [n,12] where n,12 is the BIAS is the number of records\n",
        "# Returns the matrix with the calucalted DL result for each pair of attributes.\n",
        "# Special Note: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Version 1.3: 2020-04-25\n",
        "\n",
        "    \n",
        "\n",
        "def DLM3 (dset,\n",
        "          left1,right1,\n",
        "          left2,right2,\n",
        "          left3,right3,\n",
        "          left4,right4,\n",
        "          left5,right5,\n",
        "          key1,\n",
        "          key2,\n",
        "          key3,\n",
        "          key4,\n",
        "          key5,\n",
        "          key6,\n",
        "          pair_id,\n",
        "          label):\n",
        "    rows=len(dset)\n",
        "    matrix1 = np.zeros(rows*12).reshape(rows,12)\n",
        "    for i in range(rows):\n",
        "        for j in range(12):\n",
        "            if j == 0:\n",
        "                matrix1[i,j] = DL(left1[i],right1[i])\n",
        "            elif j == 1:\n",
        "                matrix1[i,j] = DL(left2[i],right2[i])\n",
        "            elif j == 2:\n",
        "                matrix1[i,j] = DL(left3[i],right3[i])\n",
        "            elif j == 3:\n",
        "                matrix1[i,j] = DL(left4[i],right4[i])\n",
        "            elif j == 4:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key1)),(multiObjects(right5[i],key1)))\n",
        "            elif j == 5:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key2)),(multiObjects(right5[i],key2)))\n",
        "            elif j == 6:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key3)),(multiObjects(right5[i],key3)))\n",
        "            elif j == 7:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key4)),(multiObjects(right5[i],key4)))\n",
        "            elif j == 8:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key5)),(multiObjects(right5[i],key5)))\n",
        "            elif j == 9:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key6)),(multiObjects(right5[i],key6)))\n",
        "            elif j == 10:\n",
        "                matrix1[i,j] = pair_id[i]\n",
        "            elif j == 11:\n",
        "                matrix1[i,j] = label[i]\n",
        "                \n",
        "    return matrix1\n",
        "\n",
        "# Function to create a new Data Frame with selected columns of a data set.\n",
        "# Returns the new data frame / data set with all the required columns of tuple.\n",
        "# Arguments: Data Set\n",
        "# Special Note: This function will only return as part of the new data frame:\n",
        "# Special Note2: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Will bring data from: \"right\" and \"left\" dat set tuple\n",
        "# Version 1.0: 2020-04-24\n",
        "\n",
        "\n",
        "def dataFileAll (df1):\n",
        "    idLeft = df1.id_left\n",
        "    idRight = df1.id_right\n",
        "    brandListLeft = df1.brand_left\n",
        "    brandListRight = df1.brand_right\n",
        "    categoryListLeft = df1.category_left\n",
        "    categoryListRight = df1.category_right\n",
        "    descriptionListLeft = df1.description_left\n",
        "    descriptionListRight = df1.description_right\n",
        "    titleListLeft = df1.title_left\n",
        "    titleListRight = df1.title_right\n",
        "    gtin8ListLeft = identifiersList(df1.identifiers_left,\"/gtin8\")\n",
        "    gtin8ListRight = identifiersList(df1.identifiers_right,\"/gtin8\")\n",
        "    gtin12ListLeft = identifiersList(df1.identifiers_left,\"/gtin12\")\n",
        "    gtin12ListRight = identifiersList(df1.identifiers_right,\"/gtin12\")\n",
        "    gtin13ListLeft = identifiersList(df1.identifiers_left,\"/gtin13\")\n",
        "    gtin13ListRight = identifiersList(df1.identifiers_right,\"/gtin13\")\n",
        "    gtin14ListLeft = identifiersList(df1.identifiers_left,\"/gtin14\")\n",
        "    gtin14ListRight = identifiersList(df1.identifiers_right,\"/gtin14\")\n",
        "    mpnListLeft = identifiersList(df1.identifiers_left,\"/mpn\")\n",
        "    mpnListRight = identifiersList(df1.identifiers_right,\"/mpn\")\n",
        "    skuListLeft = identifiersList(df1.identifiers_left,\"/sku\")\n",
        "    skuListRight = identifiersList(df1.identifiers_right,\"/sku\")\n",
        "    pairIdList = df1.pair_id\n",
        "    labelList = df1.label\n",
        "    \n",
        "    \n",
        "    zipList = list(zip(idLeft\n",
        "                       ,idRight\n",
        "                       ,brandListLeft\n",
        "                       ,brandListRight\n",
        "                       ,categoryListLeft\n",
        "                       ,categoryListRight\n",
        "                       ,descriptionListLeft\n",
        "                       ,descriptionListRight\n",
        "                       ,titleListLeft\n",
        "                       ,titleListRight\n",
        "                       ,gtin8ListLeft\n",
        "                       ,gtin8ListRight\n",
        "                       ,gtin12ListLeft\n",
        "                       ,gtin12ListRight\n",
        "                       ,gtin13ListLeft\n",
        "                       ,gtin13ListRight\n",
        "                       ,gtin14ListLeft\n",
        "                       ,gtin14ListRight\n",
        "                       ,mpnListLeft\n",
        "                       ,mpnListRight\n",
        "                       ,skuListLeft\n",
        "                       ,skuListRight\n",
        "                       ,pairIdList\n",
        "                       ,labelList\n",
        "                      )\n",
        "                  )\n",
        "    dataObjectLeft = pd.DataFrame(zipList ,columns = [\"idLeft\"\n",
        "                       ,\"idRight\"\n",
        "                       ,\"brandListLeft\"\n",
        "                       ,\"brandListRight\"\n",
        "                       ,\"categoryListLeft\"\n",
        "                       ,\"categoryListRight\"\n",
        "                       ,\"descriptionListLeft\"\n",
        "                       ,\"descriptionListRight\"\n",
        "                       ,\"titleListLeft\"\n",
        "                       ,\"titleListRight\"\n",
        "                       ,\"gtin8ListLeft\"\n",
        "                       ,\"gtin8ListRight\"\n",
        "                       ,\"gtin12ListLeft\"\n",
        "                       ,\"gtin12ListRight\"\n",
        "                       ,\"gtin13ListLeft\"\n",
        "                       ,\"gtin13ListRight\"\n",
        "                       ,\"gtin14ListLeft\"\n",
        "                       ,\"gtin14ListRight\"\n",
        "                       ,\"mpnListLeft\"\n",
        "                       ,\"mpnListRight\"\n",
        "                       ,\"skuListLeft\"\n",
        "                       ,\"skuListRight\"\n",
        "                       ,\"pairIdList\"\n",
        "                       ,\"labelList\"])\n",
        "\n",
        "    return dataObjectLeft"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwHSstjgRjPq"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdv6td_4RjPq"
      },
      "source": [
        "#2020-07-20 Reading AppendedDataFile using pickle\n",
        "#TestDataSet=pd.read_pickle('/Users/juliohallo/Documents/Personal/Maestria 2018/Python/20200720_DataAnalysis/TestDataSet.pkl')\n",
        "import io\n",
        "\n",
        "TestDataSet=pd.read_pickle(io.BytesIO(uploaded['TestDataSet.pkl']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZDqkxn4RjPq"
      },
      "source": [
        "TestDataSet=pd.DataFrame(None)\n",
        "print (\"TestDataSet.shape\")\n",
        "print (TestDataSet.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjgYZokuRjPq"
      },
      "source": [
        "#2020-08-07 Reading TrainDataSet using pickle from My drive Google Drive\n",
        "TrainDataSet=pd.read_pickle('/content/drive/My Drive/Python/20200720_DataAnalysis/TrainDataSet.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7P5IO5ztTUr"
      },
      "source": [
        "#2020-08-07 Reading AppendedDataFile using pickle from My drive Google Drive\n",
        "TrainDataSet90=pd.read_pickle('/content/drive/My Drive/Python/20200720_DataAnalysis/TrainDataSet90.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCXSMrvNxnwM"
      },
      "source": [
        "#2020-11-07 Reading TrainDataSet90 using pickle from My drive Google Drive\n",
        "ValidationDataSet10=pd.read_pickle('/content/drive/My Drive/Python/20200720_DataAnalysis/ValidationDataSet10.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqWaQiwhRjPq"
      },
      "source": [
        "print (\"TrainDataSet.shape\")\n",
        "print (TrainDataSet.shape)\n",
        "print (\"TrainDataSet.dtypes\")\n",
        "print (TrainDataSet.dtypes)\n",
        "print (\"TrainDataSet.isnull().sum()\")\n",
        "print (TrainDataSet.isnull().sum())\n",
        "TrainDataSet = TrainDataSet.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsTBhCxVRjPr"
      },
      "source": [
        "print (\"ValidationDataSet10.shape\")\n",
        "print (ValidationDataSet10.shape)\n",
        "print (\"ValidationDataSet10.dtypes\")\n",
        "print (ValidationDataSet10.dtypes)\n",
        "print (\"ValidationDataSet10.isnull().sum()\")\n",
        "print (ValidationDataSet10.isnull().sum())\n",
        "ValidationDataSet10 = ValidationDataSet10.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6ReAoPmt7dC"
      },
      "source": [
        "#2020-11-07 JXHALLO: Removing from TrainDataSet the ValidationDataSet10 records.\n",
        "#TrainDataSet90 = pd.merge (TrainDataSet, ValidationDataSet10, how='outer', indicator=True)\n",
        "cond = TrainDataSet['pair_id'].isin(ValidationDataSet10['pair_id'])\n",
        "TrainDataSet.drop(TrainDataSet[cond].index, inplace = True)\n",
        "TrainDataSet90 = TrainDataSet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d28vhPHZvp5R"
      },
      "source": [
        "print (\"TrainDataSet90.shape\")\n",
        "print (TrainDataSet90.shape)\n",
        "print (\"TrainDataSet90.dtypes\")\n",
        "print (TrainDataSet90.dtypes)\n",
        "print (\"TrainDataSet90.isnull().sum()\")\n",
        "print (TrainDataSet90.isnull().sum())\n",
        "TrainDataSet90 = TrainDataSet90.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWcLw0GERjPs"
      },
      "source": [
        "# 4.1- JXHALLO Preprocess Data Corpus to dataFileAll\n",
        "\n",
        "# all_train_xlarge_sample.json\n",
        "# Complete Data Catalog available at: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# Data Corpus Explanation available at: http://webdatacommons.org/largescaleproductcorpus/v2/index.html\n",
        "# Will just create a [n,24] dataframe\n",
        "\n",
        "data2 = dataFileAll(TrainDataSet90)\n",
        "print (data2.shape)\n",
        "print (data2.dtypes)\n",
        "print (data2.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNrUnQ5wRjPs"
      },
      "source": [
        "# Initialize prepocess_dataset DL Similarity Matrix \n",
        "\n",
        "TrainDataSet90DL = DLM1(data2,\n",
        "                     data2.brandListLeft,data2.brandListRight,\n",
        "                     data2.categoryListLeft,data2.categoryListRight,\n",
        "                     data2.descriptionListLeft,data2.descriptionListRight,\n",
        "                     data2.titleListLeft,data2.titleListRight,\n",
        "                     data2.gtin8ListLeft,data2.gtin8ListRight,\n",
        "                     data2.gtin12ListLeft,data2.gtin12ListRight,\n",
        "                     data2.gtin13ListLeft,data2.gtin13ListRight,\n",
        "                     data2.gtin14ListLeft,data2.gtin14ListRight,\n",
        "                     data2.mpnListLeft,data2.mpnListRight,\n",
        "                     data2.skuListLeft,data2.skuListRight,\n",
        "                     data2.labelList)\n",
        "print (\"TrainDataSet90DL\")\n",
        "print (TrainDataSet90DL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwyUQV1cRjPs"
      },
      "source": [
        "TrainDataSet90DL[35563]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIQBDZzHRjPs"
      },
      "source": [
        "print (data2.labelList[35563])\n",
        "print (data2.categoryListLeft[35563])\n",
        "print (data2.categoryListRight[35563])\n",
        "print (DL(data2.categoryListLeft[35563],data2.categoryListRight[35563]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-LvUx0aRjPs"
      },
      "source": [
        "print (data2.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUeVXqiiRjPt"
      },
      "source": [
        "\n",
        "print (data2.dtypes)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0BzE2I8RjPt"
      },
      "source": [
        "\n",
        "print (data2.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekRJPLG-RjPt"
      },
      "source": [
        "#numpy.save(file, arr, allow_pickle=True, fix_imports=True)[source]\n",
        "\n",
        "np.save('/content/drive/My Drive/Python/20200720_DataAnalysis/TrainDataSet90DL', TrainDataSet90DL)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSYAY7l2RjPt"
      },
      "source": [
        "TrainDataSet90DL[0]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZzcDPCWRjPt"
      },
      "source": [
        "TrainDataSet90DL.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOQREvkBRzMs"
      },
      "source": [
        "# Preprocessing Data Corpus: Preprocessing of TrainDataSet.pkl to Create 10% Hyperparameter Validation Data Set with DL Similarity Matrix\n",
        "2020-11-07 JXHALLO: Re Preprocesing DL TrainingDataSet\n",
        "Adjusting DL Function to use max len of strings as denominator in order to ensure DL returns a number between [0,1]\n",
        "Removing from train data set the train data set records (90%) to have a clean 10%\n",
        "\n",
        "\n",
        "**Preprocessed Data Set Outputs:**\n",
        "\n",
        "* ValidationDataSet10DL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcyPuzKJSO3E",
        "outputId": "75cd0698-4686-4058-cabe-08dce2e0c883"
      },
      "source": [
        "# 0.1 - Import Python Libraries\n",
        "!pip install whoosh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: whoosh in /usr/local/lib/python3.6/dist-packages (2.7.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvMUq0t3SO3E"
      },
      "source": [
        "# 1- Import Python Libraries\n",
        "import numpy as np\n",
        "import gensim as gs\n",
        "import re as re\n",
        "import string as st\n",
        "import codecs as co\n",
        "import glob as gl\n",
        "import logging as logger\n",
        "import multiprocessing as mult\n",
        "import os as os\n",
        "import pprint as pp\n",
        "import nltk\n",
        "import gensim.models.word2vec as w2v\n",
        "import sklearn.manifold\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import whoosh as ws\n",
        "import random as ra\n",
        "import csv as csv\n",
        "import scipy as sc\n",
        "import json as js\n",
        "import itertools "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FYZ_2ZrSO3F"
      },
      "source": [
        "# 2- Import Python Functions\n",
        "from whoosh.fields import Schema, TEXT, KEYWORD, ID, STORED\n",
        "from whoosh.support.levenshtein import levenshtein\n",
        "from whoosh.support.levenshtein import damerau_levenshtein\n",
        "from IPython.display import clear_output\n",
        "from six.moves import urllib\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import ConfusionMatrixDisplay"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gd8rN5EISO3F",
        "outputId": "fb316ba0-f44e-42f4-af9e-dbd92efadb70"
      },
      "source": [
        "# 3- Import Python tensorflow library\n",
        "import tensorflow as tf\n",
        "print(tf.version)  # make sure the version is 2.x\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_probability as tfp  # We are using a different module from tensorflow this time\n",
        "import tensorflow.compat.v2.feature_column as fc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<module 'tensorflow._api.v2.version' from '/usr/local/lib/python3.6/dist-packages/tensorflow/_api/v2/version/__init__.py'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Srma3QZlSO3F",
        "outputId": "013a6eeb-b3d6-4de3-a096-639c4d458837"
      },
      "source": [
        "# 3.1 - Importing drive from google.colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7go_TpK6SO3F"
      },
      "source": [
        "# 3- JXHALLO Personal Functions for Code\n",
        "\n",
        "# String Normalizer\n",
        "# Version 1.0: 2020-04-10\n",
        "# Returns normalized string without spaces and special characters using RegEx. Then sets lower case\n",
        "\n",
        "def norm (x):\n",
        "    return re.sub(r\"\\s|[^a-z0-9]\",\"\",x.lower(), flags=re.IGNORECASE)\n",
        "\n",
        "# String Exact Comparison\n",
        "# Version 1.0: 2020-04-10\n",
        "# Returns boolean if string comparison is exact.\n",
        "\n",
        "def exact(a,b):\n",
        "    if a is b:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "# Function to access a specific value within an object list\n",
        "# Returns the value of the record with the corresponding key.\n",
        "# Arguments: object that contain the list of keys and values, the key that you want to match to return the value\n",
        "# Special Note: This function will only return the first value of the list.\n",
        "# Special Note2: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Version 1.2: 2020-04-17\n",
        "\n",
        "def multiObjects(values,key):\n",
        "    val = None\n",
        "    for i in range(len(values)):\n",
        "        data = values[i]\n",
        "        for (k, v) in data.items():\n",
        "            if k == key:\n",
        "                val = list(v.split(\", \"))[0].replace(\"[\",\"\").replace(\"]\",\"\").strip()\n",
        "    return val\n",
        "    \n",
        "# Function to access a specific value within an object list\n",
        "# Returns the value of the record of the corresponding key.\n",
        "# Arguments: object that contain the list of keys and values, the key that you want to match to return the value\n",
        "# Special Note: This function will only return the first value of the list.\n",
        "# Special Note2: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Version 1.0: 2020-04-24\n",
        "\n",
        "def identifiersList (column,key):\n",
        "    lineLst = []\n",
        "    for i in range (len(column)):\n",
        "        mpn = multiObjects(column[i],key)\n",
        "        lineLst.append(mpn)\n",
        "    return lineLst\n",
        "    \n",
        "# Damerau–Levenshtein distance similarity function for normalized strings. Caluculates the Damerau–Levenshtein distance between two strings\n",
        "# Then caluclates the similarity dividing the Damerau–Levenshtein distance over the length of the argument (string) with max length\n",
        "# Returns 0 if any of the strings in the function arguments is None\n",
        "# Version 1.2: 2020-10-23\n",
        "# Returns Damerau–Levenshtein distance similarity [0-1]\n",
        "\n",
        "def DL (x,y):\n",
        "    if x is None or y is None:\n",
        "        return 0\n",
        "    else:\n",
        "        x = norm (x)\n",
        "        y = norm (y)\n",
        "        z = max((len(x)),(len(y)))\n",
        "        #return (1-(damerau_levenshtein (x,y)/len(x)))\n",
        "        return abs((1-(damerau_levenshtein (x,y)/z)))\n",
        "    \n",
        "# Calculates the DL for ten (10) pair attributes of a data set, and adds the label and stores them in a matrix [n,11] where n,11 is the label to identify if the reord is duplicated\n",
        "# Returns the matrix with the calucalted DL result for each pair of attributes.\n",
        "# Special Note: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Version 1.3: 2020-04-25\n",
        "\n",
        "    \n",
        "\n",
        "def DLM1 (dset,\n",
        "          left1,right1,\n",
        "          left2,right2,\n",
        "          left3,right3,\n",
        "          left4,right4,\n",
        "          left5,right5,\n",
        "          left6,right6,\n",
        "          left7,right7,\n",
        "          left8,right8,\n",
        "          left9,right9,\n",
        "          left10,right10,\n",
        "          label):\n",
        "    rows=len(dset)\n",
        "    #matrix1 = np.array(np.zeros(rows*11).reshape(rows,11),dtype=object)\n",
        "    matrix1 = np.zeros(rows*11).reshape(rows,11)\n",
        "    for i in range(rows):\n",
        "      if i % 10000 == 0:\n",
        "        print ('row number= ')\n",
        "        print (i)\n",
        "      for j in range(11):\n",
        "            if i % 10000 == 0:\n",
        "                print ('column number= ')\n",
        "                print (j)\n",
        "            if j == 0:\n",
        "                matrix1[i,j] = DL(left1[i],right1[i])\n",
        "            elif j == 1:\n",
        "                matrix1[i,j] = DL(left2[i],right2[i])\n",
        "            elif j == 2:\n",
        "                matrix1[i,j] = DL(left3[i],right3[i])\n",
        "            elif j == 3:\n",
        "                matrix1[i,j] = DL(left4[i],right4[i])\n",
        "            elif j == 4:\n",
        "                matrix1[i,j] = DL(left5[i],right5[i])\n",
        "            elif j == 5:\n",
        "                matrix1[i,j] = DL(left6[i],right6[i])\n",
        "            elif j == 6:\n",
        "                matrix1[i,j] = DL(left7[i],right7[i])\n",
        "            elif j == 7:\n",
        "                matrix1[i,j] = DL(left8[i],right8[i])\n",
        "            elif j == 8:\n",
        "                matrix1[i,j] = DL(left9[i],right9[i])\n",
        "            elif j == 9:\n",
        "                matrix1[i,j] = DL(left10[i],right10[i])\n",
        "            elif j == 10:\n",
        "                matrix1[i,j] = label[i]\n",
        "                \n",
        "    return matrix1\n",
        "    \n",
        "    \n",
        "# Calculates the DL for ten (10) pair attributes of a data set, and adds the pair_id and label and stores them in a matrix [n,12] where n,12 is the BIAS is the number of records\n",
        "# Returns the matrix with the calucalted DL result for each pair of attributes.\n",
        "# Special Note: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Version 1.3: 2020-04-25\n",
        "\n",
        "    \n",
        "\n",
        "def DLM2 (dset,\n",
        "          left1,right1,\n",
        "          left2,right2,\n",
        "          left3,right3,\n",
        "          left4,right4,\n",
        "          left5,right5,\n",
        "          left6,right6,\n",
        "          left7,right7,\n",
        "          left8,right8,\n",
        "          left9,right9,\n",
        "          left10,right10,\n",
        "          pair_id,\n",
        "          label):\n",
        "    rows=len(dset)\n",
        "    matrix1 = np.zeros(rows*12).reshape(rows,12)\n",
        "    for i in range(rows):\n",
        "        for j in range(12):\n",
        "            if j == 0:\n",
        "                matrix1[i,j] = DL(left1[i],right1[i])\n",
        "            elif j == 1:\n",
        "                matrix1[i,j] = DL(left2[i],right2[i])\n",
        "            elif j == 2:\n",
        "                matrix1[i,j] = DL(left3[i],right3[i])\n",
        "            elif j == 3:\n",
        "                matrix1[i,j] = DL(left4[i],right4[i])\n",
        "            elif j == 4:\n",
        "                matrix1[i,j] = DL(left5[i],right5[i])\n",
        "            elif j == 5:\n",
        "                matrix1[i,j] = DL(left6[i],right6[i])\n",
        "            elif j == 6:\n",
        "                matrix1[i,j] = DL(left7[i],right7[i])\n",
        "            elif j == 7:\n",
        "                matrix1[i,j] = DL(left8[i],right8[i])\n",
        "            elif j == 8:\n",
        "                matrix1[i,j] = DL(left9[i],right9[i])\n",
        "            elif j == 9:\n",
        "                matrix1[i,j] = DL(left10[i],right10[i])\n",
        "            elif j == 10:\n",
        "                matrix1[i,j] = pair_id[i]\n",
        "            elif j == 11:\n",
        "                matrix1[i,j] = label[i]\n",
        "                \n",
        "    return matrix1\n",
        "    \n",
        "    \n",
        "# Calculates the DL for ten (10) pair attributes of a data set, and adds the pair_id and label and stores them in a matrix [n,12] where n,12 is the BIAS is the number of records\n",
        "# Returns the matrix with the calucalted DL result for each pair of attributes.\n",
        "# Special Note: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Version 1.3: 2020-04-25\n",
        "\n",
        "    \n",
        "\n",
        "def DLM3 (dset,\n",
        "          left1,right1,\n",
        "          left2,right2,\n",
        "          left3,right3,\n",
        "          left4,right4,\n",
        "          left5,right5,\n",
        "          key1,\n",
        "          key2,\n",
        "          key3,\n",
        "          key4,\n",
        "          key5,\n",
        "          key6,\n",
        "          pair_id,\n",
        "          label):\n",
        "    rows=len(dset)\n",
        "    matrix1 = np.zeros(rows*12).reshape(rows,12)\n",
        "    for i in range(rows):\n",
        "        for j in range(12):\n",
        "            if j == 0:\n",
        "                matrix1[i,j] = DL(left1[i],right1[i])\n",
        "            elif j == 1:\n",
        "                matrix1[i,j] = DL(left2[i],right2[i])\n",
        "            elif j == 2:\n",
        "                matrix1[i,j] = DL(left3[i],right3[i])\n",
        "            elif j == 3:\n",
        "                matrix1[i,j] = DL(left4[i],right4[i])\n",
        "            elif j == 4:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key1)),(multiObjects(right5[i],key1)))\n",
        "            elif j == 5:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key2)),(multiObjects(right5[i],key2)))\n",
        "            elif j == 6:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key3)),(multiObjects(right5[i],key3)))\n",
        "            elif j == 7:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key4)),(multiObjects(right5[i],key4)))\n",
        "            elif j == 8:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key5)),(multiObjects(right5[i],key5)))\n",
        "            elif j == 9:\n",
        "                matrix1[i,j] = DL((multiObjects(left5[i],key6)),(multiObjects(right5[i],key6)))\n",
        "            elif j == 10:\n",
        "                matrix1[i,j] = pair_id[i]\n",
        "            elif j == 11:\n",
        "                matrix1[i,j] = label[i]\n",
        "                \n",
        "    return matrix1\n",
        "\n",
        "# Function to create a new Data Frame with selected columns of a data set.\n",
        "# Returns the new data frame / data set with all the required columns of tuple.\n",
        "# Arguments: Data Set\n",
        "# Special Note: This function will only return as part of the new data frame:\n",
        "# Special Note2: This function has been designed specifically for the data sets of the Corpus: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# For the data sets: XX_train_[size].json, XX_js.json and its respective sample data sets.\n",
        "# Will bring data from: \"right\" and \"left\" dat set tuple\n",
        "# Version 1.0: 2020-04-24\n",
        "\n",
        "\n",
        "def dataFileAll (df1):\n",
        "    idLeft = df1.id_left\n",
        "    idRight = df1.id_right\n",
        "    brandListLeft = df1.brand_left\n",
        "    brandListRight = df1.brand_right\n",
        "    categoryListLeft = df1.category_left\n",
        "    categoryListRight = df1.category_right\n",
        "    descriptionListLeft = df1.description_left\n",
        "    descriptionListRight = df1.description_right\n",
        "    titleListLeft = df1.title_left\n",
        "    titleListRight = df1.title_right\n",
        "    gtin8ListLeft = identifiersList(df1.identifiers_left,\"/gtin8\")\n",
        "    gtin8ListRight = identifiersList(df1.identifiers_right,\"/gtin8\")\n",
        "    gtin12ListLeft = identifiersList(df1.identifiers_left,\"/gtin12\")\n",
        "    gtin12ListRight = identifiersList(df1.identifiers_right,\"/gtin12\")\n",
        "    gtin13ListLeft = identifiersList(df1.identifiers_left,\"/gtin13\")\n",
        "    gtin13ListRight = identifiersList(df1.identifiers_right,\"/gtin13\")\n",
        "    gtin14ListLeft = identifiersList(df1.identifiers_left,\"/gtin14\")\n",
        "    gtin14ListRight = identifiersList(df1.identifiers_right,\"/gtin14\")\n",
        "    mpnListLeft = identifiersList(df1.identifiers_left,\"/mpn\")\n",
        "    mpnListRight = identifiersList(df1.identifiers_right,\"/mpn\")\n",
        "    skuListLeft = identifiersList(df1.identifiers_left,\"/sku\")\n",
        "    skuListRight = identifiersList(df1.identifiers_right,\"/sku\")\n",
        "    pairIdList = df1.pair_id\n",
        "    labelList = df1.label\n",
        "    \n",
        "    \n",
        "    zipList = list(zip(idLeft\n",
        "                       ,idRight\n",
        "                       ,brandListLeft\n",
        "                       ,brandListRight\n",
        "                       ,categoryListLeft\n",
        "                       ,categoryListRight\n",
        "                       ,descriptionListLeft\n",
        "                       ,descriptionListRight\n",
        "                       ,titleListLeft\n",
        "                       ,titleListRight\n",
        "                       ,gtin8ListLeft\n",
        "                       ,gtin8ListRight\n",
        "                       ,gtin12ListLeft\n",
        "                       ,gtin12ListRight\n",
        "                       ,gtin13ListLeft\n",
        "                       ,gtin13ListRight\n",
        "                       ,gtin14ListLeft\n",
        "                       ,gtin14ListRight\n",
        "                       ,mpnListLeft\n",
        "                       ,mpnListRight\n",
        "                       ,skuListLeft\n",
        "                       ,skuListRight\n",
        "                       ,pairIdList\n",
        "                       ,labelList\n",
        "                      )\n",
        "                  )\n",
        "    dataObjectLeft = pd.DataFrame(zipList ,columns = [\"idLeft\"\n",
        "                       ,\"idRight\"\n",
        "                       ,\"brandListLeft\"\n",
        "                       ,\"brandListRight\"\n",
        "                       ,\"categoryListLeft\"\n",
        "                       ,\"categoryListRight\"\n",
        "                       ,\"descriptionListLeft\"\n",
        "                       ,\"descriptionListRight\"\n",
        "                       ,\"titleListLeft\"\n",
        "                       ,\"titleListRight\"\n",
        "                       ,\"gtin8ListLeft\"\n",
        "                       ,\"gtin8ListRight\"\n",
        "                       ,\"gtin12ListLeft\"\n",
        "                       ,\"gtin12ListRight\"\n",
        "                       ,\"gtin13ListLeft\"\n",
        "                       ,\"gtin13ListRight\"\n",
        "                       ,\"gtin14ListLeft\"\n",
        "                       ,\"gtin14ListRight\"\n",
        "                       ,\"mpnListLeft\"\n",
        "                       ,\"mpnListRight\"\n",
        "                       ,\"skuListLeft\"\n",
        "                       ,\"skuListRight\"\n",
        "                       ,\"pairIdList\"\n",
        "                       ,\"labelList\"])\n",
        "\n",
        "    return dataObjectLeft"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aRq4u4xSO3H"
      },
      "source": [
        "#from google.colab import files\n",
        "#uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8aFCUXiSO3H"
      },
      "source": [
        "#2020-07-20 Reading AppendedDataFile using pickle\n",
        "#TestDataSet=pd.read_pickle('/Users/juliohallo/Documents/Personal/Maestria 2018/Python/20200720_DataAnalysis/TestDataSet.pkl')\n",
        "import io\n",
        "\n",
        "ValidationDataSet10=pd.read_pickle(io.BytesIO(uploaded['ValidationDataSet10.pkl']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzYeaoeVSO3H"
      },
      "source": [
        "ValidationDataSet10=pd.DataFrame(None)\n",
        "print (\"ValidationDataSet10.shape\")\n",
        "print (ValidationDataSet10.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpHcqiggSO3H"
      },
      "source": [
        "#2020-08-07 Reading AppendedDataFile using pickle from My drive Google Drive\n",
        "ValidationDataSet10=pd.read_pickle('/content/drive/My Drive/Python/20200720_DataAnalysis/ValidationDataSet10.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0U87R6ljSO3H"
      },
      "source": [
        "print (\"ValidationDataSet10.shape\")\n",
        "print (ValidationDataSet10.shape)\n",
        "print (\"ValidationDataSet10.dtypes\")\n",
        "print (ValidationDataSet10.dtypes)\n",
        "print (\"ValidationDataSet10.isnull().sum()\")\n",
        "print (ValidationDataSet10.isnull().sum())\n",
        "ValidationDataSet10 = ValidationDataSet10.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mC292wkTSO3I"
      },
      "source": [
        "# 4.1- JXHALLO Preprocess Data Corpus to dataFileAll\n",
        "\n",
        "# all_train_xlarge_sample.json\n",
        "# Complete Data Catalog available at: http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/\n",
        "# Data Corpus Explanation available at: http://webdatacommons.org/largescaleproductcorpus/v2/index.html\n",
        "# Will just create a [n,24] dataframe\n",
        "\n",
        "data2 = dataFileAll(ValidationDataSet10)\n",
        "print (data2.shape)\n",
        "print (data2.dtypes)\n",
        "print (data2.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbriwx86SO3I"
      },
      "source": [
        "# Initialize prepocess_dataset DL Similarity Matrix \n",
        "\n",
        "ValidationDataSet10DL2 = DLM1(data2,\n",
        "                     data2.brandListLeft,data2.brandListRight,\n",
        "                     data2.categoryListLeft,data2.categoryListRight,\n",
        "                     data2.descriptionListLeft,data2.descriptionListRight,\n",
        "                     data2.titleListLeft,data2.titleListRight,\n",
        "                     data2.gtin8ListLeft,data2.gtin8ListRight,\n",
        "                     data2.gtin12ListLeft,data2.gtin12ListRight,\n",
        "                     data2.gtin13ListLeft,data2.gtin13ListRight,\n",
        "                     data2.gtin14ListLeft,data2.gtin14ListRight,\n",
        "                     data2.mpnListLeft,data2.mpnListRight,\n",
        "                     data2.skuListLeft,data2.skuListRight,\n",
        "                     data2.labelList)\n",
        "print (\"ValidationDataSet10DL2\")\n",
        "print (ValidationDataSet10DL2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4LfoNwKSO3I"
      },
      "source": [
        "ValidationDataSet10DL = ValidationDataSet10DL2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJlCjoqySO3I"
      },
      "source": [
        "print (\"ValidationDataSet10DL\")\n",
        "print (ValidationDataSet10DL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxKGWoACSO3I"
      },
      "source": [
        "ValidationDataSet10DL[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRioxyVESO3I"
      },
      "source": [
        "print (data2.labelList[0])\n",
        "print (data2.categoryListLeft[0])\n",
        "print (data2.categoryListRight[0])\n",
        "print (DL(data2.categoryListLeft[0],data2.categoryListRight[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwgkkZcDSO3I"
      },
      "source": [
        "print (data2.labelList[0])\n",
        "print (data2.descriptionListLeft[0])\n",
        "print (data2.descriptionListRight[0])\n",
        "print (DL(data2.descriptionListLeft[0],data2.descriptionListRight[0]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqKFUkrgSO3I"
      },
      "source": [
        "print (len(data2.descriptionListLeft[0]))\n",
        "print (len(data2.descriptionListRight[0]))\n",
        "print (damerau_levenshtein (data2.descriptionListLeft[0],data2.descriptionListRight[0]))\n",
        "print ((damerau_levenshtein (data2.descriptionListLeft[0],data2.descriptionListRight[0]))/(len(data2.descriptionListRight[0])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtiMg-QNSO3J"
      },
      "source": [
        "print (data2.loc[3544])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkJ8ymsQSO3J"
      },
      "source": [
        "\n",
        "print (data2.dtypes)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fxqBkujSO3J"
      },
      "source": [
        "\n",
        "print (data2.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsSIW01tzGXP"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('drive')\n",
        "# 2020-08-07 JUHO: Saving TestDataSetDL preprocessed data using DL Similarity\n",
        "ValidationDataSet10DL.to_pickle('content/drive/My Drive/Python/20200720_DataAnalysis/ValidationDataSet10DL.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKYCEJIggwd3"
      },
      "source": [
        "\n",
        "# save numpy array as npy file\n",
        "#from numpy import asarray\n",
        "#from numpy import save\n",
        "\n",
        "# define data\n",
        "data = asarray([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]])\n",
        "# save to npy file\n",
        "#save('content/drive/My Drive/Python/20200720_DataAnalysis/data.npy', data)\n",
        "np.save('/content/drive/My Drive/Python/20200720_DataAnalysis/data', data, allow_pickle=True, fix_imports=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbRpk_ead4V5"
      },
      "source": [
        "data[0,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ltr4_Eb4SO3J"
      },
      "source": [
        "#numpy.save(file, arr, allow_pickle=True, fix_imports=True)[source]\n",
        "#TestDataSet10DL = asarray (TestDataSet10DL)\n",
        "np.save('/content/drive/My Drive/Python/20200720_DataAnalysis/ValidationDataSet10DL', ValidationDataSet10DL)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZLd-RhEiT95"
      },
      "source": [
        "ValidationDataSet10DL[0,10].dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbQbMOx7LRFO"
      },
      "source": [
        "ValidationDataSet10DL.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3k8M5TMSzLR"
      },
      "source": [
        "# ***Hyperparameter Estimation***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dx4DEMTGTYYB"
      },
      "source": [
        "# ***Hyperparameter Estimation MLP***\n",
        "\n",
        "MLP - DL Similarity Matrix Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoJwl2pjTflO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}